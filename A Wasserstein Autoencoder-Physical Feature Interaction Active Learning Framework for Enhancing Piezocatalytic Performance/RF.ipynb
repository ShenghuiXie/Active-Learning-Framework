{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea831db5-43bd-4d26-be5a-2654d71debea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)       \n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    '''\n",
    "    Args: x is a 2D numpy array [x_size, x_features]\n",
    "    '''\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.x[idx])\n",
    "\n",
    "    def getBatch(self, idxs=[]):\n",
    "        if idxs == None:\n",
    "            return idxs\n",
    "        else:\n",
    "            x_features = []\n",
    "            for i in idxs:\n",
    "                x_features.append(self.__getitem__(i))\n",
    "            return torch.FloatTensor(x_features)\n",
    "\n",
    "def normalizing_data(data, seed=1):  \n",
    "   \n",
    "    composition = data[['Ba', 'Ca', 'Sr', 'Ti', 'Zr','Sn', 'Hf']]\n",
    "    descriptors = data[['W', 'EI', 'EA', 'μ']]\n",
    "    \n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    normalized_composition = min_max_scaler.fit_transform(composition)\n",
    "    normalized_descriptors = min_max_scaler.fit_transform(descriptors)\n",
    "    \n",
    "   \n",
    "    normalized_composition_df = pd.DataFrame(normalized_composition, columns=composition.columns)\n",
    "    normalized_descriptors_df = pd.DataFrame(normalized_descriptors, columns=descriptors.columns)  \n",
    "    \n",
    "    \n",
    "    x = pd.concat([normalized_composition_df, normalized_descriptors_df], axis=1)\n",
    "    print(x)\n",
    "    \n",
    "    y = data[['d33(pC/N)']] \n",
    "    print(y)\n",
    "\n",
    "    \n",
    "    x = torch.FloatTensor(x.values)\n",
    "    y = torch.FloatTensor(y.values)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    \n",
    "    \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "    print(y)\n",
    "    return x, y, train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dded28-10ab-4f66-822b-5f97819dfc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ba        Ca   Sr     Ti     Zr        Sn    Hf         W  \\\n",
      "0    1.000000  0.000000  0.0  1.000  0.000  0.000000  0.00  1.000000   \n",
      "1    1.000000  0.000000  0.0  0.950  0.050  0.000000  0.00  0.978718   \n",
      "2    1.000000  0.000000  0.0  0.950  0.000  0.071429  0.00  0.965424   \n",
      "3    1.000000  0.000000  0.0  0.925  0.075  0.000000  0.00  0.968220   \n",
      "4    1.000000  0.000000  0.0  0.900  0.000  0.000000  0.10  0.877303   \n",
      "..        ...       ...  ...    ...    ...       ...   ...       ...   \n",
      "149  0.333333  0.666667  0.0  1.000  0.000  0.000000  0.00  0.664214   \n",
      "150  0.333333  0.666667  0.0  0.500  0.500  0.000000  0.00  0.495194   \n",
      "151  0.333333  0.666667  0.0  0.500  0.000  0.000000  0.50  0.227934   \n",
      "152  0.200000  0.800000  0.0  0.840  0.000  0.000000  0.16  0.439015   \n",
      "153  0.000000  1.000000  0.0  1.000  0.000  0.000000  0.00  0.496321   \n",
      "\n",
      "           EI        EA         μ  \n",
      "0    0.885689  0.786531  0.000000  \n",
      "1    0.892040  0.765946  0.016596  \n",
      "2    0.868796  0.725267  0.027117  \n",
      "3    0.895215  0.755653  0.024894  \n",
      "4    0.885886  0.783581  0.100000  \n",
      "..        ...       ...       ...  \n",
      "149  0.295230  0.928844  0.000000  \n",
      "150  0.358736  0.722994  0.165962  \n",
      "151  0.296214  0.914096  0.500000  \n",
      "152  0.177453  0.952587  0.160000  \n",
      "153  0.000000  1.000000  0.000000  \n",
      "\n",
      "[154 rows x 11 columns]\n",
      "     d33(pC/N)\n",
      "0          190\n",
      "1          273\n",
      "2          250\n",
      "3          317\n",
      "4          361\n",
      "..         ...\n",
      "149        123\n",
      "150        421\n",
      "151        288\n",
      "152        135\n",
      "153        106\n",
      "\n",
      "[154 rows x 1 columns]\n",
      "tensor([[190.],\n",
      "        [273.],\n",
      "        [250.],\n",
      "        [317.],\n",
      "        [361.],\n",
      "        [343.],\n",
      "        [334.],\n",
      "        [400.],\n",
      "        [272.],\n",
      "        [409.],\n",
      "        [294.],\n",
      "        [275.],\n",
      "        [361.],\n",
      "        [201.],\n",
      "        [308.],\n",
      "        [225.],\n",
      "        [384.],\n",
      "        [193.],\n",
      "        [183.],\n",
      "        [346.],\n",
      "        [165.],\n",
      "        [197.],\n",
      "        [125.],\n",
      "        [312.],\n",
      "        [210.],\n",
      "        [118.],\n",
      "        [390.],\n",
      "        [437.],\n",
      "        [435.],\n",
      "        [358.],\n",
      "        [465.],\n",
      "        [446.],\n",
      "        [451.],\n",
      "        [428.],\n",
      "        [441.],\n",
      "        [508.],\n",
      "        [237.],\n",
      "        [627.],\n",
      "        [440.],\n",
      "        [400.],\n",
      "        [440.],\n",
      "        [532.],\n",
      "        [152.],\n",
      "        [635.],\n",
      "        [520.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [282.],\n",
      "        [338.],\n",
      "        [305.],\n",
      "        [283.],\n",
      "        [249.],\n",
      "        [264.],\n",
      "        [182.],\n",
      "        [140.],\n",
      "        [187.],\n",
      "        [543.],\n",
      "        [548.],\n",
      "        [631.],\n",
      "        [448.],\n",
      "        [217.],\n",
      "        [150.],\n",
      "        [270.],\n",
      "        [285.],\n",
      "        [324.],\n",
      "        [355.],\n",
      "        [360.],\n",
      "        [525.],\n",
      "        [600.],\n",
      "        [520.],\n",
      "        [180.],\n",
      "        [320.],\n",
      "        [170.],\n",
      "        [140.],\n",
      "        [ 90.],\n",
      "        [ 70.],\n",
      "        [218.],\n",
      "        [270.],\n",
      "        [571.],\n",
      "        [552.],\n",
      "        [532.],\n",
      "        [426.],\n",
      "        [603.],\n",
      "        [339.],\n",
      "        [141.],\n",
      "        [308.],\n",
      "        [370.],\n",
      "        [323.],\n",
      "        [282.],\n",
      "        [209.],\n",
      "        [532.],\n",
      "        [283.],\n",
      "        [531.],\n",
      "        [586.],\n",
      "        [420.],\n",
      "        [383.],\n",
      "        [421.],\n",
      "        [131.],\n",
      "        [337.],\n",
      "        [381.],\n",
      "        [404.],\n",
      "        [293.],\n",
      "        [360.],\n",
      "        [129.],\n",
      "        [  9.],\n",
      "        [381.],\n",
      "        [353.],\n",
      "        [389.],\n",
      "        [338.],\n",
      "        [344.],\n",
      "        [207.],\n",
      "        [281.],\n",
      "        [192.],\n",
      "        [156.],\n",
      "        [174.],\n",
      "        [275.],\n",
      "        [356.],\n",
      "        [261.],\n",
      "        [417.],\n",
      "        [307.],\n",
      "        [417.],\n",
      "        [359.],\n",
      "        [362.],\n",
      "        [170.],\n",
      "        [199.],\n",
      "        [282.],\n",
      "        [237.],\n",
      "        [327.],\n",
      "        [347.],\n",
      "        [323.],\n",
      "        [429.],\n",
      "        [215.],\n",
      "        [270.],\n",
      "        [ 49.],\n",
      "        [ 17.],\n",
      "        [335.],\n",
      "        [298.],\n",
      "        [350.],\n",
      "        [332.],\n",
      "        [448.],\n",
      "        [176.],\n",
      "        [328.],\n",
      "        [272.],\n",
      "        [349.],\n",
      "        [238.],\n",
      "        [253.],\n",
      "        [178.],\n",
      "        [200.],\n",
      "        [238.],\n",
      "        [123.],\n",
      "        [421.],\n",
      "        [288.],\n",
      "        [135.],\n",
      "        [106.]], device='cuda:0')\n",
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "train_mapre: 0.2280007910129494\n",
      "test_mapre: 0.20091111827890884\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.2009  \u001b[39m | \u001b[39m53.36    \u001b[39m | \u001b[39m0.8042   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.419    \u001b[39m | \u001b[39m317.4    \u001b[39m |\n",
      "train_mapre: 0.32413327836036554\n",
      "test_mapre: 0.21731488087476886\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-0.2173  \u001b[39m | \u001b[39m27.39    \u001b[39m | \u001b[39m0.4304   \u001b[39m | \u001b[39m2.382    \u001b[39m | \u001b[39m5.174    \u001b[39m | \u001b[39m631.1    \u001b[39m |\n",
      "train_mapre: 0.3534743338159756\n",
      "test_mapre: 0.22888342468590056\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-0.2289  \u001b[39m | \u001b[39m53.54    \u001b[39m | \u001b[39m0.7797   \u001b[39m | \u001b[39m1.818    \u001b[39m | \u001b[39m9.025    \u001b[39m | \u001b[39m221.9    \u001b[39m |\n",
      "train_mapre: 0.35984487701966583\n",
      "test_mapre: 0.23054754352394724\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-0.2305  \u001b[39m | \u001b[39m73.64    \u001b[39m | \u001b[39m0.5921   \u001b[39m | \u001b[39m3.235    \u001b[39m | \u001b[39m3.123    \u001b[39m | \u001b[39m358.5    \u001b[39m |\n",
      "train_mapre: 0.3410869423373151\n",
      "test_mapre: 0.22416193826375327\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-0.2242  \u001b[39m | \u001b[39m84.06    \u001b[39m | \u001b[39m0.9778   \u001b[39m | \u001b[39m2.254    \u001b[39m | \u001b[39m7.539    \u001b[39m | \u001b[39m901.1    \u001b[39m |\n",
      "train_mapre: 0.21648215155742387\n",
      "test_mapre: 0.20722586503514442\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.2072  \u001b[39m | \u001b[39m91.57    \u001b[39m | \u001b[39m0.3595   \u001b[39m | \u001b[39m1.156    \u001b[39m | \u001b[39m3.359    \u001b[39m | \u001b[39m902.5    \u001b[39m |\n",
      "train_mapre: 0.4754412004014456\n",
      "test_mapre: 0.26581519071079107\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.2658  \u001b[39m | \u001b[39m27.87    \u001b[39m | \u001b[39m0.5948   \u001b[39m | \u001b[39m4.832    \u001b[39m | \u001b[39m6.265    \u001b[39m | \u001b[39m753.5    \u001b[39m |\n",
      "train_mapre: 0.4054253386922457\n",
      "test_mapre: 0.2436468514258787\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.2436  \u001b[39m | \u001b[39m45.24    \u001b[39m | \u001b[39m0.7806   \u001b[39m | \u001b[39m4.339    \u001b[39m | \u001b[39m2.146    \u001b[39m | \u001b[39m800.1    \u001b[39m |\n",
      "train_mapre: 0.3414648167125918\n",
      "test_mapre: 0.22490839118975908\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.2249  \u001b[39m | \u001b[39m99.11    \u001b[39m | \u001b[39m0.8237   \u001b[39m | \u001b[39m2.122    \u001b[39m | \u001b[39m8.314    \u001b[39m | \u001b[39m282.6    \u001b[39m |\n",
      "train_mapre: 0.27111656839157444\n",
      "test_mapre: 0.21723816818827876\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.2172  \u001b[39m | \u001b[39m55.83    \u001b[39m | \u001b[39m0.936    \u001b[39m | \u001b[39m2.174    \u001b[39m | \u001b[39m4.302    \u001b[39m | \u001b[39m304.0    \u001b[39m |\n",
      "train_mapre: 0.27697702646912653\n",
      "test_mapre: 0.21691294918912554\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.2169  \u001b[39m | \u001b[39m21.55    \u001b[39m | \u001b[39m0.7752   \u001b[39m | \u001b[39m1.847    \u001b[39m | \u001b[39m4.124    \u001b[39m | \u001b[39m593.3    \u001b[39m |\n",
      "train_mapre: 0.3339543870662426\n",
      "test_mapre: 0.2235983831603037\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.2236  \u001b[39m | \u001b[39m24.27    \u001b[39m | \u001b[39m0.7019   \u001b[39m | \u001b[39m1.587    \u001b[39m | \u001b[39m6.714    \u001b[39m | \u001b[39m759.8    \u001b[39m |\n",
      "train_mapre: 0.41334889465441177\n",
      "test_mapre: 0.2518903973495156\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.2519  \u001b[39m | \u001b[39m28.19    \u001b[39m | \u001b[39m0.5898   \u001b[39m | \u001b[39m3.778    \u001b[39m | \u001b[39m5.313    \u001b[39m | \u001b[39m240.0    \u001b[39m |\n",
      "train_mapre: 0.38635420405385235\n",
      "test_mapre: 0.2400756368724296\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.2401  \u001b[39m | \u001b[39m62.87    \u001b[39m | \u001b[39m0.7647   \u001b[39m | \u001b[39m3.06     \u001b[39m | \u001b[39m9.557    \u001b[39m | \u001b[39m669.2    \u001b[39m |\n",
      "train_mapre: 0.3577605700698143\n",
      "test_mapre: 0.22909596621052636\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.2291  \u001b[39m | \u001b[39m92.27    \u001b[39m | \u001b[39m0.3962   \u001b[39m | \u001b[39m1.557    \u001b[39m | \u001b[39m8.459    \u001b[39m | \u001b[39m518.1    \u001b[39m |\n",
      "train_mapre: 0.3419814776900179\n",
      "test_mapre: 0.2236403615975711\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.2236  \u001b[39m | \u001b[39m33.23    \u001b[39m | \u001b[39m0.9493   \u001b[39m | \u001b[39m2.391    \u001b[39m | \u001b[39m8.006    \u001b[39m | \u001b[39m780.8    \u001b[39m |\n",
      "train_mapre: 0.40598352339872873\n",
      "test_mapre: 0.2431071275329018\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.2431  \u001b[39m | \u001b[39m90.66    \u001b[39m | \u001b[39m0.7366   \u001b[39m | \u001b[39m4.004    \u001b[39m | \u001b[39m4.791    \u001b[39m | \u001b[39m415.9    \u001b[39m |\n",
      "train_mapre: 0.47596826863117203\n",
      "test_mapre: 0.2657359546284333\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.2657  \u001b[39m | \u001b[39m91.67    \u001b[39m | \u001b[39m0.5997   \u001b[39m | \u001b[39m4.859    \u001b[39m | \u001b[39m7.308    \u001b[39m | \u001b[39m697.4    \u001b[39m |\n",
      "train_mapre: 0.3483658903178692\n",
      "test_mapre: 0.23319362573480862\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-0.2332  \u001b[39m | \u001b[39m29.18    \u001b[39m | \u001b[39m0.9646   \u001b[39m | \u001b[39m2.8      \u001b[39m | \u001b[39m6.627    \u001b[39m | \u001b[39m526.5    \u001b[39m |\n",
      "train_mapre: 0.34134316388127955\n",
      "test_mapre: 0.23046090965576466\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.2305  \u001b[39m | \u001b[39m38.96    \u001b[39m | \u001b[39m0.9324   \u001b[39m | \u001b[39m3.295    \u001b[39m | \u001b[39m2.023    \u001b[39m | \u001b[39m693.7    \u001b[39m |\n",
      "train_mapre: 0.46195009191040404\n",
      "test_mapre: 0.2607933406183318\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.2608  \u001b[39m | \u001b[39m46.13    \u001b[39m | \u001b[39m0.6689   \u001b[39m | \u001b[39m4.544    \u001b[39m | \u001b[39m4.858    \u001b[39m | \u001b[39m926.8    \u001b[39m |\n",
      "train_mapre: 0.5013384090684998\n",
      "test_mapre: 0.2663709402964626\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.2664  \u001b[39m | \u001b[39m69.87    \u001b[39m | \u001b[39m0.3111   \u001b[39m | \u001b[39m4.718    \u001b[39m | \u001b[39m7.527    \u001b[39m | \u001b[39m997.9    \u001b[39m |\n",
      "train_mapre: 0.49371223144811\n",
      "test_mapre: 0.26725472859988203\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.2673  \u001b[39m | \u001b[39m33.79    \u001b[39m | \u001b[39m0.396    \u001b[39m | \u001b[39m4.73     \u001b[39m | \u001b[39m7.575    \u001b[39m | \u001b[39m252.8    \u001b[39m |\n",
      "train_mapre: 0.4447103608788326\n",
      "test_mapre: 0.26373157268095837\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-0.2637  \u001b[39m | \u001b[39m80.44    \u001b[39m | \u001b[39m0.8277   \u001b[39m | \u001b[39m4.692    \u001b[39m | \u001b[39m7.692    \u001b[39m | \u001b[39m299.4    \u001b[39m |\n",
      "train_mapre: 0.24690503955813645\n",
      "test_mapre: 0.2085455740011813\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.2085  \u001b[39m | \u001b[39m21.59    \u001b[39m | \u001b[39m0.3183   \u001b[39m | \u001b[39m1.113    \u001b[39m | \u001b[39m3.97     \u001b[39m | \u001b[39m888.0    \u001b[39m |\n",
      "train_mapre: 0.41298590097893717\n",
      "test_mapre: 0.2435552222264971\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.2436  \u001b[39m | \u001b[39m63.11    \u001b[39m | \u001b[39m0.687    \u001b[39m | \u001b[39m4.368    \u001b[39m | \u001b[39m2.993    \u001b[39m | \u001b[39m423.3    \u001b[39m |\n",
      "train_mapre: 0.3400494629257564\n",
      "test_mapre: 0.23078431514113118\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.2308  \u001b[39m | \u001b[39m66.86    \u001b[39m | \u001b[39m0.9787   \u001b[39m | \u001b[39m3.244    \u001b[39m | \u001b[39m2.149    \u001b[39m | \u001b[39m840.5    \u001b[39m |\n",
      "train_mapre: 0.37570842336639865\n",
      "test_mapre: 0.23940731521027436\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.2394  \u001b[39m | \u001b[39m38.64    \u001b[39m | \u001b[39m0.865    \u001b[39m | \u001b[39m2.551    \u001b[39m | \u001b[39m8.908    \u001b[39m | \u001b[39m797.7    \u001b[39m |\n",
      "train_mapre: 0.20860610306166164\n",
      "test_mapre: 0.20628353876958708\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.2063  \u001b[39m | \u001b[39m64.5     \u001b[39m | \u001b[39m0.3955   \u001b[39m | \u001b[39m1.24     \u001b[39m | \u001b[39m2.971    \u001b[39m | \u001b[39m235.6    \u001b[39m |\n",
      "train_mapre: 0.4198340797053308\n",
      "test_mapre: 0.2516915999955766\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.2517  \u001b[39m | \u001b[39m28.6     \u001b[39m | \u001b[39m0.458    \u001b[39m | \u001b[39m3.852    \u001b[39m | \u001b[39m6.478    \u001b[39m | \u001b[39m210.0    \u001b[39m |\n",
      "train_mapre: 0.33858548154488455\n",
      "test_mapre: 0.23009241020184126\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-0.2301  \u001b[39m | \u001b[39m25.76    \u001b[39m | \u001b[39m0.9771   \u001b[39m | \u001b[39m3.272    \u001b[39m | \u001b[39m3.626    \u001b[39m | \u001b[39m401.9    \u001b[39m |\n",
      "train_mapre: 0.4173343953497917\n",
      "test_mapre: 0.2483562158453786\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-0.2484  \u001b[39m | \u001b[39m79.51    \u001b[39m | \u001b[39m0.4368   \u001b[39m | \u001b[39m3.325    \u001b[39m | \u001b[39m9.76     \u001b[39m | \u001b[39m877.5    \u001b[39m |\n",
      "train_mapre: 0.38463513151269646\n",
      "test_mapre: 0.23971082346992356\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-0.2397  \u001b[39m | \u001b[39m39.19    \u001b[39m | \u001b[39m0.6456   \u001b[39m | \u001b[39m3.48     \u001b[39m | \u001b[39m8.632    \u001b[39m | \u001b[39m325.4    \u001b[39m |\n",
      "train_mapre: 0.40598451778358974\n",
      "test_mapre: 0.23733327404146204\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-0.2373  \u001b[39m | \u001b[39m21.49    \u001b[39m | \u001b[39m0.349    \u001b[39m | \u001b[39m2.945    \u001b[39m | \u001b[39m6.851    \u001b[39m | \u001b[39m655.1    \u001b[39m |\n",
      "train_mapre: 0.33926378252842265\n",
      "test_mapre: 0.22975833063049128\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-0.2298  \u001b[39m | \u001b[39m45.39    \u001b[39m | \u001b[39m0.992    \u001b[39m | \u001b[39m3.319    \u001b[39m | \u001b[39m5.041    \u001b[39m | \u001b[39m640.8    \u001b[39m |\n",
      "train_mapre: 0.27825135848751287\n",
      "test_mapre: 0.21751522935240405\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-0.2175  \u001b[39m | \u001b[39m79.63    \u001b[39m | \u001b[39m0.7685   \u001b[39m | \u001b[39m2.06     \u001b[39m | \u001b[39m2.531    \u001b[39m | \u001b[39m496.1    \u001b[39m |\n",
      "train_mapre: 0.4477319307557443\n",
      "test_mapre: 0.24928979464403056\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-0.2493  \u001b[39m | \u001b[39m70.38    \u001b[39m | \u001b[39m0.4471   \u001b[39m | \u001b[39m4.011    \u001b[39m | \u001b[39m2.532    \u001b[39m | \u001b[39m408.3    \u001b[39m |\n",
      "train_mapre: 0.44395010903150633\n",
      "test_mapre: 0.25042791983512863\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-0.2504  \u001b[39m | \u001b[39m84.38    \u001b[39m | \u001b[39m0.4354   \u001b[39m | \u001b[39m3.558    \u001b[39m | \u001b[39m6.197    \u001b[39m | \u001b[39m939.8    \u001b[39m |\n",
      "train_mapre: 0.4532632759143521\n",
      "test_mapre: 0.2532326443447083\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-0.2532  \u001b[39m | \u001b[39m41.06    \u001b[39m | \u001b[39m0.3462   \u001b[39m | \u001b[39m3.94     \u001b[39m | \u001b[39m8.177    \u001b[39m | \u001b[39m926.3    \u001b[39m |\n",
      "train_mapre: 0.36289509028060196\n",
      "test_mapre: 0.2252344901527309\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-0.2252  \u001b[39m | \u001b[39m94.56    \u001b[39m | \u001b[39m0.3098   \u001b[39m | \u001b[39m1.937    \u001b[39m | \u001b[39m6.934    \u001b[39m | \u001b[39m959.2    \u001b[39m |\n",
      "train_mapre: 0.46223291189767085\n",
      "test_mapre: 0.26018937944017667\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-0.2602  \u001b[39m | \u001b[39m96.01    \u001b[39m | \u001b[39m0.6897   \u001b[39m | \u001b[39m4.662    \u001b[39m | \u001b[39m7.133    \u001b[39m | \u001b[39m512.0    \u001b[39m |\n",
      "train_mapre: 0.38481928827055817\n",
      "test_mapre: 0.24125492326939935\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-0.2413  \u001b[39m | \u001b[39m58.88    \u001b[39m | \u001b[39m0.723    \u001b[39m | \u001b[39m3.198    \u001b[39m | \u001b[39m9.409    \u001b[39m | \u001b[39m935.0    \u001b[39m |\n",
      "train_mapre: 0.27249973712091546\n",
      "test_mapre: 0.2173404711878411\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-0.2173  \u001b[39m | \u001b[39m51.59    \u001b[39m | \u001b[39m0.9743   \u001b[39m | \u001b[39m1.696    \u001b[39m | \u001b[39m3.011    \u001b[39m | \u001b[39m308.1    \u001b[39m |\n",
      "train_mapre: 0.5097972143986677\n",
      "test_mapre: 0.268731763871563\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-0.2687  \u001b[39m | \u001b[39m60.45    \u001b[39m | \u001b[39m0.3151   \u001b[39m | \u001b[39m4.792    \u001b[39m | \u001b[39m8.617    \u001b[39m | \u001b[39m212.0    \u001b[39m |\n",
      "train_mapre: 0.35300470638474346\n",
      "test_mapre: 0.23112210333935823\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-0.2311  \u001b[39m | \u001b[39m34.1     \u001b[39m | \u001b[39m0.5324   \u001b[39m | \u001b[39m1.524    \u001b[39m | \u001b[39m8.476    \u001b[39m | \u001b[39m475.8    \u001b[39m |\n",
      "train_mapre: 0.461997397553074\n",
      "test_mapre: 0.2607977981615889\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-0.2608  \u001b[39m | \u001b[39m95.21    \u001b[39m | \u001b[39m0.7074   \u001b[39m | \u001b[39m4.515    \u001b[39m | \u001b[39m8.758    \u001b[39m | \u001b[39m924.3    \u001b[39m |\n",
      "train_mapre: 0.41236553007937055\n",
      "test_mapre: 0.2440052431280989\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-0.244   \u001b[39m | \u001b[39m56.79    \u001b[39m | \u001b[39m0.6824   \u001b[39m | \u001b[39m4.194    \u001b[39m | \u001b[39m4.286    \u001b[39m | \u001b[39m592.2    \u001b[39m |\n",
      "train_mapre: 0.40076595143546845\n",
      "test_mapre: 0.23839016259096144\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-0.2384  \u001b[39m | \u001b[39m67.93    \u001b[39m | \u001b[39m0.3109   \u001b[39m | \u001b[39m3.374    \u001b[39m | \u001b[39m5.469    \u001b[39m | \u001b[39m845.9    \u001b[39m |\n",
      "train_mapre: 0.3396822835945668\n",
      "test_mapre: 0.23058578502181756\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-0.2306  \u001b[39m | \u001b[39m45.22    \u001b[39m | \u001b[39m0.925    \u001b[39m | \u001b[39m3.311    \u001b[39m | \u001b[39m3.472    \u001b[39m | \u001b[39m830.3    \u001b[39m |\n",
      "train_mapre: 0.40281438707620065\n",
      "test_mapre: 0.2387913284280828\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-0.2388  \u001b[39m | \u001b[39m68.96    \u001b[39m | \u001b[39m0.3377   \u001b[39m | \u001b[39m2.681    \u001b[39m | \u001b[39m7.433    \u001b[39m | \u001b[39m934.9    \u001b[39m |\n",
      "train_mapre: 0.3829964367233276\n",
      "test_mapre: 0.24293984996320586\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-0.2429  \u001b[39m | \u001b[39m20.03    \u001b[39m | \u001b[39m0.9837   \u001b[39m | \u001b[39m2.506    \u001b[39m | \u001b[39m9.79     \u001b[39m | \u001b[39m683.8    \u001b[39m |\n",
      "train_mapre: 0.4134852141807806\n",
      "test_mapre: 0.2449024359611328\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-0.2449  \u001b[39m | \u001b[39m86.31    \u001b[39m | \u001b[39m0.7023   \u001b[39m | \u001b[39m3.512    \u001b[39m | \u001b[39m4.285    \u001b[39m | \u001b[39m669.5    \u001b[39m |\n",
      "train_mapre: 0.40084111141961504\n",
      "test_mapre: 0.24547680174182385\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-0.2455  \u001b[39m | \u001b[39m80.0     \u001b[39m | \u001b[39m0.9008   \u001b[39m | \u001b[39m4.02     \u001b[39m | \u001b[39m7.584    \u001b[39m | \u001b[39m891.6    \u001b[39m |\n",
      "train_mapre: 0.3447459070569706\n",
      "test_mapre: 0.22881762650028906\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-0.2288  \u001b[39m | \u001b[39m45.81    \u001b[39m | \u001b[39m0.7696   \u001b[39m | \u001b[39m2.803    \u001b[39m | \u001b[39m5.057    \u001b[39m | \u001b[39m528.6    \u001b[39m |\n",
      "train_mapre: 0.37264858971373566\n",
      "test_mapre: 0.23434567425893646\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-0.2343  \u001b[39m | \u001b[39m52.12    \u001b[39m | \u001b[39m0.5222   \u001b[39m | \u001b[39m3.488    \u001b[39m | \u001b[39m5.442    \u001b[39m | \u001b[39m979.0    \u001b[39m |\n",
      "train_mapre: 0.38560086823082224\n",
      "test_mapre: 0.2350595443537526\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-0.2351  \u001b[39m | \u001b[39m74.22    \u001b[39m | \u001b[39m0.439    \u001b[39m | \u001b[39m2.707    \u001b[39m | \u001b[39m4.747    \u001b[39m | \u001b[39m838.1    \u001b[39m |\n",
      "train_mapre: 0.396402879978938\n",
      "test_mapre: 0.2467154470144799\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-0.2467  \u001b[39m | \u001b[39m90.4     \u001b[39m | \u001b[39m0.9327   \u001b[39m | \u001b[39m3.651    \u001b[39m | \u001b[39m4.162    \u001b[39m | \u001b[39m401.9    \u001b[39m |\n",
      "train_mapre: 0.4148593922103512\n",
      "test_mapre: 0.24619124019458616\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-0.2462  \u001b[39m | \u001b[39m88.39    \u001b[39m | \u001b[39m0.6694   \u001b[39m | \u001b[39m4.209    \u001b[39m | \u001b[39m6.58     \u001b[39m | \u001b[39m786.5    \u001b[39m |\n",
      "train_mapre: 0.3444119816045447\n",
      "test_mapre: 0.23239368149329803\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m-0.2324  \u001b[39m | \u001b[39m61.52    \u001b[39m | \u001b[39m0.8396   \u001b[39m | \u001b[39m3.275    \u001b[39m | \u001b[39m5.726    \u001b[39m | \u001b[39m474.2    \u001b[39m |\n",
      "train_mapre: 0.35189575932221323\n",
      "test_mapre: 0.23250822956078768\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-0.2325  \u001b[39m | \u001b[39m25.46    \u001b[39m | \u001b[39m0.5645   \u001b[39m | \u001b[39m1.319    \u001b[39m | \u001b[39m9.863    \u001b[39m | \u001b[39m345.3    \u001b[39m |\n",
      "train_mapre: 0.3971836754559238\n",
      "test_mapre: 0.24730000924259282\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m-0.2473  \u001b[39m | \u001b[39m84.95    \u001b[39m | \u001b[39m0.9125   \u001b[39m | \u001b[39m3.754    \u001b[39m | \u001b[39m6.556    \u001b[39m | \u001b[39m328.8    \u001b[39m |\n",
      "train_mapre: 0.34120741903190266\n",
      "test_mapre: 0.22523019811756165\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m-0.2252  \u001b[39m | \u001b[39m57.35    \u001b[39m | \u001b[39m0.5416   \u001b[39m | \u001b[39m1.9      \u001b[39m | \u001b[39m6.74     \u001b[39m | \u001b[39m449.8    \u001b[39m |\n",
      "train_mapre: 0.2729760382639687\n",
      "test_mapre: 0.2174647925517335\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m-0.2175  \u001b[39m | \u001b[39m93.3     \u001b[39m | \u001b[39m0.9367   \u001b[39m | \u001b[39m2.028    \u001b[39m | \u001b[39m2.887    \u001b[39m | \u001b[39m354.4    \u001b[39m |\n",
      "train_mapre: 0.2790168677893664\n",
      "test_mapre: 0.21827563603796116\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m-0.2183  \u001b[39m | \u001b[39m59.97    \u001b[39m | \u001b[39m0.81     \u001b[39m | \u001b[39m1.833    \u001b[39m | \u001b[39m3.984    \u001b[39m | \u001b[39m881.3    \u001b[39m |\n",
      "train_mapre: 0.27777054024867714\n",
      "test_mapre: 0.2166059237800812\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m-0.2166  \u001b[39m | \u001b[39m53.27    \u001b[39m | \u001b[39m0.7317   \u001b[39m | \u001b[39m1.935    \u001b[39m | \u001b[39m2.816    \u001b[39m | \u001b[39m612.7    \u001b[39m |\n",
      "train_mapre: 0.38764084515486175\n",
      "test_mapre: 0.23391031396551462\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m-0.2339  \u001b[39m | \u001b[39m58.17    \u001b[39m | \u001b[39m0.4069   \u001b[39m | \u001b[39m3.487    \u001b[39m | \u001b[39m6.352    \u001b[39m | \u001b[39m723.3    \u001b[39m |\n",
      "train_mapre: 0.31544935587352785\n",
      "test_mapre: 0.2199676726838595\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m-0.22    \u001b[39m | \u001b[39m31.56    \u001b[39m | \u001b[39m0.8261   \u001b[39m | \u001b[39m1.888    \u001b[39m | \u001b[39m6.155    \u001b[39m | \u001b[39m828.2    \u001b[39m |\n",
      "train_mapre: 0.4410406831194118\n",
      "test_mapre: 0.2536743189557801\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m-0.2537  \u001b[39m | \u001b[39m21.79    \u001b[39m | \u001b[39m0.5271   \u001b[39m | \u001b[39m4.492    \u001b[39m | \u001b[39m8.758    \u001b[39m | \u001b[39m630.8    \u001b[39m |\n",
      "train_mapre: 0.3993380398952484\n",
      "test_mapre: 0.2501856466691817\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m-0.2502  \u001b[39m | \u001b[39m89.33    \u001b[39m | \u001b[39m0.9649   \u001b[39m | \u001b[39m4.306    \u001b[39m | \u001b[39m8.833    \u001b[39m | \u001b[39m279.0    \u001b[39m |\n",
      "train_mapre: 0.3656494356644131\n",
      "test_mapre: 0.2383571450975041\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m-0.2384  \u001b[39m | \u001b[39m72.1     \u001b[39m | \u001b[39m0.7925   \u001b[39m | \u001b[39m3.441    \u001b[39m | \u001b[39m8.397    \u001b[39m | \u001b[39m227.7    \u001b[39m |\n",
      "train_mapre: 0.2806826077213585\n",
      "test_mapre: 0.2169001249540764\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m-0.2169  \u001b[39m | \u001b[39m81.62    \u001b[39m | \u001b[39m0.8122   \u001b[39m | \u001b[39m2.039    \u001b[39m | \u001b[39m4.057    \u001b[39m | \u001b[39m705.8    \u001b[39m |\n",
      "train_mapre: 0.3644520867955647\n",
      "test_mapre: 0.2364233338121771\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m-0.2364  \u001b[39m | \u001b[39m47.62    \u001b[39m | \u001b[39m0.8576   \u001b[39m | \u001b[39m2.785    \u001b[39m | \u001b[39m8.262    \u001b[39m | \u001b[39m992.4    \u001b[39m |\n",
      "train_mapre: 0.49475250094683276\n",
      "test_mapre: 0.26596626801760453\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m-0.266   \u001b[39m | \u001b[39m44.02    \u001b[39m | \u001b[39m0.4001   \u001b[39m | \u001b[39m4.605    \u001b[39m | \u001b[39m6.332    \u001b[39m | \u001b[39m979.8    \u001b[39m |\n",
      "train_mapre: 0.3404730093696403\n",
      "test_mapre: 0.2305676456791548\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m-0.2306  \u001b[39m | \u001b[39m70.93    \u001b[39m | \u001b[39m0.9957   \u001b[39m | \u001b[39m3.184    \u001b[39m | \u001b[39m6.211    \u001b[39m | \u001b[39m308.3    \u001b[39m |\n",
      "train_mapre: 0.36912322424327015\n",
      "test_mapre: 0.23680222083525437\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m-0.2368  \u001b[39m | \u001b[39m48.46    \u001b[39m | \u001b[39m0.3184   \u001b[39m | \u001b[39m1.642    \u001b[39m | \u001b[39m7.965    \u001b[39m | \u001b[39m224.3    \u001b[39m |\n",
      "train_mapre: 0.39996347450617814\n",
      "test_mapre: 0.2451498515104008\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m-0.2451  \u001b[39m | \u001b[39m49.32    \u001b[39m | \u001b[39m0.9036   \u001b[39m | \u001b[39m3.771    \u001b[39m | \u001b[39m7.528    \u001b[39m | \u001b[39m350.9    \u001b[39m |\n",
      "train_mapre: 0.4655915605242165\n",
      "test_mapre: 0.2600295377954105\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m-0.26    \u001b[39m | \u001b[39m55.35    \u001b[39m | \u001b[39m0.7071   \u001b[39m | \u001b[39m4.959    \u001b[39m | \u001b[39m3.631    \u001b[39m | \u001b[39m398.2    \u001b[39m |\n",
      "train_mapre: 0.34464297795551485\n",
      "test_mapre: 0.23149906865039085\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m-0.2315  \u001b[39m | \u001b[39m40.97    \u001b[39m | \u001b[39m0.8251   \u001b[39m | \u001b[39m2.828    \u001b[39m | \u001b[39m2.455    \u001b[39m | \u001b[39m606.8    \u001b[39m |\n",
      "train_mapre: 0.276030408131857\n",
      "test_mapre: 0.2184083086264561\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m-0.2184  \u001b[39m | \u001b[39m36.96    \u001b[39m | \u001b[39m0.859    \u001b[39m | \u001b[39m2.189    \u001b[39m | \u001b[39m2.221    \u001b[39m | \u001b[39m674.7    \u001b[39m |\n",
      "train_mapre: 0.42321777910493213\n",
      "test_mapre: 0.24796097659507504\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m-0.248   \u001b[39m | \u001b[39m87.51    \u001b[39m | \u001b[39m0.5667   \u001b[39m | \u001b[39m3.999    \u001b[39m | \u001b[39m6.089    \u001b[39m | \u001b[39m632.8    \u001b[39m |\n",
      "train_mapre: 0.3181173684829675\n",
      "test_mapre: 0.2196008864305168\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m-0.2196  \u001b[39m | \u001b[39m96.75    \u001b[39m | \u001b[39m0.8628   \u001b[39m | \u001b[39m1.129    \u001b[39m | \u001b[39m7.675    \u001b[39m | \u001b[39m572.0    \u001b[39m |\n",
      "train_mapre: 0.2929411142076045\n",
      "test_mapre: 0.21736012657990608\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m-0.2174  \u001b[39m | \u001b[39m95.8     \u001b[39m | \u001b[39m0.455    \u001b[39m | \u001b[39m2.068    \u001b[39m | \u001b[39m2.652    \u001b[39m | \u001b[39m542.9    \u001b[39m |\n",
      "train_mapre: 0.4053995034000954\n",
      "test_mapre: 0.24368935135617367\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m-0.2437  \u001b[39m | \u001b[39m28.72    \u001b[39m | \u001b[39m0.7437   \u001b[39m | \u001b[39m4.212    \u001b[39m | \u001b[39m7.574    \u001b[39m | \u001b[39m813.0    \u001b[39m |\n",
      "train_mapre: 0.37673167180308864\n",
      "test_mapre: 0.23974007027194943\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m-0.2397  \u001b[39m | \u001b[39m47.4     \u001b[39m | \u001b[39m0.8921   \u001b[39m | \u001b[39m2.715    \u001b[39m | \u001b[39m8.592    \u001b[39m | \u001b[39m701.2    \u001b[39m |\n",
      "train_mapre: 0.21197183747746828\n",
      "test_mapre: 0.20453784187336177\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m-0.2045  \u001b[39m | \u001b[39m31.47    \u001b[39m | \u001b[39m0.3549   \u001b[39m | \u001b[39m1.073    \u001b[39m | \u001b[39m2.534    \u001b[39m | \u001b[39m566.9    \u001b[39m |\n",
      "train_mapre: 0.4538670453044115\n",
      "test_mapre: 0.2531964422957564\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m-0.2532  \u001b[39m | \u001b[39m29.07    \u001b[39m | \u001b[39m0.3194   \u001b[39m | \u001b[39m4.019    \u001b[39m | \u001b[39m5.159    \u001b[39m | \u001b[39m797.6    \u001b[39m |\n",
      "train_mapre: 0.36410874813709226\n",
      "test_mapre: 0.23240554450354048\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m-0.2324  \u001b[39m | \u001b[39m56.19    \u001b[39m | \u001b[39m0.6151   \u001b[39m | \u001b[39m2.912    \u001b[39m | \u001b[39m5.792    \u001b[39m | \u001b[39m842.5    \u001b[39m |\n",
      "train_mapre: 0.31922856193251414\n",
      "test_mapre: 0.21871228841699306\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m-0.2187  \u001b[39m | \u001b[39m52.19    \u001b[39m | \u001b[39m0.9333   \u001b[39m | \u001b[39m1.148    \u001b[39m | \u001b[39m8.191    \u001b[39m | \u001b[39m300.5    \u001b[39m |\n",
      "train_mapre: 0.39702804514494866\n",
      "test_mapre: 0.2379042902727005\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m-0.2379  \u001b[39m | \u001b[39m69.48    \u001b[39m | \u001b[39m0.3073   \u001b[39m | \u001b[39m3.155    \u001b[39m | \u001b[39m2.024    \u001b[39m | \u001b[39m961.0    \u001b[39m |\n",
      "train_mapre: 0.44444993582271725\n",
      "test_mapre: 0.26342165344349394\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m-0.2634  \u001b[39m | \u001b[39m92.43    \u001b[39m | \u001b[39m0.8572   \u001b[39m | \u001b[39m4.661    \u001b[39m | \u001b[39m3.164    \u001b[39m | \u001b[39m326.2    \u001b[39m |\n",
      "train_mapre: 0.4577353074922767\n",
      "test_mapre: 0.26215828742554315\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m-0.2622  \u001b[39m | \u001b[39m35.01    \u001b[39m | \u001b[39m0.7357   \u001b[39m | \u001b[39m4.623    \u001b[39m | \u001b[39m9.92     \u001b[39m | \u001b[39m768.9    \u001b[39m |\n",
      "train_mapre: 0.34079594201691216\n",
      "test_mapre: 0.23064865357397843\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m-0.2306  \u001b[39m | \u001b[39m78.54    \u001b[39m | \u001b[39m0.9365   \u001b[39m | \u001b[39m2.603    \u001b[39m | \u001b[39m3.999    \u001b[39m | \u001b[39m338.7    \u001b[39m |\n",
      "train_mapre: 0.2771471558340716\n",
      "test_mapre: 0.2188649489248074\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m-0.2189  \u001b[39m | \u001b[39m29.56    \u001b[39m | \u001b[39m0.8688   \u001b[39m | \u001b[39m1.587    \u001b[39m | \u001b[39m4.114    \u001b[39m | \u001b[39m855.3    \u001b[39m |\n",
      "train_mapre: 0.31316821836884096\n",
      "test_mapre: 0.21926021108430863\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m-0.2193  \u001b[39m | \u001b[39m44.85    \u001b[39m | \u001b[39m0.9877   \u001b[39m | \u001b[39m2.067    \u001b[39m | \u001b[39m6.269    \u001b[39m | \u001b[39m451.6    \u001b[39m |\n",
      "train_mapre: 0.3619022028673913\n",
      "test_mapre: 0.23136492473199954\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m-0.2314  \u001b[39m | \u001b[39m92.86    \u001b[39m | \u001b[39m0.5566   \u001b[39m | \u001b[39m2.734    \u001b[39m | \u001b[39m6.098    \u001b[39m | \u001b[39m951.1    \u001b[39m |\n",
      "train_mapre: 0.45685821663586257\n",
      "test_mapre: 0.2619643451804782\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m-0.262   \u001b[39m | \u001b[39m22.48    \u001b[39m | \u001b[39m0.8018   \u001b[39m | \u001b[39m4.564    \u001b[39m | \u001b[39m2.218    \u001b[39m | \u001b[39m617.6    \u001b[39m |\n",
      "train_mapre: 0.3629733089942315\n",
      "test_mapre: 0.23585471813549824\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m-0.2359  \u001b[39m | \u001b[39m46.08    \u001b[39m | \u001b[39m0.9016   \u001b[39m | \u001b[39m3.234    \u001b[39m | \u001b[39m7.522    \u001b[39m | \u001b[39m562.3    \u001b[39m |\n",
      "train_mapre: 0.30353851479901606\n",
      "test_mapre: 0.21973387607553904\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m-0.2197  \u001b[39m | \u001b[39m70.26    \u001b[39m | \u001b[39m0.5031   \u001b[39m | \u001b[39m1.037    \u001b[39m | \u001b[39m6.614    \u001b[39m | \u001b[39m449.2    \u001b[39m |\n",
      "train_mapre: 0.3374802717027595\n",
      "test_mapre: 0.22998307628691472\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m-0.23    \u001b[39m | \u001b[39m61.38    \u001b[39m | \u001b[39m0.9415   \u001b[39m | \u001b[39m2.706    \u001b[39m | \u001b[39m3.979    \u001b[39m | \u001b[39m497.0    \u001b[39m |\n",
      "train_mapre: 0.4007488920937946\n",
      "test_mapre: 0.24825032261054522\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m-0.2483  \u001b[39m | \u001b[39m94.55    \u001b[39m | \u001b[39m0.9558   \u001b[39m | \u001b[39m4.377    \u001b[39m | \u001b[39m9.362    \u001b[39m | \u001b[39m382.3    \u001b[39m |\n",
      "train_mapre: 0.25508159406902653\n",
      "test_mapre: 0.20767868974691642\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m-0.2077  \u001b[39m | \u001b[39m55.03    \u001b[39m | \u001b[39m0.8102   \u001b[39m | \u001b[39m1.227    \u001b[39m | \u001b[39m5.36     \u001b[39m | \u001b[39m313.7    \u001b[39m |\n",
      "train_mapre: 0.4157494325593998\n",
      "test_mapre: 0.2500384115127715\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m-0.25    \u001b[39m | \u001b[39m53.03    \u001b[39m | \u001b[39m0.5526   \u001b[39m | \u001b[39m4.384    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m315.9    \u001b[39m |\n",
      "train_mapre: 0.3002740988754333\n",
      "test_mapre: 0.21434024844151398\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m-0.2143  \u001b[39m | \u001b[39m54.2     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.679    \u001b[39m | \u001b[39m316.6    \u001b[39m |\n",
      "train_mapre: 0.2280007910129494\n",
      "test_mapre: 0.20091111827890884\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m-0.2009  \u001b[39m | \u001b[39m55.61    \u001b[39m | \u001b[39m0.7732   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.019    \u001b[39m | \u001b[39m316.5    \u001b[39m |\n",
      "train_mapre: 0.24742778491089798\n",
      "test_mapre: 0.20358891766773715\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m-0.2036  \u001b[39m | \u001b[39m53.63    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.025    \u001b[39m | \u001b[39m315.3    \u001b[39m |\n",
      "train_mapre: 0.24729322915749585\n",
      "test_mapre: 0.20369429897270144\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m-0.2037  \u001b[39m | \u001b[39m55.28    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.906    \u001b[39m | \u001b[39m319.8    \u001b[39m |\n",
      "train_mapre: 0.31547919459242907\n",
      "test_mapre: 0.21999281138599092\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m-0.22    \u001b[39m | \u001b[39m28.29    \u001b[39m | \u001b[39m0.3075   \u001b[39m | \u001b[39m2.243    \u001b[39m | \u001b[39m3.295    \u001b[39m | \u001b[39m566.2    \u001b[39m |\n",
      "train_mapre: 0.381151229764378\n",
      "test_mapre: 0.23292070122628522\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m-0.2329  \u001b[39m | \u001b[39m33.97    \u001b[39m | \u001b[39m0.4391   \u001b[39m | \u001b[39m3.11     \u001b[39m | \u001b[39m4.111    \u001b[39m | \u001b[39m567.0    \u001b[39m |\n",
      "train_mapre: 0.27756817264767886\n",
      "test_mapre: 0.2178883005622455\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m-0.2179  \u001b[39m | \u001b[39m88.42    \u001b[39m | \u001b[39m0.7746   \u001b[39m | \u001b[39m2.237    \u001b[39m | \u001b[39m3.925    \u001b[39m | \u001b[39m903.6    \u001b[39m |\n",
      "train_mapre: 0.18830324926731795\n",
      "test_mapre: 0.20386342695836063\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m-0.2039  \u001b[39m | \u001b[39m63.5     \u001b[39m | \u001b[39m0.5414   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.123    \u001b[39m | \u001b[39m238.9    \u001b[39m |\n",
      "train_mapre: 0.4128011591270461\n",
      "test_mapre: 0.25142351683925546\n",
      "| \u001b[39m111      \u001b[39m | \u001b[39m-0.2514  \u001b[39m | \u001b[39m63.3     \u001b[39m | \u001b[39m0.613    \u001b[39m | \u001b[39m4.193    \u001b[39m | \u001b[39m3.71     \u001b[39m | \u001b[39m237.9    \u001b[39m |\n",
      "train_mapre: 0.19242840163707314\n",
      "test_mapre: 0.19893394003837064\n",
      "| \u001b[35m112      \u001b[39m | \u001b[35m-0.1989  \u001b[39m | \u001b[35m30.36    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m569.4    \u001b[39m |\n",
      "train_mapre: 0.18150845860093603\n",
      "test_mapre: 0.20077158113934163\n",
      "| \u001b[39m113      \u001b[39m | \u001b[39m-0.2008  \u001b[39m | \u001b[39m27.76    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m570.6    \u001b[39m |\n",
      "train_mapre: 0.1894600220186255\n",
      "test_mapre: 0.1992722867190491\n",
      "| \u001b[39m114      \u001b[39m | \u001b[39m-0.1993  \u001b[39m | \u001b[39m66.77    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m237.9    \u001b[39m |\n",
      "train_mapre: 0.18114733679637302\n",
      "test_mapre: 0.2007413841429413\n",
      "| \u001b[39m115      \u001b[39m | \u001b[39m-0.2007  \u001b[39m | \u001b[39m30.09    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m573.1    \u001b[39m |\n",
      "train_mapre: 0.45337459180608847\n",
      "test_mapre: 0.25117489975643925\n",
      "| \u001b[39m116      \u001b[39m | \u001b[39m-0.2512  \u001b[39m | \u001b[39m29.02    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m4.055    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m571.9    \u001b[39m |\n",
      "train_mapre: 0.21789341149382438\n",
      "test_mapre: 0.20328320549106324\n",
      "| \u001b[39m117      \u001b[39m | \u001b[39m-0.2033  \u001b[39m | \u001b[39m29.81    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.383    \u001b[39m | \u001b[39m570.6    \u001b[39m |\n",
      "train_mapre: 0.2895211146786055\n",
      "test_mapre: 0.21927742729947747\n",
      "| \u001b[39m118      \u001b[39m | \u001b[39m-0.2193  \u001b[39m | \u001b[39m90.75    \u001b[39m | \u001b[39m0.3263   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.012    \u001b[39m | \u001b[39m900.3    \u001b[39m |\n",
      "train_mapre: 0.4799377059508814\n",
      "test_mapre: 0.2631280128426371\n",
      "| \u001b[39m119      \u001b[39m | \u001b[39m-0.2631  \u001b[39m | \u001b[39m92.39    \u001b[39m | \u001b[39m0.4842   \u001b[39m | \u001b[39m4.534    \u001b[39m | \u001b[39m2.925    \u001b[39m | \u001b[39m901.8    \u001b[39m |\n",
      "train_mapre: 0.18304646241301606\n",
      "test_mapre: 0.20297670949691388\n",
      "| \u001b[39m120      \u001b[39m | \u001b[39m-0.203   \u001b[39m | \u001b[39m66.03    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m240.5    \u001b[39m |\n",
      "train_mapre: 0.18988557867921405\n",
      "test_mapre: 0.20002801790471708\n",
      "| \u001b[39m121      \u001b[39m | \u001b[39m-0.2     \u001b[39m | \u001b[39m29.07    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.083    \u001b[39m | \u001b[39m568.5    \u001b[39m |\n",
      "train_mapre: 0.18131603108826022\n",
      "test_mapre: 0.20071819129050913\n",
      "| \u001b[39m122      \u001b[39m | \u001b[39m-0.2007  \u001b[39m | \u001b[39m32.79    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.124    \u001b[39m | \u001b[39m571.7    \u001b[39m |\n",
      "train_mapre: 0.27126026286467597\n",
      "test_mapre: 0.2177839821355982\n",
      "| \u001b[39m123      \u001b[39m | \u001b[39m-0.2178  \u001b[39m | \u001b[39m58.8     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.627    \u001b[39m | \u001b[39m318.6    \u001b[39m |\n",
      "train_mapre: 0.24920193349013361\n",
      "test_mapre: 0.20374952314971656\n",
      "| \u001b[39m124      \u001b[39m | \u001b[39m-0.2037  \u001b[39m | \u001b[39m56.24    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.578    \u001b[39m | \u001b[39m309.8    \u001b[39m |\n",
      "train_mapre: 0.1933964019319504\n",
      "test_mapre: 0.19906577195377823\n",
      "| \u001b[39m125      \u001b[39m | \u001b[39m-0.1991  \u001b[39m | \u001b[39m58.0     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.417    \u001b[39m | \u001b[39m312.9    \u001b[39m |\n",
      "train_mapre: 0.2725653398641179\n",
      "test_mapre: 0.21836053304132194\n",
      "| \u001b[39m126      \u001b[39m | \u001b[39m-0.2184  \u001b[39m | \u001b[39m59.72    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.071    \u001b[39m | \u001b[39m311.3    \u001b[39m |\n",
      "train_mapre: 0.21736298427735842\n",
      "test_mapre: 0.20273178685871412\n",
      "| \u001b[39m127      \u001b[39m | \u001b[39m-0.2027  \u001b[39m | \u001b[39m32.79    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.147    \u001b[39m | \u001b[39m574.9    \u001b[39m |\n",
      "train_mapre: 0.18337053316544932\n",
      "test_mapre: 0.20349490224042663\n",
      "| \u001b[39m128      \u001b[39m | \u001b[39m-0.2035  \u001b[39m | \u001b[39m68.04    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m234.1    \u001b[39m |\n",
      "train_mapre: 0.18058170665821796\n",
      "test_mapre: 0.20048208373158197\n",
      "| \u001b[39m129      \u001b[39m | \u001b[39m-0.2005  \u001b[39m | \u001b[39m31.75    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m578.0    \u001b[39m |\n",
      "train_mapre: 0.24424092666528802\n",
      "test_mapre: 0.2081338178459909\n",
      "| \u001b[39m130      \u001b[39m | \u001b[39m-0.2081  \u001b[39m | \u001b[39m28.98    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.868    \u001b[39m | \u001b[39m577.7    \u001b[39m |\n",
      "train_mapre: 0.24458480627664392\n",
      "test_mapre: 0.20815615740530274\n",
      "| \u001b[39m131      \u001b[39m | \u001b[39m-0.2082  \u001b[39m | \u001b[39m33.73    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.165    \u001b[39m | \u001b[39m580.1    \u001b[39m |\n",
      "train_mapre: 0.18082657914176553\n",
      "test_mapre: 0.20049467326669068\n",
      "| \u001b[39m132      \u001b[39m | \u001b[39m-0.2005  \u001b[39m | \u001b[39m36.39    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m576.9    \u001b[39m |\n",
      "train_mapre: 0.38629552045462895\n",
      "test_mapre: 0.243857427634269\n",
      "| \u001b[39m133      \u001b[39m | \u001b[39m-0.2439  \u001b[39m | \u001b[39m35.65    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.409    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m579.7    \u001b[39m |\n",
      "train_mapre: 0.18114733679637302\n",
      "test_mapre: 0.2007413841429413\n",
      "| \u001b[39m134      \u001b[39m | \u001b[39m-0.2007  \u001b[39m | \u001b[39m37.82    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m573.1    \u001b[39m |\n",
      "train_mapre: 0.2769883088964216\n",
      "test_mapre: 0.21112206091877486\n",
      "| \u001b[39m135      \u001b[39m | \u001b[39m-0.2111  \u001b[39m | \u001b[39m38.14    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.871    \u001b[39m | \u001b[39m575.4    \u001b[39m |\n",
      "train_mapre: 0.3401599612053088\n",
      "test_mapre: 0.2309696093373639\n",
      "| \u001b[39m136      \u001b[39m | \u001b[39m-0.231   \u001b[39m | \u001b[39m20.31    \u001b[39m | \u001b[39m0.9361   \u001b[39m | \u001b[39m2.641    \u001b[39m | \u001b[39m3.1      \u001b[39m | \u001b[39m883.4    \u001b[39m |\n",
      "train_mapre: 0.18295274792833596\n",
      "test_mapre: 0.20279839772974775\n",
      "| \u001b[39m137      \u001b[39m | \u001b[39m-0.2028  \u001b[39m | \u001b[39m71.64    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m238.2    \u001b[39m |\n",
      "train_mapre: 0.2902130624803288\n",
      "test_mapre: 0.22458034954845868\n",
      "| \u001b[39m138      \u001b[39m | \u001b[39m-0.2246  \u001b[39m | \u001b[39m69.81    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.805    \u001b[39m | \u001b[39m237.0    \u001b[39m |\n",
      "train_mapre: 0.2699061396165982\n",
      "test_mapre: 0.21658657477963045\n",
      "| \u001b[39m139      \u001b[39m | \u001b[39m-0.2166  \u001b[39m | \u001b[39m23.1     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.026    \u001b[39m | \u001b[39m892.9    \u001b[39m |\n",
      "train_mapre: 0.19191551718762073\n",
      "test_mapre: 0.19981858117834067\n",
      "| \u001b[39m140      \u001b[39m | \u001b[39m-0.1998  \u001b[39m | \u001b[39m71.41    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m243.1    \u001b[39m |\n",
      "train_mapre: 0.18420768846549007\n",
      "test_mapre: 0.20245161963630992\n",
      "| \u001b[39m141      \u001b[39m | \u001b[39m-0.2025  \u001b[39m | \u001b[39m75.96    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m241.9    \u001b[39m |\n",
      "train_mapre: 0.18343722909046495\n",
      "test_mapre: 0.20258164347284538\n",
      "| \u001b[39m142      \u001b[39m | \u001b[39m-0.2026  \u001b[39m | \u001b[39m74.76    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m247.1    \u001b[39m |\n",
      "train_mapre: 0.4272718710210074\n",
      "test_mapre: 0.26740226556468716\n",
      "| \u001b[39m143      \u001b[39m | \u001b[39m-0.2674  \u001b[39m | \u001b[39m74.08    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m244.0    \u001b[39m |\n",
      "train_mapre: 0.1903625811796416\n",
      "test_mapre: 0.19938924766696142\n",
      "| \u001b[39m144      \u001b[39m | \u001b[39m-0.1994  \u001b[39m | \u001b[39m69.76    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m247.8    \u001b[39m |\n",
      "train_mapre: 0.2908897586238313\n",
      "test_mapre: 0.22442428577736\n",
      "| \u001b[39m145      \u001b[39m | \u001b[39m-0.2244  \u001b[39m | \u001b[39m71.73    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.748    \u001b[39m | \u001b[39m247.6    \u001b[39m |\n",
      "train_mapre: 0.18100109324527877\n",
      "test_mapre: 0.20053786255265582\n",
      "| \u001b[39m146      \u001b[39m | \u001b[39m-0.2005  \u001b[39m | \u001b[39m41.68    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m575.6    \u001b[39m |\n",
      "train_mapre: 0.18228081160039597\n",
      "test_mapre: 0.20197854185448275\n",
      "| \u001b[39m147      \u001b[39m | \u001b[39m-0.202   \u001b[39m | \u001b[39m72.56    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m251.7    \u001b[39m |\n",
      "train_mapre: 0.18228081160039597\n",
      "test_mapre: 0.20197854185448275\n",
      "| \u001b[39m148      \u001b[39m | \u001b[39m-0.202   \u001b[39m | \u001b[39m67.25    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m252.0    \u001b[39m |\n",
      "train_mapre: 0.18150845860093603\n",
      "test_mapre: 0.20077158113934163\n",
      "| \u001b[39m149      \u001b[39m | \u001b[39m-0.2008  \u001b[39m | \u001b[39m43.49    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m571.3    \u001b[39m |\n",
      "train_mapre: 0.19229435284182483\n",
      "test_mapre: 0.19868900763761474\n",
      "| \u001b[35m150      \u001b[39m | \u001b[35m-0.1987  \u001b[39m | \u001b[35m47.12    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m574.7    \u001b[39m |\n",
      "train_mapre: 0.2879339591792343\n",
      "test_mapre: 0.21652813388758935\n",
      "| \u001b[39m151      \u001b[39m | \u001b[39m-0.2165  \u001b[39m | \u001b[39m45.39    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.159    \u001b[39m | \u001b[39m573.9    \u001b[39m |\n",
      "train_mapre: 0.4305796403930095\n",
      "test_mapre: 0.26210396124961555\n",
      "| \u001b[39m152      \u001b[39m | \u001b[39m-0.2621  \u001b[39m | \u001b[39m45.41    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m573.6    \u001b[39m |\n",
      "train_mapre: 0.1921698714416663\n",
      "test_mapre: 0.19870415679991105\n",
      "| \u001b[39m153      \u001b[39m | \u001b[39m-0.1987  \u001b[39m | \u001b[39m47.06    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m579.0    \u001b[39m |\n",
      "train_mapre: 0.189725216767806\n",
      "test_mapre: 0.19896037492883067\n",
      "| \u001b[39m154      \u001b[39m | \u001b[39m-0.199   \u001b[39m | \u001b[39m64.8     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m247.0    \u001b[39m |\n",
      "train_mapre: 0.19192643670503573\n",
      "test_mapre: 0.19868121874980096\n",
      "| \u001b[35m155      \u001b[39m | \u001b[35m-0.1987  \u001b[39m | \u001b[35m51.34    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m577.2    \u001b[39m |\n",
      "train_mapre: 0.28744567725619846\n",
      "test_mapre: 0.21673094973934512\n",
      "| \u001b[39m156      \u001b[39m | \u001b[39m-0.2167  \u001b[39m | \u001b[39m50.06    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.927    \u001b[39m | \u001b[39m579.3    \u001b[39m |\n",
      "train_mapre: 0.19060807005152383\n",
      "test_mapre: 0.1995919729315162\n",
      "| \u001b[39m157      \u001b[39m | \u001b[39m-0.1996  \u001b[39m | \u001b[39m61.47    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m251.1    \u001b[39m |\n",
      "train_mapre: 0.2751007020241288\n",
      "test_mapre: 0.21313389971908675\n",
      "| \u001b[39m158      \u001b[39m | \u001b[39m-0.2131  \u001b[39m | \u001b[39m63.2     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.211    \u001b[39m | \u001b[39m250.3    \u001b[39m |\n",
      "train_mapre: 0.5102946595878411\n",
      "test_mapre: 0.2669682871699198\n",
      "| \u001b[39m159      \u001b[39m | \u001b[39m-0.267   \u001b[39m | \u001b[39m63.77    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m250.9    \u001b[39m |\n",
      "train_mapre: 0.18691235082689828\n",
      "test_mapre: 0.2034090791799251\n",
      "| \u001b[39m160      \u001b[39m | \u001b[39m-0.2034  \u001b[39m | \u001b[39m59.6     \u001b[39m | \u001b[39m0.8732   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m246.9    \u001b[39m |\n",
      "train_mapre: 0.19241301255629198\n",
      "test_mapre: 0.1988454435117879\n",
      "| \u001b[39m161      \u001b[39m | \u001b[39m-0.1988  \u001b[39m | \u001b[39m40.38    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m568.5    \u001b[39m |\n",
      "train_mapre: 0.19226370329660677\n",
      "test_mapre: 0.19869330047042896\n",
      "| \u001b[39m162      \u001b[39m | \u001b[39m-0.1987  \u001b[39m | \u001b[39m52.09    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m572.5    \u001b[39m |\n",
      "train_mapre: 0.19229435284182483\n",
      "test_mapre: 0.19868900763761474\n",
      "| \u001b[39m163      \u001b[39m | \u001b[39m-0.1987  \u001b[39m | \u001b[39m56.5     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m574.7    \u001b[39m |\n",
      "train_mapre: 0.2768365602265858\n",
      "test_mapre: 0.21120317670536326\n",
      "| \u001b[39m164      \u001b[39m | \u001b[39m-0.2112  \u001b[39m | \u001b[39m54.97    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.164    \u001b[39m | \u001b[39m573.2    \u001b[39m |\n",
      "train_mapre: 0.21234849463566172\n",
      "test_mapre: 0.2039717215935182\n",
      "| \u001b[39m165      \u001b[39m | \u001b[39m-0.204   \u001b[39m | \u001b[39m56.4     \u001b[39m | \u001b[39m0.3913   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.572    \u001b[39m | \u001b[39m251.9    \u001b[39m |\n",
      "train_mapre: 0.19242840163707314\n",
      "test_mapre: 0.19893394003837064\n",
      "| \u001b[39m166      \u001b[39m | \u001b[39m-0.1989  \u001b[39m | \u001b[39m57.41    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m569.5    \u001b[39m |\n",
      "train_mapre: 0.502649427317624\n",
      "test_mapre: 0.266016039825426\n",
      "| \u001b[39m167      \u001b[39m | \u001b[39m-0.266   \u001b[39m | \u001b[39m58.84    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m572.1    \u001b[39m |\n",
      "train_mapre: 0.1925106003394482\n",
      "test_mapre: 0.19857462856222446\n",
      "| \u001b[35m168      \u001b[39m | \u001b[35m-0.1986  \u001b[39m | \u001b[35m53.84    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m567.1    \u001b[39m |\n",
      "train_mapre: 0.19212439446810026\n",
      "test_mapre: 0.19890007215357797\n",
      "| \u001b[39m169      \u001b[39m | \u001b[39m-0.1989  \u001b[39m | \u001b[39m55.98    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m579.7    \u001b[39m |\n",
      "train_mapre: 0.18169442838002514\n",
      "test_mapre: 0.20100373409509462\n",
      "| \u001b[39m170      \u001b[39m | \u001b[39m-0.201   \u001b[39m | \u001b[39m57.93    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m564.4    \u001b[39m |\n",
      "train_mapre: 0.28748243019675196\n",
      "test_mapre: 0.21663456682074403\n",
      "| \u001b[39m171      \u001b[39m | \u001b[39m-0.2166  \u001b[39m | \u001b[39m56.41    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.145    \u001b[39m | \u001b[39m566.3    \u001b[39m |\n",
      "train_mapre: 0.3091098437068371\n",
      "test_mapre: 0.2274054364197428\n",
      "| \u001b[39m172      \u001b[39m | \u001b[39m-0.2274  \u001b[39m | \u001b[39m56.38    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.123    \u001b[39m | \u001b[39m248.7    \u001b[39m |\n",
      "train_mapre: 0.18429027274675053\n",
      "test_mapre: 0.2021260703455612\n",
      "| \u001b[39m173      \u001b[39m | \u001b[39m-0.2021  \u001b[39m | \u001b[39m59.18    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m256.5    \u001b[39m |\n",
      "train_mapre: 0.1841052720504258\n",
      "test_mapre: 0.19966840671990427\n",
      "| \u001b[39m174      \u001b[39m | \u001b[39m-0.1997  \u001b[39m | \u001b[39m53.58    \u001b[39m | \u001b[39m0.7375   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m257.8    \u001b[39m |\n",
      "train_mapre: 0.30996200092088433\n",
      "test_mapre: 0.22666625123852524\n",
      "| \u001b[39m175      \u001b[39m | \u001b[39m-0.2267  \u001b[39m | \u001b[39m56.04    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.587    \u001b[39m | \u001b[39m258.5    \u001b[39m |\n",
      "train_mapre: 0.1824281504924581\n",
      "test_mapre: 0.2023734315938304\n",
      "| \u001b[39m176      \u001b[39m | \u001b[39m-0.2024  \u001b[39m | \u001b[39m49.86    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m254.1    \u001b[39m |\n",
      "train_mapre: 0.18305930790658603\n",
      "test_mapre: 0.20178893730645864\n",
      "| \u001b[39m177      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m48.16    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m259.7    \u001b[39m |\n",
      "train_mapre: 0.4287253246911519\n",
      "test_mapre: 0.26758201707706125\n",
      "| \u001b[39m178      \u001b[39m | \u001b[39m-0.2676  \u001b[39m | \u001b[39m50.48    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m257.4    \u001b[39m |\n",
      "train_mapre: 0.18429027274675053\n",
      "test_mapre: 0.2021260703455612\n",
      "| \u001b[39m179      \u001b[39m | \u001b[39m-0.2021  \u001b[39m | \u001b[39m69.88    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m256.9    \u001b[39m |\n",
      "train_mapre: 0.18429027274675053\n",
      "test_mapre: 0.2021260703455612\n",
      "| \u001b[39m180      \u001b[39m | \u001b[39m-0.2021  \u001b[39m | \u001b[39m75.5     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m256.9    \u001b[39m |\n",
      "train_mapre: 0.2758752096729974\n",
      "test_mapre: 0.21284640788419848\n",
      "| \u001b[39m181      \u001b[39m | \u001b[39m-0.2128  \u001b[39m | \u001b[39m72.7     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.461    \u001b[39m | \u001b[39m256.7    \u001b[39m |\n",
      "train_mapre: 0.1822853644002962\n",
      "test_mapre: 0.19960727458658417\n",
      "| \u001b[39m182      \u001b[39m | \u001b[39m-0.1996  \u001b[39m | \u001b[39m78.68    \u001b[39m | \u001b[39m0.7952   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m251.8    \u001b[39m |\n",
      "train_mapre: 0.24677554232872603\n",
      "test_mapre: 0.20925526500307595\n",
      "| \u001b[39m183      \u001b[39m | \u001b[39m-0.2093  \u001b[39m | \u001b[39m80.84    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m4.752    \u001b[39m | \u001b[39m256.0    \u001b[39m |\n",
      "train_mapre: 0.1902454965404858\n",
      "test_mapre: 0.1990934563889332\n",
      "| \u001b[39m184      \u001b[39m | \u001b[39m-0.1991  \u001b[39m | \u001b[39m81.2     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m246.4    \u001b[39m |\n",
      "train_mapre: 0.18959492450333865\n",
      "test_mapre: 0.19986429447777748\n",
      "| \u001b[39m185      \u001b[39m | \u001b[39m-0.1999  \u001b[39m | \u001b[39m81.89    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m240.5    \u001b[39m |\n",
      "train_mapre: 0.19438910594330158\n",
      "test_mapre: 0.2036833650397781\n",
      "| \u001b[39m186      \u001b[39m | \u001b[39m-0.2037  \u001b[39m | \u001b[39m86.56    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.507    \u001b[39m | \u001b[39m244.1    \u001b[39m |\n",
      "train_mapre: 0.18270496575531944\n",
      "test_mapre: 0.2023740983474647\n",
      "| \u001b[39m187      \u001b[39m | \u001b[39m-0.2024  \u001b[39m | \u001b[39m85.31    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m250.8    \u001b[39m |\n",
      "train_mapre: 0.29654325394509784\n",
      "test_mapre: 0.21610251249050433\n",
      "| \u001b[39m188      \u001b[39m | \u001b[39m-0.2161  \u001b[39m | \u001b[39m83.41    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.139    \u001b[39m | \u001b[39m247.7    \u001b[39m |\n",
      "train_mapre: 0.18953564838503534\n",
      "test_mapre: 0.20413658384563288\n",
      "| \u001b[39m189      \u001b[39m | \u001b[39m-0.2041  \u001b[39m | \u001b[39m45.96    \u001b[39m | \u001b[39m0.6281   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m265.2    \u001b[39m |\n",
      "train_mapre: 0.18341413258458547\n",
      "test_mapre: 0.20271387871486019\n",
      "| \u001b[39m190      \u001b[39m | \u001b[39m-0.2027  \u001b[39m | \u001b[39m87.17    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m236.9    \u001b[39m |\n",
      "train_mapre: 0.18306008054577788\n",
      "test_mapre: 0.20324655126785734\n",
      "| \u001b[39m191      \u001b[39m | \u001b[39m-0.2032  \u001b[39m | \u001b[39m80.05    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m234.7    \u001b[39m |\n",
      "train_mapre: 0.2953737151924838\n",
      "test_mapre: 0.21670028468072305\n",
      "| \u001b[39m192      \u001b[39m | \u001b[39m-0.2167  \u001b[39m | \u001b[39m83.75    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.205    \u001b[39m | \u001b[39m237.4    \u001b[39m |\n",
      "train_mapre: 0.5097732505531513\n",
      "test_mapre: 0.26721747655637046\n",
      "| \u001b[39m193      \u001b[39m | \u001b[39m-0.2672  \u001b[39m | \u001b[39m91.01    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m240.4    \u001b[39m |\n",
      "train_mapre: 0.18387533655484326\n",
      "test_mapre: 0.20279986984142315\n",
      "| \u001b[39m194      \u001b[39m | \u001b[39m-0.2028  \u001b[39m | \u001b[39m85.45    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m231.4    \u001b[39m |\n",
      "train_mapre: 0.18453546239634794\n",
      "test_mapre: 0.20210429966377894\n",
      "| \u001b[39m195      \u001b[39m | \u001b[39m-0.2021  \u001b[39m | \u001b[39m42.47    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m260.6    \u001b[39m |\n",
      "train_mapre: 0.298157186611655\n",
      "test_mapre: 0.2157459678195536\n",
      "| \u001b[39m196      \u001b[39m | \u001b[39m-0.2157  \u001b[39m | \u001b[39m44.87    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.102    \u001b[39m | \u001b[39m262.3    \u001b[39m |\n",
      "train_mapre: 0.1835996461647179\n",
      "test_mapre: 0.20178669870032717\n",
      "| \u001b[39m197      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m72.68    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m263.4    \u001b[39m |\n",
      "train_mapre: 0.5124849111367571\n",
      "test_mapre: 0.268000968316102\n",
      "| \u001b[39m198      \u001b[39m | \u001b[39m-0.268   \u001b[39m | \u001b[39m77.39    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m262.2    \u001b[39m |\n",
      "train_mapre: 0.1835996461647179\n",
      "test_mapre: 0.20178669870032717\n",
      "| \u001b[39m199      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m67.27    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m263.3    \u001b[39m |\n",
      "train_mapre: 0.29870159984067696\n",
      "test_mapre: 0.21507290169377966\n",
      "| \u001b[39m200      \u001b[39m | \u001b[39m-0.2151  \u001b[39m | \u001b[39m69.67    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.625    \u001b[39m | \u001b[39m265.4    \u001b[39m |\n",
      "train_mapre: 0.18576445581412226\n",
      "test_mapre: 0.2022669821590162\n",
      "| \u001b[39m201      \u001b[39m | \u001b[39m-0.2023  \u001b[39m | \u001b[39m69.44    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m269.3    \u001b[39m |\n",
      "train_mapre: 0.2005020787170719\n",
      "test_mapre: 0.20747946827402042\n",
      "| \u001b[39m202      \u001b[39m | \u001b[39m-0.2075  \u001b[39m | \u001b[39m62.83    \u001b[39m | \u001b[39m0.4283   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m268.8    \u001b[39m |\n",
      "train_mapre: 0.3341106838199749\n",
      "test_mapre: 0.23233472107070735\n",
      "| \u001b[39m203      \u001b[39m | \u001b[39m-0.2323  \u001b[39m | \u001b[39m66.16    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.087    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m275.0    \u001b[39m |\n",
      "train_mapre: 0.1835979343696559\n",
      "test_mapre: 0.20150936452359247\n",
      "| \u001b[39m204      \u001b[39m | \u001b[39m-0.2015  \u001b[39m | \u001b[39m54.29    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m265.2    \u001b[39m |\n",
      "train_mapre: 0.1883270810017432\n",
      "test_mapre: 0.20390316711548626\n",
      "| \u001b[39m205      \u001b[39m | \u001b[39m-0.2039  \u001b[39m | \u001b[39m51.71    \u001b[39m | \u001b[39m0.9326   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m270.9    \u001b[39m |\n",
      "train_mapre: 0.3087197122404969\n",
      "test_mapre: 0.2235901220908965\n",
      "| \u001b[39m206      \u001b[39m | \u001b[39m-0.2236  \u001b[39m | \u001b[39m55.98    \u001b[39m | \u001b[39m0.5765   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.609    \u001b[39m | \u001b[39m269.8    \u001b[39m |\n",
      "train_mapre: 0.18504308319516416\n",
      "test_mapre: 0.2021302496527712\n",
      "| \u001b[39m207      \u001b[39m | \u001b[39m-0.2021  \u001b[39m | \u001b[39m45.05    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m272.9    \u001b[39m |\n",
      "train_mapre: 0.18789190194298702\n",
      "test_mapre: 0.20229408500125737\n",
      "| \u001b[39m208      \u001b[39m | \u001b[39m-0.2023  \u001b[39m | \u001b[39m49.02    \u001b[39m | \u001b[39m0.8464   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m277.9    \u001b[39m |\n",
      "train_mapre: 0.5141655531813337\n",
      "test_mapre: 0.26917429017970357\n",
      "| \u001b[39m209      \u001b[39m | \u001b[39m-0.2692  \u001b[39m | \u001b[39m47.7     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m5.278    \u001b[39m | \u001b[39m274.7    \u001b[39m |\n",
      "train_mapre: 0.18576445581412226\n",
      "test_mapre: 0.2022669821590162\n",
      "| \u001b[39m210      \u001b[39m | \u001b[39m-0.2023  \u001b[39m | \u001b[39m39.99    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m268.5    \u001b[39m |\n",
      "train_mapre: 0.1851458359382261\n",
      "test_mapre: 0.20235511465358408\n",
      "| \u001b[39m211      \u001b[39m | \u001b[39m-0.2024  \u001b[39m | \u001b[39m38.99    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m274.9    \u001b[39m |\n",
      "train_mapre: 0.18496245943151132\n",
      "test_mapre: 0.20232717476161544\n",
      "| \u001b[39m212      \u001b[39m | \u001b[39m-0.2023  \u001b[39m | \u001b[39m33.65    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m271.1    \u001b[39m |\n",
      "train_mapre: 0.2994995699298712\n",
      "test_mapre: 0.2155505386241494\n",
      "| \u001b[39m213      \u001b[39m | \u001b[39m-0.2156  \u001b[39m | \u001b[39m36.35    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.264    \u001b[39m | \u001b[39m271.3    \u001b[39m |\n",
      "train_mapre: 0.18494908076664116\n",
      "test_mapre: 0.19983201486722385\n",
      "| \u001b[39m214      \u001b[39m | \u001b[39m-0.1998  \u001b[39m | \u001b[39m32.35    \u001b[39m | \u001b[39m0.8151   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m277.5    \u001b[39m |\n",
      "train_mapre: 0.5141655531813337\n",
      "test_mapre: 0.26917429017970357\n",
      "| \u001b[39m215      \u001b[39m | \u001b[39m-0.2692  \u001b[39m | \u001b[39m34.04    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m274.8    \u001b[39m |\n",
      "train_mapre: 0.1835996461647179\n",
      "test_mapre: 0.20178669870032717\n",
      "| \u001b[39m216      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m60.17    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m262.9    \u001b[39m |\n",
      "train_mapre: 0.1841419149810673\n",
      "test_mapre: 0.2016360159756437\n",
      "| \u001b[39m217      \u001b[39m | \u001b[39m-0.2016  \u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m282.0    \u001b[39m |\n",
      "train_mapre: 0.1843430679760797\n",
      "test_mapre: 0.20184769388132598\n",
      "| \u001b[39m218      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m26.92    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m277.3    \u001b[39m |\n",
      "train_mapre: 0.2986052517967622\n",
      "test_mapre: 0.21500675408047787\n",
      "| \u001b[39m219      \u001b[39m | \u001b[39m-0.215   \u001b[39m | \u001b[39m29.63    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.722    \u001b[39m | \u001b[39m279.1    \u001b[39m |\n",
      "train_mapre: 0.1841419149810673\n",
      "test_mapre: 0.2016360159756437\n",
      "| \u001b[39m220      \u001b[39m | \u001b[39m-0.2016  \u001b[39m | \u001b[39m36.59    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m282.2    \u001b[39m |\n",
      "train_mapre: 0.18408595469540712\n",
      "test_mapre: 0.20193894416515465\n",
      "| \u001b[39m221      \u001b[39m | \u001b[39m-0.2019  \u001b[39m | \u001b[39m43.07    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m280.4    \u001b[39m |\n",
      "train_mapre: 0.1835979343696559\n",
      "test_mapre: 0.20150936452359247\n",
      "| \u001b[39m222      \u001b[39m | \u001b[39m-0.2015  \u001b[39m | \u001b[39m34.33    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m265.2    \u001b[39m |\n",
      "train_mapre: 0.1852505793885845\n",
      "test_mapre: 0.2019392018237297\n",
      "| \u001b[39m223      \u001b[39m | \u001b[39m-0.2019  \u001b[39m | \u001b[39m28.13    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m268.2    \u001b[39m |\n",
      "train_mapre: 0.18461184883365792\n",
      "test_mapre: 0.20175016339170093\n",
      "| \u001b[39m224      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m48.89    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m284.3    \u001b[39m |\n",
      "train_mapre: 0.18552220847371276\n",
      "test_mapre: 0.20165988328460008\n",
      "| \u001b[39m225      \u001b[39m | \u001b[39m-0.2017  \u001b[39m | \u001b[39m42.36    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m287.4    \u001b[39m |\n",
      "train_mapre: 0.3178254490573721\n",
      "test_mapre: 0.22241260659990503\n",
      "| \u001b[39m226      \u001b[39m | \u001b[39m-0.2224  \u001b[39m | \u001b[39m44.04    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.546    \u001b[39m | \u001b[39m285.8    \u001b[39m |\n",
      "train_mapre: 0.1856055060521593\n",
      "test_mapre: 0.20186597665017106\n",
      "| \u001b[39m227      \u001b[39m | \u001b[39m-0.2019  \u001b[39m | \u001b[39m35.35    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m289.1    \u001b[39m |\n",
      "train_mapre: 0.4711065009994511\n",
      "test_mapre: 0.26646877088085413\n",
      "| \u001b[39m228      \u001b[39m | \u001b[39m-0.2665  \u001b[39m | \u001b[39m39.71    \u001b[39m | \u001b[39m0.6037   \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m292.3    \u001b[39m |\n",
      "train_mapre: 0.1856055060521593\n",
      "test_mapre: 0.20186597665017106\n",
      "| \u001b[39m229      \u001b[39m | \u001b[39m-0.2019  \u001b[39m | \u001b[39m29.52    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m288.7    \u001b[39m |\n",
      "train_mapre: 0.18360749994692344\n",
      "test_mapre: 0.20186877174291504\n",
      "| \u001b[39m230      \u001b[39m | \u001b[39m-0.2019  \u001b[39m | \u001b[39m54.6     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m281.2    \u001b[39m |\n",
      "train_mapre: 0.2776592436423188\n",
      "test_mapre: 0.2125670435703543\n",
      "| \u001b[39m231      \u001b[39m | \u001b[39m-0.2126  \u001b[39m | \u001b[39m33.14    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.304    \u001b[39m | \u001b[39m286.5    \u001b[39m |\n",
      "train_mapre: 0.18461184883365792\n",
      "test_mapre: 0.20175016339170093\n",
      "| \u001b[39m232      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m23.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m284.4    \u001b[39m |\n",
      "train_mapre: 0.46619425716144314\n",
      "test_mapre: 0.25936358597298736\n",
      "| \u001b[39m233      \u001b[39m | \u001b[39m-0.2594  \u001b[39m | \u001b[39m23.31    \u001b[39m | \u001b[39m0.7115   \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m289.6    \u001b[39m |\n",
      "train_mapre: 0.183508842976343\n",
      "test_mapre: 0.20180792714420528\n",
      "| \u001b[39m234      \u001b[39m | \u001b[39m-0.2018  \u001b[39m | \u001b[39m20.37    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m279.2    \u001b[39m |\n",
      "train_mapre: 0.18538293793118604\n",
      "test_mapre: 0.20216655191505598\n",
      "| \u001b[39m235      \u001b[39m | \u001b[39m-0.2022  \u001b[39m | \u001b[39m21.8     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m271.9    \u001b[39m |\n",
      "train_mapre: 0.3167146776812442\n",
      "test_mapre: 0.22295993076063758\n",
      "| \u001b[39m236      \u001b[39m | \u001b[39m-0.223   \u001b[39m | \u001b[39m21.31    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.597    \u001b[39m | \u001b[39m275.2    \u001b[39m |\n",
      "train_mapre: 0.18903639056584406\n",
      "test_mapre: 0.19890699293307806\n",
      "| \u001b[39m237      \u001b[39m | \u001b[39m-0.1989  \u001b[39m | \u001b[39m21.62    \u001b[39m | \u001b[39m0.6789   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m265.1    \u001b[39m |\n",
      "train_mapre: 0.2987513408696274\n",
      "test_mapre: 0.21490448284207836\n",
      "| \u001b[39m238      \u001b[39m | \u001b[39m-0.2149  \u001b[39m | \u001b[39m24.46    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.126    \u001b[39m | \u001b[39m265.7    \u001b[39m |\n",
      "train_mapre: 0.18864520067301785\n",
      "test_mapre: 0.20168738846704126\n",
      "| \u001b[39m239      \u001b[39m | \u001b[39m-0.2017  \u001b[39m | \u001b[39m55.26    \u001b[39m | \u001b[39m0.8352   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m288.0    \u001b[39m |\n",
      "train_mapre: 0.3178254490573721\n",
      "test_mapre: 0.22241260659990503\n",
      "| \u001b[39m240      \u001b[39m | \u001b[39m-0.2224  \u001b[39m | \u001b[39m55.64    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m7.607    \u001b[39m | \u001b[39m285.5    \u001b[39m |\n",
      "train_mapre: 0.1834051136556838\n",
      "test_mapre: 0.2017251448882536\n",
      "| \u001b[39m241      \u001b[39m | \u001b[39m-0.2017  \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m259.1    \u001b[39m |\n",
      "train_mapre: 0.4290839230361693\n",
      "test_mapre: 0.26718091782230496\n",
      "| \u001b[39m242      \u001b[39m | \u001b[39m-0.2672  \u001b[39m | \u001b[39m24.12    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m261.9    \u001b[39m |\n",
      "train_mapre: 0.19339364605446902\n",
      "test_mapre: 0.1983951619096918\n",
      "| \u001b[35m243      \u001b[39m | \u001b[35m-0.1984  \u001b[39m | \u001b[35m57.58    \u001b[39m | \u001b[35m0.3      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m294.0    \u001b[39m |\n",
      "train_mapre: 0.19385234828559067\n",
      "test_mapre: 0.1986245655122874\n",
      "| \u001b[39m244      \u001b[39m | \u001b[39m-0.1986  \u001b[39m | \u001b[39m52.0     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m293.0    \u001b[39m |\n",
      "train_mapre: 0.4319901025541171\n",
      "test_mapre: 0.2656584004221397\n",
      "| \u001b[39m245      \u001b[39m | \u001b[39m-0.2657  \u001b[39m | \u001b[39m55.1     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m292.2    \u001b[39m |\n",
      "train_mapre: 0.194598667384242\n",
      "test_mapre: 0.1987698092419577\n",
      "| \u001b[39m246      \u001b[39m | \u001b[39m-0.1988  \u001b[39m | \u001b[39m61.62    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m297.1    \u001b[39m |\n",
      "train_mapre: 0.19420494583256123\n",
      "test_mapre: 0.19860985497657474\n",
      "| \u001b[39m247      \u001b[39m | \u001b[39m-0.1986  \u001b[39m | \u001b[39m62.6     \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m291.8    \u001b[39m |\n",
      "train_mapre: 0.29538261738709964\n",
      "test_mapre: 0.22249093327981292\n",
      "| \u001b[39m248      \u001b[39m | \u001b[39m-0.2225  \u001b[39m | \u001b[39m61.05    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m6.43     \u001b[39m | \u001b[39m294.5    \u001b[39m |\n",
      "train_mapre: 0.42938996974889154\n",
      "test_mapre: 0.2667458830858455\n",
      "| \u001b[39m249      \u001b[39m | \u001b[39m-0.2667  \u001b[39m | \u001b[39m64.05    \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m265.1    \u001b[39m |\n",
      "train_mapre: 0.46426018382827394\n",
      "test_mapre: 0.25447748411192384\n",
      "| \u001b[39m250      \u001b[39m | \u001b[39m-0.2545  \u001b[39m | \u001b[39m24.13    \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m3.839    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m280.5    \u001b[39m |\n",
      "=====================================================================================\n",
      "Running time: 0:01:38.847583\n",
      "       target  n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0   -0.200911    317.404713  53.361760           4.418661          1.000457   \n",
      "1   -0.217315    631.053387  27.387088           5.174140          2.382243   \n",
      "2   -0.228883    221.910075  53.535561           9.024939          1.817809   \n",
      "3   -0.230548    358.481191  73.637401           3.123096          3.234759   \n",
      "4   -0.224162    901.111322  84.059565           7.538581          2.253697   \n",
      "..        ...           ...        ...                ...               ...   \n",
      "246 -0.198610    291.815754  62.599344           2.000000          1.000000   \n",
      "247 -0.222491    294.492787  61.046940           6.430337          1.000000   \n",
      "248 -0.266746    265.122372  64.054303           2.000000          5.000000   \n",
      "249 -0.254477    280.501327  24.133185           2.000000          3.839290   \n",
      "250 -0.198395    293.988442  57.583972           2.000000          1.000000   \n",
      "\n",
      "     max_features  \n",
      "0        0.804227  \n",
      "1        0.430382  \n",
      "2        0.779654  \n",
      "3        0.592113  \n",
      "4        0.977783  \n",
      "..            ...  \n",
      "246      0.300000  \n",
      "247      0.300000  \n",
      "248      1.000000  \n",
      "249      0.300000  \n",
      "250      0.300000  \n",
      "\n",
      "[251 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(1)\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "t = time.localtime()\n",
    "model_name = 'd33_inference_RandomForest'\n",
    "file_name = '{}.xlsx'.format(model_name)\n",
    "data =  pd.read_excel('data-1.xlsx')\n",
    "\n",
    "x_all, y_all, train_features, test_features, train_labels, test_labels = normalizing_data(data, seed=1)\n",
    "train_features, test_features = train_features.cpu().data.numpy(), test_features.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.cpu().data.numpy(), test_labels.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.reshape(-1), test_labels.reshape(-1) \n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def train_model(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features):\n",
    "    params = {\n",
    "        \"n_estimators\": int(round(n_estimators)),\n",
    "        \"max_depth\": int(round(max_depth)),\n",
    "        \"min_samples_split\": int(round(min_samples_split)),\n",
    "        \"min_samples_leaf\": int(round(min_samples_leaf)),\n",
    "        \"max_features\": max(min(max_features, 1), 0),\n",
    "        \"random_state\": 1\n",
    "    }\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(train_features, train_labels)\n",
    "    y_pred_train = model.predict(train_features)\n",
    "    y_pred_test = model.predict(test_features)\n",
    "    train_mape = mean_absolute_percentage_error(train_labels, y_pred_train)\n",
    "    test_mape = mean_absolute_percentage_error(test_labels, y_pred_test)\n",
    "    print(\"train_mapre:\", train_mape)\n",
    "    print(\"test_mapre:\", test_mape)\n",
    "    error = -test_mape\n",
    "    return error\n",
    "\n",
    "\n",
    "bounds = {\n",
    "    'n_estimators': (200, 1000), \n",
    "    'max_depth': (20, 100), \n",
    "    'min_samples_split': (2, 10), \n",
    "    'min_samples_leaf': (1, 5), \n",
    "    'max_features': (0.3, 1) \n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_model,\n",
    "    pbounds=bounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer.maximize(init_points=100, n_iter=150)\n",
    "\n",
    "\n",
    "table = pd.DataFrame(columns=['target', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features'])\n",
    "result_list = []\n",
    "\n",
    "for res in optimizer.res:\n",
    "    result_list.append(pd.DataFrame({'target': [res['target']],\n",
    "                                     'n_estimators': [res['params']['n_estimators']],\n",
    "                                     'max_depth': [res['params']['max_depth']],\n",
    "                                     'min_samples_split': [res['params']['min_samples_split']],\n",
    "                                     'min_samples_leaf': [res['params']['min_samples_leaf']],\n",
    "                                     'max_features': [res['params']['max_features']]}))\n",
    "\n",
    "\n",
    "table = pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "\n",
    "best_result = pd.DataFrame({'target': [optimizer.max['target']],\n",
    "                            'n_estimators': [optimizer.max['params']['n_estimators']],\n",
    "                            'max_depth': [optimizer.max['params']['max_depth']],\n",
    "                            'min_samples_split': [optimizer.max['params']['min_samples_split']],\n",
    "                            'min_samples_leaf': [optimizer.max['params']['min_samples_leaf']],\n",
    "                            'max_features': [optimizer.max['params']['max_features']]})\n",
    "\n",
    "\n",
    "table = pd.concat([table, best_result], ignore_index=True)\n",
    "\n",
    "\n",
    "table.to_excel(file_name)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print('Running time: {}'.format(endtime - starttime))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a9374-616d-40a1-83ca-2e256f7a41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ba        Ca   Sr     Ti     Zr        Sn    Hf         W  \\\n",
      "0    1.000000  0.000000  0.0  1.000  0.000  0.000000  0.00  1.000000   \n",
      "1    1.000000  0.000000  0.0  0.950  0.050  0.000000  0.00  0.978718   \n",
      "2    1.000000  0.000000  0.0  0.950  0.000  0.071429  0.00  0.965424   \n",
      "3    1.000000  0.000000  0.0  0.925  0.075  0.000000  0.00  0.968220   \n",
      "4    1.000000  0.000000  0.0  0.900  0.000  0.000000  0.10  0.877303   \n",
      "..        ...       ...  ...    ...    ...       ...   ...       ...   \n",
      "149  0.333333  0.666667  0.0  1.000  0.000  0.000000  0.00  0.664214   \n",
      "150  0.333333  0.666667  0.0  0.500  0.500  0.000000  0.00  0.495194   \n",
      "151  0.333333  0.666667  0.0  0.500  0.000  0.000000  0.50  0.227934   \n",
      "152  0.200000  0.800000  0.0  0.840  0.000  0.000000  0.16  0.439015   \n",
      "153  0.000000  1.000000  0.0  1.000  0.000  0.000000  0.00  0.496321   \n",
      "\n",
      "           EI        EA         μ  \n",
      "0    0.885689  0.786531  0.000000  \n",
      "1    0.892040  0.765946  0.016596  \n",
      "2    0.868796  0.725267  0.027117  \n",
      "3    0.895215  0.755653  0.024894  \n",
      "4    0.885886  0.783581  0.100000  \n",
      "..        ...       ...       ...  \n",
      "149  0.295230  0.928844  0.000000  \n",
      "150  0.358736  0.722994  0.165962  \n",
      "151  0.296214  0.914096  0.500000  \n",
      "152  0.177453  0.952587  0.160000  \n",
      "153  0.000000  1.000000  0.000000  \n",
      "\n",
      "[154 rows x 11 columns]\n",
      "     d33(pC/N)\n",
      "0          190\n",
      "1          273\n",
      "2          250\n",
      "3          317\n",
      "4          361\n",
      "..         ...\n",
      "149        123\n",
      "150        421\n",
      "151        288\n",
      "152        135\n",
      "153        106\n",
      "\n",
      "[154 rows x 1 columns]\n",
      "tensor([[190.],\n",
      "        [273.],\n",
      "        [250.],\n",
      "        [317.],\n",
      "        [361.],\n",
      "        [343.],\n",
      "        [334.],\n",
      "        [400.],\n",
      "        [272.],\n",
      "        [409.],\n",
      "        [294.],\n",
      "        [275.],\n",
      "        [361.],\n",
      "        [201.],\n",
      "        [308.],\n",
      "        [225.],\n",
      "        [384.],\n",
      "        [193.],\n",
      "        [183.],\n",
      "        [346.],\n",
      "        [165.],\n",
      "        [197.],\n",
      "        [125.],\n",
      "        [312.],\n",
      "        [210.],\n",
      "        [118.],\n",
      "        [390.],\n",
      "        [437.],\n",
      "        [435.],\n",
      "        [358.],\n",
      "        [465.],\n",
      "        [446.],\n",
      "        [451.],\n",
      "        [428.],\n",
      "        [441.],\n",
      "        [508.],\n",
      "        [237.],\n",
      "        [627.],\n",
      "        [440.],\n",
      "        [400.],\n",
      "        [440.],\n",
      "        [532.],\n",
      "        [152.],\n",
      "        [635.],\n",
      "        [520.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [282.],\n",
      "        [338.],\n",
      "        [305.],\n",
      "        [283.],\n",
      "        [249.],\n",
      "        [264.],\n",
      "        [182.],\n",
      "        [140.],\n",
      "        [187.],\n",
      "        [543.],\n",
      "        [548.],\n",
      "        [631.],\n",
      "        [448.],\n",
      "        [217.],\n",
      "        [150.],\n",
      "        [270.],\n",
      "        [285.],\n",
      "        [324.],\n",
      "        [355.],\n",
      "        [360.],\n",
      "        [525.],\n",
      "        [600.],\n",
      "        [520.],\n",
      "        [180.],\n",
      "        [320.],\n",
      "        [170.],\n",
      "        [140.],\n",
      "        [ 90.],\n",
      "        [ 70.],\n",
      "        [218.],\n",
      "        [270.],\n",
      "        [571.],\n",
      "        [552.],\n",
      "        [532.],\n",
      "        [426.],\n",
      "        [603.],\n",
      "        [339.],\n",
      "        [141.],\n",
      "        [308.],\n",
      "        [370.],\n",
      "        [323.],\n",
      "        [282.],\n",
      "        [209.],\n",
      "        [532.],\n",
      "        [283.],\n",
      "        [531.],\n",
      "        [586.],\n",
      "        [420.],\n",
      "        [383.],\n",
      "        [421.],\n",
      "        [131.],\n",
      "        [337.],\n",
      "        [381.],\n",
      "        [404.],\n",
      "        [293.],\n",
      "        [360.],\n",
      "        [129.],\n",
      "        [  9.],\n",
      "        [381.],\n",
      "        [353.],\n",
      "        [389.],\n",
      "        [338.],\n",
      "        [344.],\n",
      "        [207.],\n",
      "        [281.],\n",
      "        [192.],\n",
      "        [156.],\n",
      "        [174.],\n",
      "        [275.],\n",
      "        [356.],\n",
      "        [261.],\n",
      "        [417.],\n",
      "        [307.],\n",
      "        [417.],\n",
      "        [359.],\n",
      "        [362.],\n",
      "        [170.],\n",
      "        [199.],\n",
      "        [282.],\n",
      "        [237.],\n",
      "        [327.],\n",
      "        [347.],\n",
      "        [323.],\n",
      "        [429.],\n",
      "        [215.],\n",
      "        [270.],\n",
      "        [ 49.],\n",
      "        [ 17.],\n",
      "        [335.],\n",
      "        [298.],\n",
      "        [350.],\n",
      "        [332.],\n",
      "        [448.],\n",
      "        [176.],\n",
      "        [328.],\n",
      "        [272.],\n",
      "        [349.],\n",
      "        [238.],\n",
      "        [253.],\n",
      "        [178.],\n",
      "        [200.],\n",
      "        [238.],\n",
      "        [123.],\n",
      "        [421.],\n",
      "        [288.],\n",
      "        [135.],\n",
      "        [106.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_229906/4281542962.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(1)\n",
    "\n",
    "folder_dir_results = 'Results/STU_RF_BO(100+150)_1'\n",
    "folder_dir_figures = os.path.join(folder_dir_results, 'Figures')\n",
    "if not os.path.exists(folder_dir_results):\n",
    "    os.makedirs(folder_dir_results)\n",
    "if not os.path.exists(folder_dir_figures):\n",
    "    os.makedirs(folder_dir_figures)\n",
    "\n",
    "\n",
    "x_all, y_all, train_features, test_features, train_labels, test_labels = normalizing_data(data, seed=1)\n",
    "train_features, test_features = train_features.cpu().data.numpy(), test_features.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.cpu().data.numpy(), test_labels.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.reshape(-1), test_labels.reshape(-1)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Iteration', 'target', 'R2_Score_test', 'R2_Score_train', 'Train_MAPE', 'Test_MAPE', 'Figure_Path_test', 'Figure_Path_train', 'Figure_Path_all', 'Loss_Path', 'Prediction_Train_Path', 'Prediction_Test_Path'])\n",
    "\n",
    "for mm in range(0, 251):\n",
    "\n",
    "    set_random_seed(1)\n",
    "    target = pd.read_excel('d33_inference_RandomForest.xlsx')\n",
    "    tg = target.at[mm, 'target']\n",
    "    n_estimators = int(round(target.at[mm, 'n_estimators']))\n",
    "    max_depth = int(round(target.at[mm, 'max_depth']))\n",
    "    min_samples_split = int(round(target.at[mm, 'min_samples_split']))\n",
    "    min_samples_leaf = int(round(target.at[mm, 'min_samples_leaf']))\n",
    "    max_features = max(min(target.at[mm, 'max_features'], 1), 0)\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features,\n",
    "        'random_state': 1\n",
    "    }\n",
    "\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    model_save_path = f'Results/STU_RF_BO(100+150)_1/{mm}-seed_1.joblib'\n",
    "    joblib.dump(model, model_save_path)  \n",
    "\n",
    "\n",
    "    \n",
    "    predict_train = model.predict(train_features)\n",
    "    train_mape = mean_absolute_percentage_error(train_labels, predict_train)\n",
    "\n",
    "    predict_test = model.predict(test_features)\n",
    "    test_mape = mean_absolute_percentage_error(test_labels, predict_test)\n",
    "\n",
    "    \n",
    "    loss_data = pd.DataFrame({'Epoch': [1], 'Train Loss': [train_mape], 'Test Loss': [test_mape]})\n",
    "    loss_file_path = f'{folder_dir_results}/RF_loss_data_{mm}_seed_1.xlsx'\n",
    "    loss_data.to_excel(loss_file_path, index=False)\n",
    "\n",
    "    \n",
    "    df_prediction_train = pd.DataFrame({'Predicted': predict_train, 'Actual': train_labels})\n",
    "    prediction_train_path = f'{folder_dir_results}/RF_prediction_train_{mm}_seed_1.xlsx'\n",
    "    df_prediction_train.to_excel(prediction_train_path, index=False)\n",
    "\n",
    "    df_prediction_test = pd.DataFrame({'Predicted': predict_test, 'Actual': test_labels})\n",
    "    prediction_test_path = f'{folder_dir_results}/RF_prediction_test_{mm}_seed_1.xlsx'\n",
    "    df_prediction_test.to_excel(prediction_test_path, index=False)\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot([1], [train_mape], 'bo-', label=\"Train MAPE\")\n",
    "    plt.plot([1], [test_mape], 'ro-', label=\"Test MAPE\")\n",
    "    plt.legend()\n",
    "    plt.title('MAPE during Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.text(1, test_mape, f'Target Loss={tg:.4f}', fontdict={'size': 12, 'color': 'red'})\n",
    "    mape_curve_filename = f'{folder_dir_figures}/{mm}_RF_training_loss_seed_1.png'\n",
    "    plt.savefig(mape_curve_filename, format='png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    fig_name_2_train = f'{folder_dir_figures}/{mm}_RF_experiment_vs_pred_train_seed_1.png'\n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_train, y=train_labels, color='blue')\n",
    "    current_r2_train = r2_score(train_labels, predict_train)\n",
    "    plt.text(min(predict_train), max(train_labels), f'R²={current_r2_train:.4f}', color='blue')\n",
    "    plt.title('Train Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_2_train, format='png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    fig_name_2_test = f'{folder_dir_figures}/{mm}_RF_experiment_vs_pred_test_seed_1.png'\n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_test, y=test_labels, color='red')\n",
    "    current_r2_test = r2_score(test_labels, predict_test)\n",
    "    plt.text(min(predict_test), max(test_labels), f'R²={current_r2_test:.4f}', color='red')\n",
    "    plt.title('Test Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_2_test, format='png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    fig_name_2_all = f'{folder_dir_figures}/{mm}_RF_experiment_vs_pred_all_seed_1.png'\n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_train, y=train_labels, color='blue', label=\"Train\")\n",
    "    sns.regplot(x=predict_test, y=test_labels, color='red', label=\"Test\")\n",
    "    plt.legend()\n",
    "    current_r2_all = r2_score(np.concatenate([train_labels, test_labels]), np.concatenate([predict_train, predict_test]))\n",
    "    plt.text(min(np.concatenate([predict_train, predict_test])), max(np.concatenate([train_labels, test_labels])), f'R²={current_r2_all:.4f}', color='green')\n",
    "    plt.title('All Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_2_all, format='png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    df_prediction_comparison_all = pd.DataFrame({\n",
    "        'Predicted (Train)': np.concatenate([predict_train, [np.nan] * len(test_labels)]),\n",
    "        'Actual (Train)': np.concatenate([train_labels, [np.nan] * len(test_labels)]),\n",
    "        'Predicted (Test)': np.concatenate([[np.nan] * len(train_labels), predict_test]),\n",
    "        'Actual (Test)': np.concatenate([[np.nan] * len(train_labels), test_labels])\n",
    "    })\n",
    "    prediction_comparison_all_filename = f'{folder_dir_results}/{mm}_RF_experiments_and_prediction_comparison_all_seed_1.xlsx'\n",
    "    df_prediction_comparison_all.to_excel(prediction_comparison_all_filename, index=False)\n",
    "\n",
    "    \n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "        'Iteration': mm,\n",
    "        'target': tg,\n",
    "        'R2_Score_test': current_r2_test,\n",
    "        'R2_Score_train': current_r2_train,\n",
    "        'Train_MAPE': train_mape,\n",
    "        'Test_MAPE': test_mape,\n",
    "        'Figure_Path_test': fig_name_2_test,\n",
    "        'Figure_Path_train': fig_name_2_train,\n",
    "        'Figure_Path_all': fig_name_2_all,\n",
    "        'Loss_Path': mape_curve_filename,\n",
    "        'Prediction_Train_Path': prediction_train_path,\n",
    "        'Prediction_Test_Path': prediction_test_path\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "\n",
    "results_summary_filename = f'{folder_dir_results}/results_summary_RF.csv'\n",
    "results_df.to_csv(results_summary_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acbe6c-0801-4190-8f80-982a12bf8d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d7d6b-6106-49da-8b2c-3a07f2d9d13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963b7e5-02c7-42e4-8ca6-2ef8a4b88dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
