{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb188c8-a119-445a-be25-e52bfd78f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)       \n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    '''\n",
    "    Args: x is a 2D numpy array [x_size, x_features]\n",
    "    '''\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.x[idx])\n",
    "\n",
    "    def getBatch(self, idxs=[]):\n",
    "        if idxs == None:\n",
    "            return idxs\n",
    "        else:\n",
    "            x_features = []\n",
    "            for i in idxs:\n",
    "                x_features.append(self.__getitem__(i))\n",
    "            return torch.FloatTensor(x_features)\n",
    "\n",
    "def normalizing_data(data, seed=1):  \n",
    "    \n",
    "    composition = data[['Ba', 'Ca', 'Sr', 'Ti', 'Zr','Sn', 'Hf']]\n",
    "    descriptors = data[['W', 'EI', 'EA', 'μ']]\n",
    "    \n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    normalized_composition = min_max_scaler.fit_transform(composition)\n",
    "    normalized_descriptors = min_max_scaler.fit_transform(descriptors)\n",
    "    \n",
    "    \n",
    "    normalized_composition_df = pd.DataFrame(normalized_composition, columns=composition.columns)\n",
    "    normalized_descriptors_df = pd.DataFrame(normalized_descriptors, columns=descriptors.columns)  \n",
    "    \n",
    "    \n",
    "    x = pd.concat([normalized_composition_df, normalized_descriptors_df], axis=1)\n",
    "    print(x)\n",
    "    \n",
    "    y = data[['d33(pC/N)']] \n",
    "    print(y)\n",
    "\n",
    "    \n",
    "    x = torch.FloatTensor(x.values)\n",
    "    y = torch.FloatTensor(y.values)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    \n",
    "    \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "    print(y)\n",
    "    return x, y, train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bd161-6f95-4163-b7cc-b944a418d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ba        Ca   Sr     Ti     Zr        Sn    Hf         W  \\\n",
      "0    1.000000  0.000000  0.0  1.000  0.000  0.000000  0.00  1.000000   \n",
      "1    1.000000  0.000000  0.0  0.950  0.050  0.000000  0.00  0.978718   \n",
      "2    1.000000  0.000000  0.0  0.950  0.000  0.071429  0.00  0.965424   \n",
      "3    1.000000  0.000000  0.0  0.925  0.075  0.000000  0.00  0.968220   \n",
      "4    1.000000  0.000000  0.0  0.900  0.000  0.000000  0.10  0.877303   \n",
      "..        ...       ...  ...    ...    ...       ...   ...       ...   \n",
      "149  0.333333  0.666667  0.0  1.000  0.000  0.000000  0.00  0.664214   \n",
      "150  0.333333  0.666667  0.0  0.500  0.500  0.000000  0.00  0.495194   \n",
      "151  0.333333  0.666667  0.0  0.500  0.000  0.000000  0.50  0.227934   \n",
      "152  0.200000  0.800000  0.0  0.840  0.000  0.000000  0.16  0.439015   \n",
      "153  0.000000  1.000000  0.0  1.000  0.000  0.000000  0.00  0.496321   \n",
      "\n",
      "           EI        EA         μ  \n",
      "0    0.885689  0.786531  0.000000  \n",
      "1    0.892040  0.765946  0.016596  \n",
      "2    0.868796  0.725267  0.027117  \n",
      "3    0.895215  0.755653  0.024894  \n",
      "4    0.885886  0.783581  0.100000  \n",
      "..        ...       ...       ...  \n",
      "149  0.295230  0.928844  0.000000  \n",
      "150  0.358736  0.722994  0.165962  \n",
      "151  0.296214  0.914096  0.500000  \n",
      "152  0.177453  0.952587  0.160000  \n",
      "153  0.000000  1.000000  0.000000  \n",
      "\n",
      "[154 rows x 11 columns]\n",
      "     d33(pC/N)\n",
      "0          190\n",
      "1          273\n",
      "2          250\n",
      "3          317\n",
      "4          361\n",
      "..         ...\n",
      "149        123\n",
      "150        421\n",
      "151        288\n",
      "152        135\n",
      "153        106\n",
      "\n",
      "[154 rows x 1 columns]\n",
      "tensor([[190.],\n",
      "        [273.],\n",
      "        [250.],\n",
      "        [317.],\n",
      "        [361.],\n",
      "        [343.],\n",
      "        [334.],\n",
      "        [400.],\n",
      "        [272.],\n",
      "        [409.],\n",
      "        [294.],\n",
      "        [275.],\n",
      "        [361.],\n",
      "        [201.],\n",
      "        [308.],\n",
      "        [225.],\n",
      "        [384.],\n",
      "        [193.],\n",
      "        [183.],\n",
      "        [346.],\n",
      "        [165.],\n",
      "        [197.],\n",
      "        [125.],\n",
      "        [312.],\n",
      "        [210.],\n",
      "        [118.],\n",
      "        [390.],\n",
      "        [437.],\n",
      "        [435.],\n",
      "        [358.],\n",
      "        [465.],\n",
      "        [446.],\n",
      "        [451.],\n",
      "        [428.],\n",
      "        [441.],\n",
      "        [508.],\n",
      "        [237.],\n",
      "        [627.],\n",
      "        [440.],\n",
      "        [400.],\n",
      "        [440.],\n",
      "        [532.],\n",
      "        [152.],\n",
      "        [635.],\n",
      "        [520.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [282.],\n",
      "        [338.],\n",
      "        [305.],\n",
      "        [283.],\n",
      "        [249.],\n",
      "        [264.],\n",
      "        [182.],\n",
      "        [140.],\n",
      "        [187.],\n",
      "        [543.],\n",
      "        [548.],\n",
      "        [631.],\n",
      "        [448.],\n",
      "        [217.],\n",
      "        [150.],\n",
      "        [270.],\n",
      "        [285.],\n",
      "        [324.],\n",
      "        [355.],\n",
      "        [360.],\n",
      "        [525.],\n",
      "        [600.],\n",
      "        [520.],\n",
      "        [180.],\n",
      "        [320.],\n",
      "        [170.],\n",
      "        [140.],\n",
      "        [ 90.],\n",
      "        [ 70.],\n",
      "        [218.],\n",
      "        [270.],\n",
      "        [571.],\n",
      "        [552.],\n",
      "        [532.],\n",
      "        [426.],\n",
      "        [603.],\n",
      "        [339.],\n",
      "        [141.],\n",
      "        [308.],\n",
      "        [370.],\n",
      "        [323.],\n",
      "        [282.],\n",
      "        [209.],\n",
      "        [532.],\n",
      "        [283.],\n",
      "        [531.],\n",
      "        [586.],\n",
      "        [420.],\n",
      "        [383.],\n",
      "        [421.],\n",
      "        [131.],\n",
      "        [337.],\n",
      "        [381.],\n",
      "        [404.],\n",
      "        [293.],\n",
      "        [360.],\n",
      "        [129.],\n",
      "        [  9.],\n",
      "        [381.],\n",
      "        [353.],\n",
      "        [389.],\n",
      "        [338.],\n",
      "        [344.],\n",
      "        [207.],\n",
      "        [281.],\n",
      "        [192.],\n",
      "        [156.],\n",
      "        [174.],\n",
      "        [275.],\n",
      "        [356.],\n",
      "        [261.],\n",
      "        [417.],\n",
      "        [307.],\n",
      "        [417.],\n",
      "        [359.],\n",
      "        [362.],\n",
      "        [170.],\n",
      "        [199.],\n",
      "        [282.],\n",
      "        [237.],\n",
      "        [327.],\n",
      "        [347.],\n",
      "        [323.],\n",
      "        [429.],\n",
      "        [215.],\n",
      "        [270.],\n",
      "        [ 49.],\n",
      "        [ 17.],\n",
      "        [335.],\n",
      "        [298.],\n",
      "        [350.],\n",
      "        [332.],\n",
      "        [448.],\n",
      "        [176.],\n",
      "        [328.],\n",
      "        [272.],\n",
      "        [349.],\n",
      "        [238.],\n",
      "        [253.],\n",
      "        [178.],\n",
      "        [200.],\n",
      "        [238.],\n",
      "        [123.],\n",
      "        [421.],\n",
      "        [288.],\n",
      "        [135.],\n",
      "        [106.]], device='cuda:0')\n",
      "|   iter    |  target   |     C     |  epsilon  |   gamma   |\n",
      "-------------------------------------------------------------\n",
      "cv_scores (each fold): [-1.99888311 -0.41461687 -0.32488414 -0.26247098 -1.22682441]\n",
      "cv_score (mean): 0.8455359027841812\n",
      "train_mapre: 0.8219525728799938\n",
      "test_mapre: 0.415328624396739\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.4153  \u001b[39m | \u001b[39m209.1    \u001b[39m | \u001b[39m3.63     \u001b[39m | \u001b[39m0.01114  \u001b[39m |\n",
      "cv_scores (each fold): [-1.59174458 -0.28119277 -0.16737692 -0.22464947 -0.65969321]\n",
      "cv_score (mean): 0.5849313904886977\n",
      "train_mapre: 0.39291579829553247\n",
      "test_mapre: 0.2237504514398014\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m-0.2238  \u001b[39m | \u001b[35m151.9    \u001b[39m | \u001b[35m0.8191   \u001b[39m | \u001b[35m0.9325   \u001b[39m |\n",
      "cv_scores (each fold): [-1.09795295 -0.21988176 -0.14201549 -0.13588605 -0.6213254 ]\n",
      "cv_score (mean): 0.44341232925623064\n",
      "train_mapre: 0.2723074366407812\n",
      "test_mapre: 0.13702327416608348\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m-0.137   \u001b[39m | \u001b[35m93.94    \u001b[39m | \u001b[35m1.793    \u001b[39m | \u001b[35m3.974    \u001b[39m |\n",
      "cv_scores (each fold): [-0.75052461 -0.19521386 -0.15485598 -0.11984667 -0.66843057]\n",
      "cv_score (mean): 0.3777743393363634\n",
      "train_mapre: 0.06007281673523342\n",
      "test_mapre: 0.11497628567148319\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-0.115   \u001b[39m | \u001b[35m269.9    \u001b[39m | \u001b[35m2.154    \u001b[39m | \u001b[35m6.855    \u001b[39m |\n",
      "cv_scores (each fold): [-2.1648884  -0.39993515 -0.26162052 -0.22087687 -0.89363313]\n",
      "cv_score (mean): 0.7881908158305715\n",
      "train_mapre: 0.6947913062024849\n",
      "test_mapre: 0.33816496262178525\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-0.3382  \u001b[39m | \u001b[39m103.0    \u001b[39m | \u001b[39m4.403    \u001b[39m | \u001b[39m0.2836   \u001b[39m |\n",
      "cv_scores (each fold): [-0.58581539 -0.18853438 -0.15108863 -0.12834026 -0.56002001]\n",
      "cv_score (mean): 0.3227597353807453\n",
      "train_mapre: 0.06048934166760148\n",
      "test_mapre: 0.11519917723327473\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.1152  \u001b[39m | \u001b[39m335.6    \u001b[39m | \u001b[39m2.145    \u001b[39m | \u001b[39m5.591    \u001b[39m |\n",
      "cv_scores (each fold): [-1.23564632 -0.22510003 -0.14765303 -0.11583637 -0.86407471]\n",
      "cv_score (mean): 0.5176620908699728\n",
      "train_mapre: 0.3187758914297474\n",
      "test_mapre: 0.1489586347417756\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.149   \u001b[39m | \u001b[39m71.05    \u001b[39m | \u001b[39m1.071    \u001b[39m | \u001b[39m8.009    \u001b[39m |\n",
      "cv_scores (each fold): [-0.77354827 -0.19323922 -0.16076831 -0.11954737 -0.66797004]\n",
      "cv_score (mean): 0.3830146424346048\n",
      "train_mapre: 0.049733011164079265\n",
      "test_mapre: 0.11713297155801825\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.1171  \u001b[39m | \u001b[39m484.2    \u001b[39m | \u001b[39m1.636    \u001b[39m | \u001b[39m6.926    \u001b[39m |\n",
      "cv_scores (each fold): [-1.22227771 -0.27032739 -0.15760128 -0.22179478 -0.65666719]\n",
      "cv_score (mean): 0.5057336694793525\n",
      "train_mapre: 0.27324111159645287\n",
      "test_mapre: 0.19309621684240647\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.1931  \u001b[39m | \u001b[39m438.3    \u001b[39m | \u001b[39m4.484    \u001b[39m | \u001b[39m0.8596   \u001b[39m |\n",
      "cv_scores (each fold): [-1.59986465 -0.32170548 -0.21865849 -0.17732588 -1.10893361]\n",
      "cv_score (mean): 0.6852976210994983\n",
      "train_mapre: 0.5684336105506795\n",
      "test_mapre: 0.2647573426317573\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.2648  \u001b[39m | \u001b[39m20.49    \u001b[39m | \u001b[39m0.9322   \u001b[39m | \u001b[39m8.783    \u001b[39m |\n",
      "cv_scores (each fold): [-1.37358451 -0.24668614 -0.15410158 -0.1377123  -0.9564549 ]\n",
      "cv_score (mean): 0.5737078869041461\n",
      "train_mapre: 0.39701755069523353\n",
      "test_mapre: 0.17602525920743986\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.176   \u001b[39m | \u001b[39m50.08    \u001b[39m | \u001b[39m2.163    \u001b[39m | \u001b[39m9.579    \u001b[39m |\n",
      "cv_scores (each fold): [-0.76229117 -0.19441363 -0.12761243 -0.14816409 -0.44932565]\n",
      "cv_score (mean): 0.3363613950172046\n",
      "train_mapre: 0.11587191951670903\n",
      "test_mapre: 0.12017907441822981\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.1202  \u001b[39m | \u001b[39m267.0    \u001b[39m | \u001b[39m3.49     \u001b[39m | \u001b[39m3.162    \u001b[39m |\n",
      "cv_scores (each fold): [-2.35792521 -0.37736215 -0.22374719 -0.23391777 -0.66947298]\n",
      "cv_score (mean): 0.7724850576017978\n",
      "train_mapre: 0.6079157402406129\n",
      "test_mapre: 0.3052988614967171\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.3053  \u001b[39m | \u001b[39m343.6    \u001b[39m | \u001b[39m4.19     \u001b[39m | \u001b[39m0.1927   \u001b[39m |\n",
      "cv_scores (each fold): [-0.86080753 -0.19896129 -0.1580468  -0.11630713 -0.71507467]\n",
      "cv_score (mean): 0.40983948380297247\n",
      "train_mapre: 0.06055071920450909\n",
      "test_mapre: 0.12006493583776931\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.1201  \u001b[39m | \u001b[39m375.3    \u001b[39m | \u001b[39m4.945    \u001b[39m | \u001b[39m7.484    \u001b[39m |\n",
      "cv_scores (each fold): [-1.52935399 -0.28108143 -0.16931117 -0.21786064 -0.66400652]\n",
      "cv_score (mean): 0.572322749855726\n",
      "train_mapre: 0.3906794511182019\n",
      "test_mapre: 0.21725086340799488\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.2173  \u001b[39m | \u001b[39m140.9    \u001b[39m | \u001b[39m3.967    \u001b[39m | \u001b[39m1.041    \u001b[39m |\n",
      "cv_scores (each fold): [-0.84483678 -0.20692161 -0.13264374 -0.14915295 -0.46998508]\n",
      "cv_score (mean): 0.3607080331917941\n",
      "train_mapre: 0.15907465220650624\n",
      "test_mapre: 0.13023932000224606\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.1302  \u001b[39m | \u001b[39m224.5    \u001b[39m | \u001b[39m4.552    \u001b[39m | \u001b[39m2.943    \u001b[39m |\n",
      "cv_scores (each fold): [-2.26868843 -0.41050161 -0.27427219 -0.2213899  -0.89702999]\n",
      "cv_score (mean): 0.814376422075578\n",
      "train_mapre: 0.7266442161033575\n",
      "test_mapre: 0.35632697235919436\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.3563  \u001b[39m | \u001b[39m144.6    \u001b[39m | \u001b[39m0.7371   \u001b[39m | \u001b[39m0.2035   \u001b[39m |\n",
      "cv_scores (each fold): [-0.71705177 -0.20166198 -0.13368499 -0.15959548 -0.4151152 ]\n",
      "cv_score (mean): 0.32542188359215507\n",
      "train_mapre: 0.11314710810976918\n",
      "test_mapre: 0.1252500539289699\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.1253  \u001b[39m | \u001b[39m339.7    \u001b[39m | \u001b[39m1.137    \u001b[39m | \u001b[39m2.663    \u001b[39m |\n",
      "cv_scores (each fold): [-0.71059303 -0.18835456 -0.15231475 -0.125175   -0.58330933]\n",
      "cv_score (mean): 0.3519493312564618\n",
      "train_mapre: 0.06355854652675742\n",
      "test_mapre: 0.11154248598696609\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m-0.1115  \u001b[39m | \u001b[35m246.3    \u001b[39m | \u001b[35m0.3615   \u001b[39m | \u001b[35m5.745    \u001b[39m |\n",
      "cv_scores (each fold): [-1.18668857 -0.2231929  -0.14600014 -0.11785797 -0.82442929]\n",
      "cv_score (mean): 0.4996337748587538\n",
      "train_mapre: 0.30965096795543756\n",
      "test_mapre: 0.14549681538561898\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.1455  \u001b[39m | \u001b[39m74.22    \u001b[39m | \u001b[39m2.988    \u001b[39m | \u001b[39m7.001    \u001b[39m |\n",
      "cv_scores (each fold): [-1.31222237 -0.23742099 -0.15215226 -0.124909   -0.88541993]\n",
      "cv_score (mean): 0.542424907426547\n",
      "train_mapre: 0.37423321690367706\n",
      "test_mapre: 0.16095837494926726\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.161   \u001b[39m | \u001b[39m52.06    \u001b[39m | \u001b[39m2.129    \u001b[39m | \u001b[39m6.947    \u001b[39m |\n",
      "cv_scores (each fold): [-0.7940524  -0.18859776 -0.14202628 -0.12429096 -0.57082317]\n",
      "cv_score (mean): 0.363958112481822\n",
      "train_mapre: 0.07843261047501116\n",
      "test_mapre: 0.11275222468716839\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.1128  \u001b[39m | \u001b[39m207.7    \u001b[39m | \u001b[39m0.3448   \u001b[39m | \u001b[39m5.364    \u001b[39m |\n",
      "cv_scores (each fold): [-1.00801025 -0.2099918  -0.15886306 -0.11953612 -0.78913782]\n",
      "cv_score (mean): 0.4571078120003609\n",
      "train_mapre: 0.04982092367281949\n",
      "test_mapre: 0.12547795115694024\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.1255  \u001b[39m | \u001b[39m332.2    \u001b[39m | \u001b[39m2.623    \u001b[39m | \u001b[39m9.447    \u001b[39m |\n",
      "cv_scores (each fold): [-0.9534158  -0.24693411 -0.14392126 -0.19490485 -0.53273817]\n",
      "cv_score (mean): 0.41438283705768236\n",
      "train_mapre: 0.25987837103473993\n",
      "test_mapre: 0.18260193330455568\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-0.1826  \u001b[39m | \u001b[39m293.7    \u001b[39m | \u001b[39m4.527    \u001b[39m | \u001b[39m1.383    \u001b[39m |\n",
      "cv_scores (each fold): [-1.17666978 -0.22811866 -0.14730742 -0.13890368 -0.68424146]\n",
      "cv_score (mean): 0.4750482008013832\n",
      "train_mapre: 0.32831561696712835\n",
      "test_mapre: 0.15317986004839917\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.1532  \u001b[39m | \u001b[39m70.5     \u001b[39m | \u001b[39m4.056    \u001b[39m | \u001b[39m3.983    \u001b[39m |\n",
      "cv_scores (each fold): [-1.13210828 -0.2253455  -0.14334883 -0.14579908 -0.62101518]\n",
      "cv_score (mean): 0.45352337382468944\n",
      "train_mapre: 0.30388155950526774\n",
      "test_mapre: 0.1535046763595461\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.1535  \u001b[39m | \u001b[39m83.51    \u001b[39m | \u001b[39m4.645    \u001b[39m | \u001b[39m3.484    \u001b[39m |\n",
      "cv_scores (each fold): [-0.9666879  -0.20653268 -0.15859247 -0.11867833 -0.77022285]\n",
      "cv_score (mean): 0.44414284616553446\n",
      "train_mapre: 0.053625749678892755\n",
      "test_mapre: 0.12303901879033591\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.123   \u001b[39m | \u001b[39m375.7    \u001b[39m | \u001b[39m3.657    \u001b[39m | \u001b[39m8.834    \u001b[39m |\n",
      "cv_scores (each fold): [-0.67317189 -0.18649586 -0.12845482 -0.13917795 -0.43769018]\n",
      "cv_score (mean): 0.312998140983347\n",
      "train_mapre: 0.08062443006373111\n",
      "test_mapre: 0.11834936096724624\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.1183  \u001b[39m | \u001b[39m312.2    \u001b[39m | \u001b[39m3.78     \u001b[39m | \u001b[39m3.495    \u001b[39m |\n",
      "cv_scores (each fold): [-0.98568037 -0.2021747  -0.13389736 -0.12862317 -0.56891291]\n",
      "cv_score (mean): 0.4038577014808091\n",
      "train_mapre: 0.20324658247910227\n",
      "test_mapre: 0.12782992373747676\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.1278  \u001b[39m | \u001b[39m135.7    \u001b[39m | \u001b[39m4.49     \u001b[39m | \u001b[39m4.287    \u001b[39m |\n",
      "cv_scores (each fold): [-0.65809369 -0.18987782 -0.15720358 -0.11911544 -0.6266434 ]\n",
      "cv_score (mean): 0.35018678850331575\n",
      "train_mapre: 0.05742791189423485\n",
      "test_mapre: 0.11806660419582476\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.1181  \u001b[39m | \u001b[39m482.5    \u001b[39m | \u001b[39m3.351    \u001b[39m | \u001b[39m6.221    \u001b[39m |\n",
      "cv_scores (each fold): [-1.23631919 -0.23123978 -0.15289418 -0.13675408 -0.75190957]\n",
      "cv_score (mean): 0.5018233619447446\n",
      "train_mapre: 0.3563683446555184\n",
      "test_mapre: 0.15914871464772914\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-0.1591  \u001b[39m | \u001b[39m58.26    \u001b[39m | \u001b[39m4.752    \u001b[39m | \u001b[39m4.505    \u001b[39m |\n",
      "cv_scores (each fold): [-0.7997297  -0.20487614 -0.13689591 -0.15868973 -0.44719613]\n",
      "cv_score (mean): 0.34947752270929533\n",
      "train_mapre: 0.1618051970340405\n",
      "test_mapre: 0.1428953623204698\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-0.1429  \u001b[39m | \u001b[39m289.6    \u001b[39m | \u001b[39m2.1      \u001b[39m | \u001b[39m2.378    \u001b[39m |\n",
      "cv_scores (each fold): [-2.43754989 -0.43380683 -0.31036156 -0.2109747  -0.95373459]\n",
      "cv_score (mean): 0.869285513029334\n",
      "train_mapre: 0.8055477943649405\n",
      "test_mapre: 0.39192615225515554\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-0.3919  \u001b[39m | \u001b[39m451.8    \u001b[39m | \u001b[39m2.911    \u001b[39m | \u001b[39m0.03867  \u001b[39m |\n",
      "cv_scores (each fold): [-0.58780049 -0.18746227 -0.14952643 -0.12925298 -0.52890414]\n",
      "cv_score (mean): 0.31658926209044236\n",
      "train_mapre: 0.062268096772896867\n",
      "test_mapre: 0.1138568868404955\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-0.1139  \u001b[39m | \u001b[39m309.0    \u001b[39m | \u001b[39m1.701    \u001b[39m | \u001b[39m5.275    \u001b[39m |\n",
      "cv_scores (each fold): [-0.97992305 -0.2132465  -0.16368077 -0.12192535 -0.77669332]\n",
      "cv_score (mean): 0.45109379625123724\n",
      "train_mapre: 0.045370206764361175\n",
      "test_mapre: 0.12355007280362613\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-0.1236  \u001b[39m | \u001b[39m443.1    \u001b[39m | \u001b[39m1.851    \u001b[39m | \u001b[39m9.086    \u001b[39m |\n",
      "cv_scores (each fold): [-0.98528119 -0.208161   -0.1618814  -0.11777571 -0.77821531]\n",
      "cv_score (mean): 0.45026292282096636\n",
      "train_mapre: 0.04235422683866365\n",
      "test_mapre: 0.12648266572118813\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-0.1265  \u001b[39m | \u001b[39m312.1    \u001b[39m | \u001b[39m0.1775   \u001b[39m | \u001b[39m9.295    \u001b[39m |\n",
      "cv_scores (each fold): [-0.79071133 -0.21424497 -0.14433667 -0.16321323 -0.51892095]\n",
      "cv_score (mean): 0.3662854286146094\n",
      "train_mapre: 0.18712624894185428\n",
      "test_mapre: 0.1679708615658167\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-0.168   \u001b[39m | \u001b[39m345.8    \u001b[39m | \u001b[39m4.987    \u001b[39m | \u001b[39m1.732    \u001b[39m |\n",
      "cv_scores (each fold): [-1.20436996 -0.22774523 -0.14664586 -0.118369   -0.83830255]\n",
      "cv_score (mean): 0.5070865214887569\n",
      "train_mapre: 0.3246440182573738\n",
      "test_mapre: 0.14922611511388678\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-0.1492  \u001b[39m | \u001b[39m69.43    \u001b[39m | \u001b[39m4.67     \u001b[39m | \u001b[39m6.971    \u001b[39m |\n",
      "cv_scores (each fold): [-1.42582262 -0.27588956 -0.17995785 -0.15202632 -0.98013582]\n",
      "cv_score (mean): 0.6027664326592277\n",
      "train_mapre: 0.46567313635236746\n",
      "test_mapre: 0.20270585583773262\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-0.2027  \u001b[39m | \u001b[39m33.93    \u001b[39m | \u001b[39m3.802    \u001b[39m | \u001b[39m7.541    \u001b[39m |\n",
      "cv_scores (each fold): [-0.80496715 -0.23810091 -0.14252874 -0.18832226 -0.54597596]\n",
      "cv_score (mean): 0.38397900647052197\n",
      "train_mapre: 0.19879165096777288\n",
      "test_mapre: 0.18408986448475342\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-0.1841  \u001b[39m | \u001b[39m461.6    \u001b[39m | \u001b[39m3.586    \u001b[39m | \u001b[39m1.251    \u001b[39m |\n",
      "cv_scores (each fold): [-1.94305287 -0.40771942 -0.31255246 -0.2524095  -1.21857088]\n",
      "cv_score (mean): 0.826861025080005\n",
      "train_mapre: 0.795788258636504\n",
      "test_mapre: 0.4052863619352247\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-0.4053  \u001b[39m | \u001b[39m10.92    \u001b[39m | \u001b[39m0.2284   \u001b[39m | \u001b[39m0.2928   \u001b[39m |\n",
      "cv_scores (each fold): [-1.01315479 -0.1974207  -0.13883906 -0.12414902 -0.65889206]\n",
      "cv_score (mean): 0.4264911258879356\n",
      "train_mapre: 0.19792327261695813\n",
      "test_mapre: 0.12438562971667291\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-0.1244  \u001b[39m | \u001b[39m123.9    \u001b[39m | \u001b[39m4.314    \u001b[39m | \u001b[39m5.393    \u001b[39m |\n",
      "cv_scores (each fold): [-1.07102057 -0.26248317 -0.14181602 -0.20052226 -0.57664137]\n",
      "cv_score (mean): 0.4504966795054348\n",
      "train_mapre: 0.273757547655979\n",
      "test_mapre: 0.19013448545224598\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-0.1901  \u001b[39m | \u001b[39m276.9    \u001b[39m | \u001b[39m4.226    \u001b[39m | \u001b[39m1.25     \u001b[39m |\n",
      "cv_scores (each fold): [-1.07784972 -0.21260684 -0.15281119 -0.11797866 -0.82432943]\n",
      "cv_score (mean): 0.4771151662972876\n",
      "train_mapre: 0.16723540495776906\n",
      "test_mapre: 0.13462203405660397\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-0.1346  \u001b[39m | \u001b[39m140.3    \u001b[39m | \u001b[39m2.97     \u001b[39m | \u001b[39m9.696    \u001b[39m |\n",
      "cv_scores (each fold): [-0.86967492 -0.20036399 -0.15819338 -0.11612605 -0.72470871]\n",
      "cv_score (mean): 0.41381340935098054\n",
      "train_mapre: 0.05044551085809651\n",
      "test_mapre: 0.11940498037427144\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-0.1194  \u001b[39m | \u001b[39m281.0    \u001b[39m | \u001b[39m0.1914   \u001b[39m | \u001b[39m8.008    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03177046 -0.20949296 -0.13814483 -0.13499498 -0.57173857]\n",
      "cv_score (mean): 0.41722836069890673\n",
      "train_mapre: 0.23865940708934266\n",
      "test_mapre: 0.1333249588587707\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-0.1333  \u001b[39m | \u001b[39m117.3    \u001b[39m | \u001b[39m4.055    \u001b[39m | \u001b[39m3.885    \u001b[39m |\n",
      "cv_scores (each fold): [-0.57243231 -0.19054098 -0.15043664 -0.12795541 -0.56346968]\n",
      "cv_score (mean): 0.3209670049550476\n",
      "train_mapre: 0.06252790719320485\n",
      "test_mapre: 0.1165508584510081\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-0.1166  \u001b[39m | \u001b[39m431.9    \u001b[39m | \u001b[39m3.761    \u001b[39m | \u001b[39m5.567    \u001b[39m |\n",
      "cv_scores (each fold): [-1.4618118  -0.30036407 -0.17110568 -0.20330192 -0.68282958]\n",
      "cv_score (mean): 0.5638826118318729\n",
      "train_mapre: 0.44198365033733067\n",
      "test_mapre: 0.2260977841236636\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-0.2261  \u001b[39m | \u001b[39m69.09    \u001b[39m | \u001b[39m0.3936   \u001b[39m | \u001b[39m1.222    \u001b[39m |\n",
      "cv_scores (each fold): [-1.54851663 -0.33457835 -0.21882829 -0.16961606 -0.95816824]\n",
      "cv_score (mean): 0.6459415160217958\n",
      "train_mapre: 0.538963342195007\n",
      "test_mapre: 0.2502483982363717\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-0.2502  \u001b[39m | \u001b[39m23.23    \u001b[39m | \u001b[39m0.6267   \u001b[39m | \u001b[39m2.265    \u001b[39m |\n",
      "cv_scores (each fold): [-2.51815122 -0.4051002  -0.26367771 -0.23373291 -0.76190569]\n",
      "cv_score (mean): 0.8365135452541874\n",
      "train_mapre: 0.6744485935898638\n",
      "test_mapre: 0.34222687139111335\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-0.3422  \u001b[39m | \u001b[39m356.8    \u001b[39m | \u001b[39m2.843    \u001b[39m | \u001b[39m0.1354   \u001b[39m |\n",
      "cv_scores (each fold): [-1.38447019 -0.2651107  -0.17093882 -0.13896777 -0.91125719]\n",
      "cv_score (mean): 0.5741489353793625\n",
      "train_mapre: 0.4409015044753597\n",
      "test_mapre: 0.18887532810800522\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-0.1889  \u001b[39m | \u001b[39m36.92    \u001b[39m | \u001b[39m4.84     \u001b[39m | \u001b[39m5.685    \u001b[39m |\n",
      "cv_scores (each fold): [-1.10142166 -0.20889612 -0.14506389 -0.11927718 -0.78711282]\n",
      "cv_score (mean): 0.47235433408402433\n",
      "train_mapre: 0.23159641702075887\n",
      "test_mapre: 0.13431874257535875\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-0.1343  \u001b[39m | \u001b[39m102.4    \u001b[39m | \u001b[39m1.336    \u001b[39m | \u001b[39m7.441    \u001b[39m |\n",
      "cv_scores (each fold): [-1.18165936 -0.216617   -0.14623098 -0.11795755 -0.867226  ]\n",
      "cv_score (mean): 0.505938177045534\n",
      "train_mapre: 0.24754197475596043\n",
      "test_mapre: 0.1411857939464365\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-0.1412  \u001b[39m | \u001b[39m98.52    \u001b[39m | \u001b[39m2.949    \u001b[39m | \u001b[39m9.7      \u001b[39m |\n",
      "cv_scores (each fold): [-0.45429723 -0.18549521 -0.14977397 -0.13107881 -0.48156507]\n",
      "cv_score (mean): 0.2804420573290189\n",
      "train_mapre: 0.059086261674951374\n",
      "test_mapre: 0.11409988326623155\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-0.1141  \u001b[39m | \u001b[39m423.6    \u001b[39m | \u001b[39m1.275    \u001b[39m | \u001b[39m4.943    \u001b[39m |\n",
      "cv_scores (each fold): [-0.82993506 -0.22900832 -0.14545116 -0.18143239 -0.52766288]\n",
      "cv_score (mean): 0.38269796332830464\n",
      "train_mapre: 0.21900523218710613\n",
      "test_mapre: 0.1742071388932331\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-0.1742  \u001b[39m | \u001b[39m310.4    \u001b[39m | \u001b[39m4.162    \u001b[39m | \u001b[39m1.576    \u001b[39m |\n",
      "cv_scores (each fold): [-1.68153702 -0.3731634  -0.26274068 -0.20347476 -1.17680954]\n",
      "cv_score (mean): 0.7395450814487388\n",
      "train_mapre: 0.6607059654016137\n",
      "test_mapre: 0.31671328991449443\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-0.3167  \u001b[39m | \u001b[39m10.27    \u001b[39m | \u001b[39m0.4431   \u001b[39m | \u001b[39m4.869    \u001b[39m |\n",
      "cv_scores (each fold): [-0.70525837 -0.1924366  -0.12562399 -0.14688285 -0.4318919 ]\n",
      "cv_score (mean): 0.32041874219421485\n",
      "train_mapre: 0.08727464450173107\n",
      "test_mapre: 0.11765423745401234\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-0.1177  \u001b[39m | \u001b[39m303.6    \u001b[39m | \u001b[39m2.887    \u001b[39m | \u001b[39m3.18     \u001b[39m |\n",
      "cv_scores (each fold): [-0.36719777 -0.18371726 -0.13822667 -0.13737611 -0.36131966]\n",
      "cv_score (mean): 0.23756749419750572\n",
      "train_mapre: 0.07071131166455485\n",
      "test_mapre: 0.11899785565556197\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-0.119   \u001b[39m | \u001b[39m494.3    \u001b[39m | \u001b[39m2.941    \u001b[39m | \u001b[39m3.808    \u001b[39m |\n",
      "cv_scores (each fold): [-0.73216804 -0.19490919 -0.15311341 -0.12103247 -0.65983337]\n",
      "cv_score (mean): 0.3722112960575882\n",
      "train_mapre: 0.0630837756820757\n",
      "test_mapre: 0.11784708776563933\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m-0.1178  \u001b[39m | \u001b[39m275.9    \u001b[39m | \u001b[39m3.752    \u001b[39m | \u001b[39m6.696    \u001b[39m |\n",
      "cv_scores (each fold): [-0.9866448  -0.20449229 -0.13904522 -0.1356297  -0.52715847]\n",
      "cv_score (mean): 0.39859409524333034\n",
      "train_mapre: 0.22530710052583633\n",
      "test_mapre: 0.13148562963242924\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-0.1315  \u001b[39m | \u001b[39m133.2    \u001b[39m | \u001b[39m0.425    \u001b[39m | \u001b[39m3.707    \u001b[39m |\n",
      "cv_scores (each fold): [-0.83167873 -0.19801775 -0.15835054 -0.11684751 -0.70291228]\n",
      "cv_score (mean): 0.40156136032271855\n",
      "train_mapre: 0.05093548450606612\n",
      "test_mapre: 0.11600666554850095\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m-0.116   \u001b[39m | \u001b[39m315.2    \u001b[39m | \u001b[39m1.13     \u001b[39m | \u001b[39m7.53     \u001b[39m |\n",
      "cv_scores (each fold): [-1.43871424 -0.27398225 -0.18429384 -0.15188806 -0.98537033]\n",
      "cv_score (mean): 0.6068497421787663\n",
      "train_mapre: 0.46342250978225746\n",
      "test_mapre: 0.20538592442697906\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m-0.2054  \u001b[39m | \u001b[39m34.2     \u001b[39m | \u001b[39m1.376    \u001b[39m | \u001b[39m8.049    \u001b[39m |\n",
      "cv_scores (each fold): [-1.08474791 -0.21262473 -0.13900378 -0.12223321 -0.68917923]\n",
      "cv_score (mean): 0.4495577731760644\n",
      "train_mapre: 0.24851026927996214\n",
      "test_mapre: 0.1319721537946558\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m-0.132   \u001b[39m | \u001b[39m97.52    \u001b[39m | \u001b[39m3.233    \u001b[39m | \u001b[39m5.251    \u001b[39m |\n",
      "cv_scores (each fold): [-1.46930841 -0.28122244 -0.16875504 -0.24262681 -0.74106155]\n",
      "cv_score (mean): 0.5805948500675288\n",
      "train_mapre: 0.3226914431459955\n",
      "test_mapre: 0.21322099412936732\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m-0.2132  \u001b[39m | \u001b[39m462.5    \u001b[39m | \u001b[39m1.39     \u001b[39m | \u001b[39m0.669    \u001b[39m |\n",
      "cv_scores (each fold): [-0.98709505 -0.20724518 -0.15788661 -0.11934026 -0.7802989 ]\n",
      "cv_score (mean): 0.4503731991386509\n",
      "train_mapre: 0.05398007048318901\n",
      "test_mapre: 0.12426163464255546\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m-0.1243  \u001b[39m | \u001b[39m367.8    \u001b[39m | \u001b[39m3.884    \u001b[39m | \u001b[39m9.079    \u001b[39m |\n",
      "cv_scores (each fold): [-0.63191354 -0.20349709 -0.13739022 -0.16635713 -0.41665259]\n",
      "cv_score (mean): 0.31116211423843476\n",
      "train_mapre: 0.08507510689588821\n",
      "test_mapre: 0.13041507210626083\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m-0.1304  \u001b[39m | \u001b[39m466.1    \u001b[39m | \u001b[39m0.1684   \u001b[39m | \u001b[39m2.351    \u001b[39m |\n",
      "cv_scores (each fold): [-1.02443046 -0.20910089 -0.15561469 -0.11911684 -0.7979141 ]\n",
      "cv_score (mean): 0.46123539508288725\n",
      "train_mapre: 0.05711389011727985\n",
      "test_mapre: 0.126872854221006\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m-0.1269  \u001b[39m | \u001b[39m308.8    \u001b[39m | \u001b[39m4.75     \u001b[39m | \u001b[39m9.502    \u001b[39m |\n",
      "cv_scores (each fold): [-0.70409784 -0.19226717 -0.15111962 -0.12316674 -0.6423798 ]\n",
      "cv_score (mean): 0.362606233640627\n",
      "train_mapre: 0.06653910625812264\n",
      "test_mapre: 0.11804686692120522\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m-0.118   \u001b[39m | \u001b[39m278.8    \u001b[39m | \u001b[39m4.586    \u001b[39m | \u001b[39m6.419    \u001b[39m |\n",
      "cv_scores (each fold): [-0.83327697 -0.18871012 -0.1479207  -0.12047044 -0.63021922]\n",
      "cv_score (mean): 0.3841194896278594\n",
      "train_mapre: 0.09273329450341476\n",
      "test_mapre: 0.11465433913284648\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m-0.1147  \u001b[39m | \u001b[39m195.6    \u001b[39m | \u001b[39m2.481    \u001b[39m | \u001b[39m6.047    \u001b[39m |\n",
      "cv_scores (each fold): [-1.00402131 -0.20875378 -0.15801789 -0.11700555 -0.7858883 ]\n",
      "cv_score (mean): 0.45473736777410034\n",
      "train_mapre: 0.05846658528045812\n",
      "test_mapre: 0.12424247079962171\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m-0.1242  \u001b[39m | \u001b[39m275.2    \u001b[39m | \u001b[39m4.638    \u001b[39m | \u001b[39m9.188    \u001b[39m |\n",
      "cv_scores (each fold): [-0.9746605  -0.23505199 -0.14645441 -0.18506539 -0.53091301]\n",
      "cv_score (mean): 0.4144290609289942\n",
      "train_mapre: 0.27909256079649025\n",
      "test_mapre: 0.17328963249666107\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m-0.1733  \u001b[39m | \u001b[39m198.0    \u001b[39m | \u001b[39m4.82     \u001b[39m | \u001b[39m1.748    \u001b[39m |\n",
      "cv_scores (each fold): [-1.2175767  -0.23304838 -0.14940987 -0.1275506  -0.76146929]\n",
      "cv_score (mean): 0.49781096778031697\n",
      "train_mapre: 0.3381330346403778\n",
      "test_mapre: 0.15003892670635097\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m-0.15    \u001b[39m | \u001b[39m64.04    \u001b[39m | \u001b[39m0.7619   \u001b[39m | \u001b[39m5.062    \u001b[39m |\n",
      "cv_scores (each fold): [-1.68728556 -0.36366074 -0.25960114 -0.20412975 -1.20059913]\n",
      "cv_score (mean): 0.7430552644734734\n",
      "train_mapre: 0.6600305414727616\n",
      "test_mapre: 0.3198216297661632\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m-0.3198  \u001b[39m | \u001b[39m11.74    \u001b[39m | \u001b[39m4.745    \u001b[39m | \u001b[39m8.273    \u001b[39m |\n",
      "cv_scores (each fold): [-1.69422611 -0.37970286 -0.27028308 -0.2080124  -1.172653  ]\n",
      "cv_score (mean): 0.7449754913041915\n",
      "train_mapre: 0.685970087109013\n",
      "test_mapre: 0.3336449094178157\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m-0.3336  \u001b[39m | \u001b[39m8.494    \u001b[39m | \u001b[39m0.9634   \u001b[39m | \u001b[39m3.327    \u001b[39m |\n",
      "cv_scores (each fold): [-1.17700711 -0.23245506 -0.1552181  -0.14316762 -0.67846484]\n",
      "cv_score (mean): 0.4772625470936506\n",
      "train_mapre: 0.3489759359420275\n",
      "test_mapre: 0.16626545133836204\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m-0.1663  \u001b[39m | \u001b[39m66.37    \u001b[39m | \u001b[39m4.067    \u001b[39m | \u001b[39m3.454    \u001b[39m |\n",
      "cv_scores (each fold): [-0.96019064 -0.21059418 -0.16369592 -0.11994785 -0.76803605]\n",
      "cv_score (mean): 0.4444929275377453\n",
      "train_mapre: 0.049406748862991234\n",
      "test_mapre: 0.12247456535263164\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m-0.1225  \u001b[39m | \u001b[39m470.1    \u001b[39m | \u001b[39m2.952    \u001b[39m | \u001b[39m8.79     \u001b[39m |\n",
      "cv_scores (each fold): [-0.44941796 -0.18544752 -0.14392399 -0.13343324 -0.46083813]\n",
      "cv_score (mean): 0.2746121660015329\n",
      "train_mapre: 0.07140600216879228\n",
      "test_mapre: 0.11864090321487195\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m-0.1186  \u001b[39m | \u001b[39m422.5    \u001b[39m | \u001b[39m4.536    \u001b[39m | \u001b[39m4.604    \u001b[39m |\n",
      "cv_scores (each fold): [-0.77759365 -0.20249559 -0.13082385 -0.15213485 -0.44691452]\n",
      "cv_score (mean): 0.34199249130904086\n",
      "train_mapre: 0.1333925777579771\n",
      "test_mapre: 0.12439633342383549\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m-0.1244  \u001b[39m | \u001b[39m273.6    \u001b[39m | \u001b[39m4.013    \u001b[39m | \u001b[39m2.864    \u001b[39m |\n",
      "cv_scores (each fold): [-2.4369386  -0.40369983 -0.26473297 -0.22916675 -0.78519429]\n",
      "cv_score (mean): 0.8239464871486307\n",
      "train_mapre: 0.6819450336543931\n",
      "test_mapre: 0.3439088310998219\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m-0.3439  \u001b[39m | \u001b[39m245.6    \u001b[39m | \u001b[39m3.036    \u001b[39m | \u001b[39m0.1652   \u001b[39m |\n",
      "cv_scores (each fold): [-0.89995065 -0.20240811 -0.15967993 -0.11580346 -0.73405922]\n",
      "cv_score (mean): 0.42238027337689416\n",
      "train_mapre: 0.05312829157769219\n",
      "test_mapre: 0.1190104272353013\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m-0.119   \u001b[39m | \u001b[39m297.1    \u001b[39m | \u001b[39m2.225    \u001b[39m | \u001b[39m8.076    \u001b[39m |\n",
      "cv_scores (each fold): [-0.92781876 -0.19150005 -0.14456076 -0.12451543 -0.63852104]\n",
      "cv_score (mean): 0.40538320735001554\n",
      "train_mapre: 0.13317316529126355\n",
      "test_mapre: 0.11942705189424757\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m-0.1194  \u001b[39m | \u001b[39m158.3    \u001b[39m | \u001b[39m4.475    \u001b[39m | \u001b[39m5.783    \u001b[39m |\n",
      "cv_scores (each fold): [-1.09398195 -0.21133739 -0.14056938 -0.1212269  -0.75319654]\n",
      "cv_score (mean): 0.46406243157416593\n",
      "train_mapre: 0.25683762434205926\n",
      "test_mapre: 0.13635088194641515\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m-0.1364  \u001b[39m | \u001b[39m92.82    \u001b[39m | \u001b[39m3.961    \u001b[39m | \u001b[39m6.124    \u001b[39m |\n",
      "cv_scores (each fold): [-1.47331884 -0.28856345 -0.19574207 -0.15673368 -0.99608446]\n",
      "cv_score (mean): 0.6220885001994259\n",
      "train_mapre: 0.4975894526045492\n",
      "test_mapre: 0.22038962937851075\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m-0.2204  \u001b[39m | \u001b[39m27.9     \u001b[39m | \u001b[39m2.159    \u001b[39m | \u001b[39m6.794    \u001b[39m |\n",
      "cv_scores (each fold): [-1.01852289 -0.22213857 -0.16652188 -0.12255732 -0.79637713]\n",
      "cv_score (mean): 0.46522355883069066\n",
      "train_mapre: 0.03767136652030555\n",
      "test_mapre: 0.1285621682501825\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m-0.1286  \u001b[39m | \u001b[39m459.4    \u001b[39m | \u001b[39m0.102    \u001b[39m | \u001b[39m9.768    \u001b[39m |\n",
      "cv_scores (each fold): [-0.86072097 -0.18734957 -0.1460361  -0.12273828 -0.64014352]\n",
      "cv_score (mean): 0.39139768746427456\n",
      "train_mapre: 0.1029239132352966\n",
      "test_mapre: 0.11607344168114328\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m-0.1161  \u001b[39m | \u001b[39m188.9    \u001b[39m | \u001b[39m4.872    \u001b[39m | \u001b[39m6.051    \u001b[39m |\n",
      "cv_scores (each fold): [-0.68089255 -0.19174949 -0.15592695 -0.12115681 -0.63197996]\n",
      "cv_score (mean): 0.3563411518003254\n",
      "train_mapre: 0.05759550956055029\n",
      "test_mapre: 0.11679461707070887\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m-0.1168  \u001b[39m | \u001b[39m414.6    \u001b[39m | \u001b[39m2.916    \u001b[39m | \u001b[39m6.284    \u001b[39m |\n",
      "cv_scores (each fold): [-0.98438391 -0.19708595 -0.14637993 -0.11829056 -0.74203867]\n",
      "cv_score (mean): 0.43763580043245265\n",
      "train_mapre: 0.15140495146072186\n",
      "test_mapre: 0.12470512628794175\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m-0.1247  \u001b[39m | \u001b[39m143.5    \u001b[39m | \u001b[39m2.975    \u001b[39m | \u001b[39m7.503    \u001b[39m |\n",
      "cv_scores (each fold): [-0.78224682 -0.19587386 -0.15962085 -0.11717469 -0.68166179]\n",
      "cv_score (mean): 0.3873156010476945\n",
      "train_mapre: 0.05705808001807891\n",
      "test_mapre: 0.11765886810902589\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m-0.1177  \u001b[39m | \u001b[39m429.3    \u001b[39m | \u001b[39m3.8      \u001b[39m | \u001b[39m6.984    \u001b[39m |\n",
      "cv_scores (each fold): [-0.7302471  -0.19225002 -0.1593657  -0.11842994 -0.65487929]\n",
      "cv_score (mean): 0.37103441075445476\n",
      "train_mapre: 0.05189772099345093\n",
      "test_mapre: 0.11573410338909466\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m-0.1157  \u001b[39m | \u001b[39m432.4    \u001b[39m | \u001b[39m1.681    \u001b[39m | \u001b[39m6.711    \u001b[39m |\n",
      "cv_scores (each fold): [-0.77933612 -0.1886116  -0.1309742  -0.13021902 -0.49417842]\n",
      "cv_score (mean): 0.3446638732584306\n",
      "train_mapre: 0.09285541322777399\n",
      "test_mapre: 0.11833826131109772\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m-0.1183  \u001b[39m | \u001b[39m226.0    \u001b[39m | \u001b[39m1.972    \u001b[39m | \u001b[39m4.114    \u001b[39m |\n",
      "cv_scores (each fold): [-0.82246552 -0.18958442 -0.15021171 -0.12148657 -0.63769352]\n",
      "cv_score (mean): 0.3842883483084811\n",
      "train_mapre: 0.08882744384908527\n",
      "test_mapre: 0.11458504218506965\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m-0.1146  \u001b[39m | \u001b[39m201.3    \u001b[39m | \u001b[39m1.655    \u001b[39m | \u001b[39m6.223    \u001b[39m |\n",
      "cv_scores (each fold): [-0.81637104 -0.19371668 -0.1499264  -0.12146627 -0.6761621 ]\n",
      "cv_score (mean): 0.39152849789019706\n",
      "train_mapre: 0.09046809371374297\n",
      "test_mapre: 0.12137441158188841\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m-0.1214  \u001b[39m | \u001b[39m215.7    \u001b[39m | \u001b[39m4.872    \u001b[39m | \u001b[39m6.781    \u001b[39m |\n",
      "cv_scores (each fold): [-1.07621742 -0.21981076 -0.14073939 -0.14501966 -0.57452222]\n",
      "cv_score (mean): 0.4312618911853134\n",
      "train_mapre: 0.27669363003241426\n",
      "test_mapre: 0.1455207965997221\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m-0.1455  \u001b[39m | \u001b[39m100.1    \u001b[39m | \u001b[39m2.191    \u001b[39m | \u001b[39m3.44     \u001b[39m |\n",
      "cv_scores (each fold): [-0.98889832 -0.20771718 -0.15794306 -0.12005567 -0.78219559]\n",
      "cv_score (mean): 0.45136196351644087\n",
      "train_mapre: 0.0550279294800248\n",
      "test_mapre: 0.12445609227048673\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m-0.1245  \u001b[39m | \u001b[39m399.0    \u001b[39m | \u001b[39m4.412    \u001b[39m | \u001b[39m9.039    \u001b[39m |\n",
      "cv_scores (each fold): [-0.74050097 -0.2020508  -0.13465989 -0.15980204 -0.42591794]\n",
      "cv_score (mean): 0.33258632885709843\n",
      "train_mapre: 0.1290328945375408\n",
      "test_mapre: 0.13163260117211265\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m-0.1316  \u001b[39m | \u001b[39m331.7    \u001b[39m | \u001b[39m1.424    \u001b[39m | \u001b[39m2.531    \u001b[39m |\n",
      "cv_scores (each fold): [-0.89556589 -0.20354802 -0.16060792 -0.11808865 -0.73348697]\n",
      "cv_score (mean): 0.42225948944510616\n",
      "train_mapre: 0.05125019685909608\n",
      "test_mapre: 0.1206643992461134\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m-0.1207  \u001b[39m | \u001b[39m427.6    \u001b[39m | \u001b[39m2.686    \u001b[39m | \u001b[39m8.024    \u001b[39m |\n",
      "cv_scores (each fold): [-0.62769816 -0.1850096  -0.1465567  -0.12891367 -0.53712734]\n",
      "cv_score (mean): 0.3250610934573418\n",
      "train_mapre: 0.06943513708674455\n",
      "test_mapre: 0.11393317433655721\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m-0.1139  \u001b[39m | \u001b[39m286.7    \u001b[39m | \u001b[39m3.692    \u001b[39m | \u001b[39m5.195    \u001b[39m |\n",
      "cv_scores (each fold): [-0.48220592 -0.18504764 -0.14632184 -0.13333199 -0.45894087]\n",
      "cv_score (mean): 0.28116965214164663\n",
      "train_mapre: 0.06714708437350426\n",
      "test_mapre: 0.11446446433629472\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m-0.1145  \u001b[39m | \u001b[39m385.7    \u001b[39m | \u001b[39m2.887    \u001b[39m | \u001b[39m4.662    \u001b[39m |\n",
      "cv_scores (each fold): [-0.90209769 -0.19866572 -0.13474217 -0.1366941  -0.50348521]\n",
      "cv_score (mean): 0.37513698071575663\n",
      "train_mapre: 0.17219177953358245\n",
      "test_mapre: 0.12451612048087325\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m-0.1245  \u001b[39m | \u001b[39m172.0    \u001b[39m | \u001b[39m0.4342   \u001b[39m | \u001b[39m3.785    \u001b[39m |\n",
      "cv_scores (each fold): [-1.36776625 -0.30906108 -0.17928922 -0.17567037 -0.79439373]\n",
      "cv_score (mean): 0.5652361295956352\n",
      "train_mapre: 0.4622136513888137\n",
      "test_mapre: 0.21878133867361976\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m-0.2188  \u001b[39m | \u001b[39m40.73    \u001b[39m | \u001b[39m4.916    \u001b[39m | \u001b[39m1.824    \u001b[39m |\n",
      "cv_scores (each fold): [-0.96952743 -0.20633523 -0.15679646 -0.11824521 -0.77179587]\n",
      "cv_score (mean): 0.4445400395324971\n",
      "train_mapre: 0.05711533629925627\n",
      "test_mapre: 0.12343974047824335\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m-0.1234  \u001b[39m | \u001b[39m345.7    \u001b[39m | \u001b[39m4.528    \u001b[39m | \u001b[39m8.765    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03602593 -0.21212142 -0.15797543 -0.11622469 -0.80685182]\n",
      "cv_score (mean): 0.4658398595390131\n",
      "train_mapre: 0.08575488874403064\n",
      "test_mapre: 0.12966375916237616\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m-0.1297  \u001b[39m | \u001b[39m207.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03181073 -0.21181715 -0.15982542 -0.11670176 -0.80380735]\n",
      "cv_score (mean): 0.4647924809261954\n",
      "train_mapre: 0.060118122121477886\n",
      "test_mapre: 0.12991381669836566\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m250.1    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03203559 -0.21211258 -0.15947795 -0.11619134 -0.80450164]\n",
      "cv_score (mean): 0.46486382232904405\n",
      "train_mapre: 0.06499474628251034\n",
      "test_mapre: 0.1299002635161518\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m242.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.0343731  -0.2120893  -0.15851425 -0.11615292 -0.80626551]\n",
      "cv_score (mean): 0.46547901553370696\n",
      "train_mapre: 0.07822962040288538\n",
      "test_mapre: 0.12977017122093298\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m-0.1298  \u001b[39m | \u001b[39m220.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.68687746 -0.20858789 -0.14589369 -0.16955903 -0.46031002]\n",
      "cv_score (mean): 0.3342456175437221\n",
      "train_mapre: 0.13232240496425546\n",
      "test_mapre: 0.1548325006354696\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m-0.1548  \u001b[39m | \u001b[39m474.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m1.911    \u001b[39m |\n",
      "cv_scores (each fold): [-0.96634419 -0.20679564 -0.16305864 -0.1181572  -0.7700688 ]\n",
      "cv_score (mean): 0.44488489338284654\n",
      "train_mapre: 0.04186225769501855\n",
      "test_mapre: 0.12527357035382952\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m-0.1253  \u001b[39m | \u001b[39m340.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m9.052    \u001b[39m |\n",
      "cv_scores (each fold): [-1.02637584 -0.20862137 -0.15319057 -0.11691232 -0.79819507]\n",
      "cv_score (mean): 0.46065903447011547\n",
      "train_mapre: 0.13947861240101794\n",
      "test_mapre: 0.1325837921296061\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m-0.1326  \u001b[39m | \u001b[39m166.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m9.237    \u001b[39m |\n",
      "cv_scores (each fold): [-2.18141733 -0.40878933 -0.32459118 -0.25737468 -1.14774238]\n",
      "cv_score (mean): 0.8639829770354893\n",
      "train_mapre: 0.8202069469271989\n",
      "test_mapre: 0.40731328742103656\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m-0.4073  \u001b[39m | \u001b[39m487.5    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.93495309 -0.20962744 -0.16697267 -0.12418829 -0.75441545]\n",
      "cv_score (mean): 0.438031387897811\n",
      "train_mapre: 0.04176948945304957\n",
      "test_mapre: 0.1209412445878546\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m-0.1209  \u001b[39m | \u001b[39m498.2    \u001b[39m | \u001b[39m0.6623   \u001b[39m | \u001b[39m8.593    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03466902 -0.22691014 -0.1663083  -0.12242517 -0.80514141]\n",
      "cv_score (mean): 0.4710908038438878\n",
      "train_mapre: 0.0369509178137993\n",
      "test_mapre: 0.12988300203089326\n",
      "| \u001b[39m111      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m478.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.73204541 -0.20664865 -0.13271171 -0.16117131 -0.4795334 ]\n",
      "cv_score (mean): 0.34242209492338116\n",
      "train_mapre: 0.14767055826574887\n",
      "test_mapre: 0.15421951461421804\n",
      "| \u001b[39m112      \u001b[39m | \u001b[39m-0.1542  \u001b[39m | \u001b[39m393.4    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m1.973    \u001b[39m |\n",
      "cv_scores (each fold): [-0.38433941 -0.18569974 -0.13101353 -0.14352399 -0.36719081]\n",
      "cv_score (mean): 0.24235349679851587\n",
      "train_mapre: 0.08251750429323784\n",
      "test_mapre: 0.12601422543556698\n",
      "| \u001b[39m113      \u001b[39m | \u001b[39m-0.126   \u001b[39m | \u001b[39m500.0    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m3.155    \u001b[39m |\n",
      "cv_scores (each fold): [-1.16012941 -0.25872802 -0.14930085 -0.21478352 -0.60543475]\n",
      "cv_score (mean): 0.4776753104084405\n",
      "train_mapre: 0.25404731652420126\n",
      "test_mapre: 0.18820622063746925\n",
      "| \u001b[39m114      \u001b[39m | \u001b[39m-0.1882  \u001b[39m | \u001b[39m378.8    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.9892   \u001b[39m |\n",
      "cv_scores (each fold): [-2.33987594 -0.41167044 -0.27982084 -0.21787549 -0.88932484]\n",
      "cv_score (mean): 0.8277135070910815\n",
      "train_mapre: 0.7266179474632278\n",
      "test_mapre: 0.353639757843787\n",
      "| \u001b[39m115      \u001b[39m | \u001b[39m-0.3536  \u001b[39m | \u001b[39m165.0    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.1751   \u001b[39m |\n",
      "cv_scores (each fold): [-0.90839628 -0.19623231 -0.15335164 -0.11870681 -0.71328108]\n",
      "cv_score (mean): 0.417993625391596\n",
      "train_mapre: 0.10845748541807747\n",
      "test_mapre: 0.1209466654750593\n",
      "| \u001b[39m116      \u001b[39m | \u001b[39m-0.1209  \u001b[39m | \u001b[39m179.1    \u001b[39m | \u001b[39m0.804    \u001b[39m | \u001b[39m7.419    \u001b[39m |\n",
      "cv_scores (each fold): [-1.07872933 -0.21247489 -0.15331606 -0.11654404 -0.82808488]\n",
      "cv_score (mean): 0.4778298381435187\n",
      "train_mapre: 0.1591027297154965\n",
      "test_mapre: 0.13740495307259107\n",
      "| \u001b[39m117      \u001b[39m | \u001b[39m-0.1374  \u001b[39m | \u001b[39m152.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05728083 -0.21253549 -0.15585805 -0.11611712 -0.81168141]\n",
      "cv_score (mean): 0.4706945799191343\n",
      "train_mapre: 0.12274083169861769\n",
      "test_mapre: 0.13138706159411467\n",
      "| \u001b[39m118      \u001b[39m | \u001b[39m-0.1314  \u001b[39m | \u001b[39m172.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03051535 -0.21866764 -0.16512338 -0.12263687 -0.80433613]\n",
      "cv_score (mean): 0.4682558737214113\n",
      "train_mapre: 0.03850072931092646\n",
      "test_mapre: 0.13010315065997732\n",
      "| \u001b[39m119      \u001b[39m | \u001b[39m-0.1301  \u001b[39m | \u001b[39m390.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06889649 -0.21267794 -0.1546425  -0.11589162 -0.81312696]\n",
      "cv_score (mean): 0.47304710264962785\n",
      "train_mapre: 0.13646110866876734\n",
      "test_mapre: 0.13248108075807674\n",
      "| \u001b[39m120      \u001b[39m | \u001b[39m-0.1325  \u001b[39m | \u001b[39m159.8    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.09513001 -0.35164674 -0.18948286 -0.22097993 -0.66839557]\n",
      "cv_score (mean): 0.7051270245789458\n",
      "train_mapre: 0.5605492169077531\n",
      "test_mapre: 0.285578865929608\n",
      "| \u001b[39m121      \u001b[39m | \u001b[39m-0.2856  \u001b[39m | \u001b[39m184.1    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.3729   \u001b[39m |\n",
      "cv_scores (each fold): [-0.66779093 -0.18692437 -0.12894997 -0.1401128  -0.44025132]\n",
      "cv_score (mean): 0.31280587986599173\n",
      "train_mapre: 0.08454729866419132\n",
      "test_mapre: 0.11825075882286068\n",
      "| \u001b[39m122      \u001b[39m | \u001b[39m-0.1183  \u001b[39m | \u001b[39m321.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m3.423    \u001b[39m |\n",
      "cv_scores (each fold): [-0.72461775 -0.19090331 -0.15847248 -0.11904187 -0.65166453]\n",
      "cv_score (mean): 0.36893998644384735\n",
      "train_mapre: 0.04768888982910081\n",
      "test_mapre: 0.11306034433877965\n",
      "| \u001b[39m123      \u001b[39m | \u001b[39m-0.1131  \u001b[39m | \u001b[39m406.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m6.733    \u001b[39m |\n",
      "cv_scores (each fold): [-1.22794043 -0.27161555 -0.15760068 -0.22049697 -0.64833699]\n",
      "cv_score (mean): 0.5051981224026806\n",
      "train_mapre: 0.27992659684054766\n",
      "test_mapre: 0.19466032397056907\n",
      "| \u001b[39m124      \u001b[39m | \u001b[39m-0.1947  \u001b[39m | \u001b[39m408.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.8802   \u001b[39m |\n",
      "cv_scores (each fold): [-1.03180637 -0.21035071 -0.16177296 -0.11870097 -0.80270847]\n",
      "cv_score (mean): 0.4650678948243138\n",
      "train_mapre: 0.04116748184544026\n",
      "test_mapre: 0.1297332255862501\n",
      "| \u001b[39m125      \u001b[39m | \u001b[39m-0.1297  \u001b[39m | \u001b[39m289.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03206445 -0.21072481 -0.16242432 -0.11945257 -0.80339854]\n",
      "cv_score (mean): 0.465612938137604\n",
      "train_mapre: 0.04075223086956525\n",
      "test_mapre: 0.1296199223938943\n",
      "| \u001b[39m126      \u001b[39m | \u001b[39m-0.1296  \u001b[39m | \u001b[39m303.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03183431 -0.21264683 -0.16310158 -0.12073784 -0.8043056 ]\n",
      "cv_score (mean): 0.4665252306247359\n",
      "train_mapre: 0.040172137105148116\n",
      "test_mapre: 0.1295732639408156\n",
      "| \u001b[39m127      \u001b[39m | \u001b[39m-0.1296  \u001b[39m | \u001b[39m324.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m9.996    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03592383 -0.22767036 -0.16636768 -0.12245343 -0.80543843]\n",
      "cv_score (mean): 0.47157074722206926\n",
      "train_mapre: 0.036833116687413514\n",
      "test_mapre: 0.12971242905889635\n",
      "| \u001b[39m128      \u001b[39m | \u001b[39m-0.1297  \u001b[39m | \u001b[39m491.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05878836 -0.2120457  -0.15703579 -0.11636819 -0.81912084]\n",
      "cv_score (mean): 0.47267177558009515\n",
      "train_mapre: 0.08018419085843008\n",
      "test_mapre: 0.13205112805809946\n",
      "| \u001b[39m129      \u001b[39m | \u001b[39m-0.1321  \u001b[39m | \u001b[39m228.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03007417 -0.22136214 -0.1658741  -0.12243592 -0.80398037]\n",
      "cv_score (mean): 0.4687453398605822\n",
      "train_mapre: 0.03781021670888193\n",
      "test_mapre: 0.1299563443904293\n",
      "| \u001b[39m130      \u001b[39m | \u001b[39m-0.13    \u001b[39m | \u001b[39m419.1    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03943892 -0.21198342 -0.15769794 -0.11640999 -0.80882546]\n",
      "cv_score (mean): 0.4668711468113879\n",
      "train_mapre: 0.10273065594946267\n",
      "test_mapre: 0.1297564394708307\n",
      "| \u001b[39m131      \u001b[39m | \u001b[39m-0.1298  \u001b[39m | \u001b[39m190.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06259521 -0.21742894 -0.15722343 -0.11800707 -0.8210983 ]\n",
      "cv_score (mean): 0.4752705898620285\n",
      "train_mapre: 0.05466936469526981\n",
      "test_mapre: 0.13079504985045565\n",
      "| \u001b[39m132      \u001b[39m | \u001b[39m-0.1308  \u001b[39m | \u001b[39m408.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05988723 -0.22038478 -0.15901137 -0.11731506 -0.82218483]\n",
      "cv_score (mean): 0.4757566561457166\n",
      "train_mapre: 0.0541347832322762\n",
      "test_mapre: 0.13035398471110898\n",
      "| \u001b[39m133      \u001b[39m | \u001b[39m-0.1304  \u001b[39m | \u001b[39m463.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.10885113 -0.21370103 -0.15153479 -0.11729519 -0.84679922]\n",
      "cv_score (mean): 0.48763627225462763\n",
      "train_mapre: 0.18860779520059326\n",
      "test_mapre: 0.13939960151013897\n",
      "| \u001b[39m134      \u001b[39m | \u001b[39m-0.1394  \u001b[39m | \u001b[39m130.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.14289146 -0.40552028 -0.32597566 -0.25925237 -1.14007556]\n",
      "cv_score (mean): 0.8547430649246592\n",
      "train_mapre: 0.8220284820926111\n",
      "test_mapre: 0.4112623626776877\n",
      "| \u001b[39m135      \u001b[39m | \u001b[39m-0.4113  \u001b[39m | \u001b[39m428.5    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05856354 -0.21936068 -0.15775006 -0.1175977  -0.82162937]\n",
      "cv_score (mean): 0.4749802709293503\n",
      "train_mapre: 0.05434494202479948\n",
      "test_mapre: 0.1306151999630065\n",
      "| \u001b[39m136      \u001b[39m | \u001b[39m-0.1306  \u001b[39m | \u001b[39m435.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.0651342  -0.21568063 -0.15669157 -0.11846418 -0.81986058]\n",
      "cv_score (mean): 0.47516623302252387\n",
      "train_mapre: 0.05515193378305933\n",
      "test_mapre: 0.13051228132662435\n",
      "| \u001b[39m137      \u001b[39m | \u001b[39m-0.1305  \u001b[39m | \u001b[39m383.5    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.13922753 -0.21399405 -0.14908016 -0.11530895 -0.84342962]\n",
      "cv_score (mean): 0.4922080626510582\n",
      "train_mapre: 0.19071951599754383\n",
      "test_mapre: 0.13726367961573516\n",
      "| \u001b[39m138      \u001b[39m | \u001b[39m-0.1373  \u001b[39m | \u001b[39m119.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.04724737 -0.41071698 -0.32858069 -0.25525809 -1.1791551 ]\n",
      "cv_score (mean): 0.8441916460376468\n",
      "train_mapre: 0.8169096358237347\n",
      "test_mapre: 0.4141332431512549\n",
      "| \u001b[39m139      \u001b[39m | \u001b[39m-0.4141  \u001b[39m | \u001b[39m318.5    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05253864 -0.209955   -0.15567807 -0.1195148  -0.81188793]\n",
      "cv_score (mean): 0.46991488544132665\n",
      "train_mapre: 0.05660177381526151\n",
      "test_mapre: 0.12924328399790547\n",
      "| \u001b[39m140      \u001b[39m | \u001b[39m-0.1292  \u001b[39m | \u001b[39m319.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m9.869    \u001b[39m |\n",
      "cv_scores (each fold): [-0.69728433 -0.19491957 -0.15264011 -0.12302647 -0.64039306]\n",
      "cv_score (mean): 0.3616527082271298\n",
      "train_mapre: 0.06554152832576722\n",
      "test_mapre: 0.11836999769493604\n",
      "| \u001b[39m141      \u001b[39m | \u001b[39m-0.1184  \u001b[39m | \u001b[39m326.3    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m6.373    \u001b[39m |\n",
      "cv_scores (each fold): [-1.89237328 -0.41693867 -0.32520868 -0.274565   -1.27706924]\n",
      "cv_score (mean): 0.8372309741226396\n",
      "train_mapre: 0.8181353112568989\n",
      "test_mapre: 0.41934039491273306\n",
      "| \u001b[39m142      \u001b[39m | \u001b[39m-0.4193  \u001b[39m | \u001b[39m128.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05836168 -0.21151546 -0.15550244 -0.11771478 -0.81672044]\n",
      "cv_score (mean): 0.4719629600862353\n",
      "train_mapre: 0.05813390539850246\n",
      "test_mapre: 0.12940099266036156\n",
      "| \u001b[39m143      \u001b[39m | \u001b[39m-0.1294  \u001b[39m | \u001b[39m262.5    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06462245 -0.21133681 -0.15689823 -0.11526722 -0.82244007]\n",
      "cv_score (mean): 0.4741129541597611\n",
      "train_mapre: 0.11879861901789743\n",
      "test_mapre: 0.13406796337490867\n",
      "| \u001b[39m144      \u001b[39m | \u001b[39m-0.1341  \u001b[39m | \u001b[39m183.5    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.68896341 -0.18774708 -0.13898631 -0.12963377 -0.50606798]\n",
      "cv_score (mean): 0.33027970838227255\n",
      "train_mapre: 0.06257917891590038\n",
      "test_mapre: 0.1113747611092788\n",
      "| \u001b[35m145      \u001b[39m | \u001b[35m-0.1114  \u001b[39m | \u001b[35m259.4    \u001b[39m | \u001b[35m0.1      \u001b[39m | \u001b[35m4.781    \u001b[39m |\n",
      "cv_scores (each fold): [-1.06400844 -0.21207269 -0.1574774  -0.1151695  -0.82146236]\n",
      "cv_score (mean): 0.4740380786060429\n",
      "train_mapre: 0.10297305029244354\n",
      "test_mapre: 0.13377762873469043\n",
      "| \u001b[39m146      \u001b[39m | \u001b[39m-0.1338  \u001b[39m | \u001b[39m197.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.02495767 -0.41514302 -0.32369736 -0.2634893  -1.22035116]\n",
      "cv_score (mean): 0.849527703055046\n",
      "train_mapre: 0.8134973661958883\n",
      "test_mapre: 0.411837539025795\n",
      "| \u001b[39m147      \u001b[39m | \u001b[39m-0.4118  \u001b[39m | \u001b[39m260.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03166621 -0.21150643 -0.16019046 -0.11722805 -0.80307722]\n",
      "cv_score (mean): 0.4647336745212363\n",
      "train_mapre: 0.05503551424603163\n",
      "test_mapre: 0.1298851492239449\n",
      "| \u001b[39m148      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m258.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.81328478 -0.19758918 -0.15632475 -0.11703092 -0.70390212]\n",
      "cv_score (mean): 0.3976263483645005\n",
      "train_mapre: 0.05961070220130953\n",
      "test_mapre: 0.11691420566164022\n",
      "| \u001b[39m149      \u001b[39m | \u001b[39m-0.1169  \u001b[39m | \u001b[39m264.3    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m7.527    \u001b[39m |\n",
      "cv_scores (each fold): [-1.09169652 -0.21225457 -0.15037064 -0.11545789 -0.82126301]\n",
      "cv_score (mean): 0.47820852410958475\n",
      "train_mapre: 0.16798396602017193\n",
      "test_mapre: 0.13289283246380654\n",
      "| \u001b[39m150      \u001b[39m | \u001b[39m-0.1329  \u001b[39m | \u001b[39m133.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m9.682    \u001b[39m |\n",
      "cv_scores (each fold): [-0.94535501 -0.2005859  -0.15116219 -0.11870805 -0.7539924 ]\n",
      "cv_score (mean): 0.433960709644069\n",
      "train_mapre: 0.1254068923459367\n",
      "test_mapre: 0.12803064537948858\n",
      "| \u001b[39m151      \u001b[39m | \u001b[39m-0.128   \u001b[39m | \u001b[39m175.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m8.063    \u001b[39m |\n",
      "cv_scores (each fold): [-0.74721653 -0.18961685 -0.1551307  -0.12311118 -0.61882089]\n",
      "cv_score (mean): 0.3667792298539275\n",
      "train_mapre: 0.06963356910608665\n",
      "test_mapre: 0.11299705398273552\n",
      "| \u001b[39m152      \u001b[39m | \u001b[39m-0.113   \u001b[39m | \u001b[39m233.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m6.175    \u001b[39m |\n",
      "cv_scores (each fold): [-1.42455311 -0.27818489 -0.15860643 -0.22861716 -0.67030724]\n",
      "cv_score (mean): 0.5520537672991366\n",
      "train_mapre: 0.34760198907561995\n",
      "test_mapre: 0.20899395166463478\n",
      "| \u001b[39m153      \u001b[39m | \u001b[39m-0.209   \u001b[39m | \u001b[39m231.7    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.9221   \u001b[39m |\n",
      "cv_scores (each fold): [-0.44217145 -0.18497754 -0.13059742 -0.13506536 -0.3932027 ]\n",
      "cv_score (mean): 0.2572028940021342\n",
      "train_mapre: 0.0638249010040549\n",
      "test_mapre: 0.1194723196310012\n",
      "| \u001b[39m154      \u001b[39m | \u001b[39m-0.1195  \u001b[39m | \u001b[39m399.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m3.883    \u001b[39m |\n",
      "cv_scores (each fold): [-2.21750189 -0.40459323 -0.32548632 -0.25588518 -1.13449788]\n",
      "cv_score (mean): 0.8675928989008431\n",
      "train_mapre: 0.8270160559457446\n",
      "test_mapre: 0.4093039775728507\n",
      "| \u001b[39m155      \u001b[39m | \u001b[39m-0.4093  \u001b[39m | \u001b[39m499.4    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.92850512 -0.20358132 -0.1626493  -0.118319   -0.755437  ]\n",
      "cv_score (mean): 0.4336983508498934\n",
      "train_mapre: 0.056931366264623265\n",
      "test_mapre: 0.1211959816525495\n",
      "| \u001b[39m156      \u001b[39m | \u001b[39m-0.1212  \u001b[39m | \u001b[39m495.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m8.27     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05984046 -0.21096974 -0.15520147 -0.11851432 -0.81579033]\n",
      "cv_score (mean): 0.47206326359451045\n",
      "train_mapre: 0.05745308057970363\n",
      "test_mapre: 0.12963119212156618\n",
      "| \u001b[39m157      \u001b[39m | \u001b[39m-0.1296  \u001b[39m | \u001b[39m284.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.70094208 -0.20419707 -0.13984519 -0.16620042 -0.43297988]\n",
      "cv_score (mean): 0.32883292921280693\n",
      "train_mapre: 0.12056027361886709\n",
      "test_mapre: 0.1377928443176873\n",
      "| \u001b[39m158      \u001b[39m | \u001b[39m-0.1378  \u001b[39m | \u001b[39m417.5    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m2.224    \u001b[39m |\n",
      "cv_scores (each fold): [-1.12236114 -0.21391872 -0.14997378 -0.11497857 -0.83699606]\n",
      "cv_score (mean): 0.4876456556001223\n",
      "train_mapre: 0.17938364148928584\n",
      "test_mapre: 0.1350889228073805\n",
      "| \u001b[39m159      \u001b[39m | \u001b[39m-0.1351  \u001b[39m | \u001b[39m126.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.51561931 -0.18904103 -0.12781602 -0.15097882 -0.38980595]\n",
      "cv_score (mean): 0.27465222349329854\n",
      "train_mapre: 0.08743378731435428\n",
      "test_mapre: 0.1197904881904137\n",
      "| \u001b[39m160      \u001b[39m | \u001b[39m-0.1198  \u001b[39m | \u001b[39m469.3    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m2.797    \u001b[39m |\n",
      "cv_scores (each fold): [-1.23742586 -0.21920116 -0.1478567  -0.11642327 -0.88423206]\n",
      "cv_score (mean): 0.5210278102692528\n",
      "train_mapre: 0.27752516532574073\n",
      "test_mapre: 0.14740261624517553\n",
      "| \u001b[39m161      \u001b[39m | \u001b[39m-0.1474  \u001b[39m | \u001b[39m86.48    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06317596 -0.22080936 -0.16050584 -0.11730227 -0.82255115]\n",
      "cv_score (mean): 0.4768689158384366\n",
      "train_mapre: 0.05398484279999397\n",
      "test_mapre: 0.13016753170966439\n",
      "| \u001b[39m162      \u001b[39m | \u001b[39m-0.1302  \u001b[39m | \u001b[39m483.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.15088073 -0.21428285 -0.14907343 -0.1184027  -0.86442723]\n",
      "cv_score (mean): 0.49941338728674334\n",
      "train_mapre: 0.21335009317553655\n",
      "test_mapre: 0.1376593336007557\n",
      "| \u001b[39m163      \u001b[39m | \u001b[39m-0.1377  \u001b[39m | \u001b[39m113.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.83096591 -0.19913686 -0.13541777 -0.14680683 -0.46147522]\n",
      "cv_score (mean): 0.3547605174933288\n",
      "train_mapre: 0.14266408089911156\n",
      "test_mapre: 0.1241344489920863\n",
      "| \u001b[39m164      \u001b[39m | \u001b[39m-0.1241  \u001b[39m | \u001b[39m220.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m3.318    \u001b[39m |\n",
      "cv_scores (each fold): [-1.12869863 -0.21424753 -0.15051602 -0.11765636 -0.85597892]\n",
      "cv_score (mean): 0.493419491133924\n",
      "train_mapre: 0.19955472244930336\n",
      "test_mapre: 0.13792616152211915\n",
      "| \u001b[39m165      \u001b[39m | \u001b[39m-0.1379  \u001b[39m | \u001b[39m121.7    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05864576 -0.21199439 -0.1567239  -0.11668144 -0.81871255]\n",
      "cv_score (mean): 0.4725516069073496\n",
      "train_mapre: 0.07433923358985949\n",
      "test_mapre: 0.13120386716131968\n",
      "| \u001b[39m166      \u001b[39m | \u001b[39m-0.1312  \u001b[39m | \u001b[39m236.3    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.95289769 -0.2060814  -0.15681989 -0.1160316  -0.76526328]\n",
      "cv_score (mean): 0.4394187719529959\n",
      "train_mapre: 0.08829149768751468\n",
      "test_mapre: 0.12670828898277067\n",
      "| \u001b[39m167      \u001b[39m | \u001b[39m-0.1267  \u001b[39m | \u001b[39m221.7    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m8.574    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03017868 -0.22065768 -0.16570737 -0.12249846 -0.80407329]\n",
      "cv_score (mean): 0.46862309422759807\n",
      "train_mapre: 0.03798790850837294\n",
      "test_mapre: 0.13001905414141815\n",
      "| \u001b[39m168      \u001b[39m | \u001b[39m-0.13    \u001b[39m | \u001b[39m411.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05846302 -0.21194616 -0.15624149 -0.11703333 -0.81835433]\n",
      "cv_score (mean): 0.4724076651652644\n",
      "train_mapre: 0.06707371013980282\n",
      "test_mapre: 0.1301929521469133\n",
      "| \u001b[39m169      \u001b[39m | \u001b[39m-0.1302  \u001b[39m | \u001b[39m246.0    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.86714641 -0.19993757 -0.16000768 -0.11774879 -0.72021893]\n",
      "cv_score (mean): 0.41301187440898435\n",
      "train_mapre: 0.05875444196328149\n",
      "test_mapre: 0.12049850216563837\n",
      "| \u001b[39m170      \u001b[39m | \u001b[39m-0.1205  \u001b[39m | \u001b[39m476.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m7.573    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03034807 -0.21974841 -0.16547272 -0.12256474 -0.8041929 ]\n",
      "cv_score (mean): 0.46846536797648275\n",
      "train_mapre: 0.038218355845522675\n",
      "test_mapre: 0.1300637724905911\n",
      "| \u001b[39m171      \u001b[39m | \u001b[39m-0.1301  \u001b[39m | \u001b[39m402.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06058233 -0.2184857  -0.15751835 -0.11780483 -0.82135974]\n",
      "cv_score (mean): 0.47515018861928543\n",
      "train_mapre: 0.05444734543067885\n",
      "test_mapre: 0.1307420035943842\n",
      "| \u001b[39m172      \u001b[39m | \u001b[39m-0.1307  \u001b[39m | \u001b[39m421.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.77148445 -0.30298552 -0.17811114 -0.24324735 -0.67966042]\n",
      "cv_score (mean): 0.6350977750702763\n",
      "train_mapre: 0.4003377066285505\n",
      "test_mapre: 0.23670513700150825\n",
      "| \u001b[39m173      \u001b[39m | \u001b[39m-0.2367  \u001b[39m | \u001b[39m270.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.5951   \u001b[39m |\n",
      "cv_scores (each fold): [-0.77341387 -0.21656887 -0.14559314 -0.16638142 -0.5260726 ]\n",
      "cv_score (mean): 0.36560598142793105\n",
      "train_mapre: 0.18391014322328728\n",
      "test_mapre: 0.1698417593234594\n",
      "| \u001b[39m174      \u001b[39m | \u001b[39m-0.1698  \u001b[39m | \u001b[39m370.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m1.647    \u001b[39m |\n",
      "cv_scores (each fold): [-0.97693494 -0.20851593 -0.15851659 -0.11718656 -0.78118587]\n",
      "cv_score (mean): 0.44846797906200864\n",
      "train_mapre: 0.08303756975300827\n",
      "test_mapre: 0.12597789549917146\n",
      "| \u001b[39m175      \u001b[39m | \u001b[39m-0.126   \u001b[39m | \u001b[39m213.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m9.237    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03278197 -0.21204599 -0.15893219 -0.11608354 -0.80562992]\n",
      "cv_score (mean): 0.4650947208315487\n",
      "train_mapre: 0.07317221628811671\n",
      "test_mapre: 0.1298633618920244\n",
      "| \u001b[39m176      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m228.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.64230359 -0.18951141 -0.15473715 -0.12334534 -0.61565457]\n",
      "cv_score (mean): 0.3451104115801734\n",
      "train_mapre: 0.05106698838058125\n",
      "test_mapre: 0.11103090279369834\n",
      "| \u001b[35m177      \u001b[39m | \u001b[35m-0.111   \u001b[39m | \u001b[35m347.8    \u001b[39m | \u001b[35m0.1      \u001b[39m | \u001b[35m6.256    \u001b[39m |\n",
      "cv_scores (each fold): [-1.06291499 -0.21350667 -0.15604046 -0.11910959 -0.81824947]\n",
      "cv_score (mean): 0.4739642362249318\n",
      "train_mapre: 0.05571659141430023\n",
      "test_mapre: 0.1303401168623867\n",
      "| \u001b[39m178      \u001b[39m | \u001b[39m-0.1303  \u001b[39m | \u001b[39m352.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.10167346 -0.40595499 -0.32658345 -0.2575998  -1.14964685]\n",
      "cv_score (mean): 0.8482917101837593\n",
      "train_mapre: 0.8195352906514971\n",
      "test_mapre: 0.41238959881061926\n",
      "| \u001b[39m179      \u001b[39m | \u001b[39m-0.4124  \u001b[39m | \u001b[39m388.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.92637993 -0.20399153 -0.15675209 -0.11689216 -0.75154976]\n",
      "cv_score (mean): 0.4311130946041365\n",
      "train_mapre: 0.05868788548649283\n",
      "test_mapre: 0.12200267335832554\n",
      "| \u001b[39m180      \u001b[39m | \u001b[39m-0.122   \u001b[39m | \u001b[39m389.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m8.227    \u001b[39m |\n",
      "cv_scores (each fold): [-0.92776427 -0.20442993 -0.16351314 -0.11753328 -0.74969419]\n",
      "cv_score (mean): 0.43258696169545774\n",
      "train_mapre: 0.04217213315854983\n",
      "test_mapre: 0.12266472730060332\n",
      "| \u001b[39m181      \u001b[39m | \u001b[39m-0.1227  \u001b[39m | \u001b[39m382.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m8.529    \u001b[39m |\n",
      "cv_scores (each fold): [-0.95080781 -0.20511848 -0.1584161  -0.11537309 -0.75917419]\n",
      "cv_score (mean): 0.4377779344532451\n",
      "train_mapre: 0.06022578589373367\n",
      "test_mapre: 0.12206501157553402\n",
      "| \u001b[39m182      \u001b[39m | \u001b[39m-0.1221  \u001b[39m | \u001b[39m301.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m8.442    \u001b[39m |\n",
      "cv_scores (each fold): [-0.50886587 -0.18619909 -0.14447755 -0.13023938 -0.49880166]\n",
      "cv_score (mean): 0.2937167112651713\n",
      "train_mapre: 0.07225774842824374\n",
      "test_mapre: 0.11726277247787065\n",
      "| \u001b[39m183      \u001b[39m | \u001b[39m-0.1173  \u001b[39m | \u001b[39m381.3    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m4.872    \u001b[39m |\n",
      "cv_scores (each fold): [-0.93921953 -0.20723171 -0.16621102 -0.12381594 -0.75126062]\n",
      "cv_score (mean): 0.4375477659594214\n",
      "train_mapre: 0.04057181372778806\n",
      "test_mapre: 0.12192733145120377\n",
      "| \u001b[39m184      \u001b[39m | \u001b[39m-0.1219  \u001b[39m | \u001b[39m465.5    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m8.547    \u001b[39m |\n",
      "cv_scores (each fold): [-1.33936812 -0.23775571 -0.15144939 -0.13084455 -0.93937046]\n",
      "cv_score (mean): 0.5597576469769258\n",
      "train_mapre: 0.3588484086044196\n",
      "test_mapre: 0.16314385539121445\n",
      "| \u001b[39m185      \u001b[39m | \u001b[39m-0.1631  \u001b[39m | \u001b[39m59.47    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06045921 -0.21059725 -0.15536659 -0.1187085  -0.81542618]\n",
      "cv_score (mean): 0.4721115427044086\n",
      "train_mapre: 0.057131809115773306\n",
      "test_mapre: 0.1297375882962896\n",
      "| \u001b[39m186      \u001b[39m | \u001b[39m-0.1297  \u001b[39m | \u001b[39m292.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03089573 -0.2161895  -0.1642512  -0.12209927 -0.80471656]\n",
      "cv_score (mean): 0.46763045201993825\n",
      "train_mapre: 0.03918491748433713\n",
      "test_mapre: 0.12994116231665154\n",
      "| \u001b[39m187      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m362.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.86422615 -0.41331816 -0.32630917 -0.28930785 -1.29745601]\n",
      "cv_score (mean): 0.8381234670865709\n",
      "train_mapre: 0.8148894653870937\n",
      "test_mapre: 0.4216523197004069\n",
      "| \u001b[39m188      \u001b[39m | \u001b[39m-0.4217  \u001b[39m | \u001b[39m87.67    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.24753016 -0.22442341 -0.14617256 -0.11857791 -0.9082024 ]\n",
      "cv_score (mean): 0.5289812873936695\n",
      "train_mapre: 0.30030727175978555\n",
      "test_mapre: 0.14796662203083075\n",
      "| \u001b[39m189      \u001b[39m | \u001b[39m-0.148   \u001b[39m | \u001b[39m81.25    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.86537626 -0.19902584 -0.15902093 -0.11602282 -0.71819644]\n",
      "cv_score (mean): 0.4115284594952386\n",
      "train_mapre: 0.061955136630522135\n",
      "test_mapre: 0.12056202508250496\n",
      "| \u001b[39m190      \u001b[39m | \u001b[39m-0.1206  \u001b[39m | \u001b[39m313.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m7.553    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03028266 -0.22313943 -0.16598966 -0.12234617 -0.80415345]\n",
      "cv_score (mean): 0.4691822754576096\n",
      "train_mapre: 0.03751032599477138\n",
      "test_mapre: 0.1299195951521644\n",
      "| \u001b[39m191      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m437.8    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.09456143 -0.41023647 -0.32627247 -0.26520018 -1.17170178]\n",
      "cv_score (mean): 0.8535944662420871\n",
      "train_mapre: 0.8155054961440377\n",
      "test_mapre: 0.4101604588471599\n",
      "| \u001b[39m192      \u001b[39m | \u001b[39m-0.4102  \u001b[39m | \u001b[39m399.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.8851564  -0.20007053 -0.16193188 -0.11656868 -0.72089079]\n",
      "cv_score (mean): 0.41692365593815445\n",
      "train_mapre: 0.04362898531906529\n",
      "test_mapre: 0.11940433998140064\n",
      "| \u001b[39m193      \u001b[39m | \u001b[39m-0.1194  \u001b[39m | \u001b[39m396.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m7.908    \u001b[39m |\n",
      "cv_scores (each fold): [-1.16736701 -0.21462707 -0.14764799 -0.1160683  -0.85431478]\n",
      "cv_score (mean): 0.5000050315428497\n",
      "train_mapre: 0.21519779430250152\n",
      "test_mapre: 0.14208031758816392\n",
      "| \u001b[39m194      \u001b[39m | \u001b[39m-0.1421  \u001b[39m | \u001b[39m109.3    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.85713058 -0.4199649  -0.32778673 -0.29074675 -1.32681244]\n",
      "cv_score (mean): 0.8444882805362713\n",
      "train_mapre: 0.8224698153166665\n",
      "test_mapre: 0.4250376882649859\n",
      "| \u001b[39m195      \u001b[39m | \u001b[39m-0.425   \u001b[39m | \u001b[39m53.93    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-2.04855454 -0.41087317 -0.32848929 -0.25538524 -1.19830529]\n",
      "cv_score (mean): 0.8483215046090564\n",
      "train_mapre: 0.819201088682486\n",
      "test_mapre: 0.4140931760806257\n",
      "| \u001b[39m196      \u001b[39m | \u001b[39m-0.4141  \u001b[39m | \u001b[39m299.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.74833881 -0.19272091 -0.15768339 -0.11846035 -0.66484487]\n",
      "cv_score (mean): 0.3764096662340699\n",
      "train_mapre: 0.048016741096496666\n",
      "test_mapre: 0.11310281584984574\n",
      "| \u001b[39m197      \u001b[39m | \u001b[39m-0.1131  \u001b[39m | \u001b[39m371.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m6.925    \u001b[39m |\n",
      "cv_scores (each fold): [-1.06259625 -0.2120877  -0.15743351 -0.11534633 -0.82093505]\n",
      "cv_score (mean): 0.4736797696676819\n",
      "train_mapre: 0.09721394446012964\n",
      "test_mapre: 0.13374913848350858\n",
      "| \u001b[39m198      \u001b[39m | \u001b[39m-0.1337  \u001b[39m | \u001b[39m205.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06269526 -0.21244712 -0.15588809 -0.11934585 -0.81759236]\n",
      "cv_score (mean): 0.47359373475712585\n",
      "train_mapre: 0.055977195524012806\n",
      "test_mapre: 0.13023367922715953\n",
      "| \u001b[39m199      \u001b[39m | \u001b[39m-0.1302  \u001b[39m | \u001b[39m338.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03415741 -0.21193341 -0.15799085 -0.11631541 -0.8075701 ]\n",
      "cv_score (mean): 0.46559343794973335\n",
      "train_mapre: 0.09435764627865974\n",
      "test_mapre: 0.12960179953314216\n",
      "| \u001b[39m200      \u001b[39m | \u001b[39m-0.1296  \u001b[39m | \u001b[39m198.5    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.55754974 -0.18650827 -0.14514533 -0.12903247 -0.52505328]\n",
      "cv_score (mean): 0.3086578193113209\n",
      "train_mapre: 0.07195697819179273\n",
      "test_mapre: 0.11704676869986272\n",
      "| \u001b[39m201      \u001b[39m | \u001b[39m-0.117   \u001b[39m | \u001b[39m349.4    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m5.086    \u001b[39m |\n",
      "cv_scores (each fold): [-1.08067042 -0.21299732 -0.15348734 -0.11561743 -0.82105225]\n",
      "cv_score (mean): 0.47676495499225424\n",
      "train_mapre: 0.15154213494321564\n",
      "test_mapre: 0.13377121463420852\n",
      "| \u001b[39m202      \u001b[39m | \u001b[39m-0.1338  \u001b[39m | \u001b[39m148.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05875278 -0.21138934 -0.15530017 -0.11793479 -0.81649751]\n",
      "cv_score (mean): 0.4719749177577543\n",
      "train_mapre: 0.05796844781159542\n",
      "test_mapre: 0.12943149097372172\n",
      "| \u001b[39m203      \u001b[39m | \u001b[39m-0.1294  \u001b[39m | \u001b[39m268.2    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.21297581 -0.21850001 -0.14776328 -0.11630166 -0.87488537]\n",
      "cv_score (mean): 0.5140852278463701\n",
      "train_mapre: 0.25846182788391503\n",
      "test_mapre: 0.1457885987575251\n",
      "| \u001b[39m204      \u001b[39m | \u001b[39m-0.1458  \u001b[39m | \u001b[39m93.49    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.86751229 -0.41520153 -0.32763262 -0.27939732 -1.30507673]\n",
      "cv_score (mean): 0.8389640979212076\n",
      "train_mapre: 0.8214155848281195\n",
      "test_mapre: 0.4233090577920043\n",
      "| \u001b[39m205      \u001b[39m | \u001b[39m-0.4233  \u001b[39m | \u001b[39m77.14    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05832033 -0.21170626 -0.15584203 -0.11728962 -0.81749431]\n",
      "cv_score (mean): 0.4721305100237984\n",
      "train_mapre: 0.061262127515903396\n",
      "test_mapre: 0.12943505711918224\n",
      "| \u001b[39m206      \u001b[39m | \u001b[39m-0.1294  \u001b[39m | \u001b[39m254.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06501986 -0.21168157 -0.15728636 -0.11512103 -0.82191598]\n",
      "cv_score (mean): 0.47420495847512356\n",
      "train_mapre: 0.1096621425246028\n",
      "test_mapre: 0.13388344915268663\n",
      "| \u001b[39m207      \u001b[39m | \u001b[39m-0.1339  \u001b[39m | \u001b[39m191.7    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03042206 -0.21547305 -0.16401557 -0.12187366 -0.80493792]\n",
      "cv_score (mean): 0.46734445205077035\n",
      "train_mapre: 0.03937256115448337\n",
      "test_mapre: 0.1298583181564172\n",
      "| \u001b[39m208      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m354.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.06562273 -0.41088342 -0.32604804 -0.26538332 -1.18503792]\n",
      "cv_score (mean): 0.8505950856933724\n",
      "train_mapre: 0.8202318602514795\n",
      "test_mapre: 0.41101172144922804\n",
      "| \u001b[39m209      \u001b[39m | \u001b[39m-0.411   \u001b[39m | \u001b[39m327.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-2.11029676 -0.41021189 -0.32604862 -0.26382002 -1.16875591]\n",
      "cv_score (mean): 0.8558266403629021\n",
      "train_mapre: 0.8168192875732541\n",
      "test_mapre: 0.4094874014225033\n",
      "| \u001b[39m210      \u001b[39m | \u001b[39m-0.4095  \u001b[39m | \u001b[39m415.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.88038531 -0.41196288 -0.32531233 -0.28780589 -1.27281308]\n",
      "cv_score (mean): 0.8356558976857329\n",
      "train_mapre: 0.8126499607668644\n",
      "test_mapre: 0.41872609331785376\n",
      "| \u001b[39m211      \u001b[39m | \u001b[39m-0.4187  \u001b[39m | \u001b[39m114.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.69085591 -0.18778284 -0.15036438 -0.12621268 -0.56629253]\n",
      "cv_score (mean): 0.34430166841378484\n",
      "train_mapre: 0.0590577346601228\n",
      "test_mapre: 0.11068938535377873\n",
      "| \u001b[35m212      \u001b[39m | \u001b[35m-0.1107  \u001b[39m | \u001b[35m253.6    \u001b[39m | \u001b[35m0.1      \u001b[39m | \u001b[35m5.571    \u001b[39m |\n",
      "cv_scores (each fold): [-2.05014157 -0.40997359 -0.32784514 -0.2555584  -1.20819624]\n",
      "cv_score (mean): 0.8503429888572704\n",
      "train_mapre: 0.8206005179397199\n",
      "test_mapre: 0.41418914259050843\n",
      "| \u001b[39m213      \u001b[39m | \u001b[39m-0.4142  \u001b[39m | \u001b[39m284.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-1.03158797 -0.2242996  -0.16613278 -0.12236016 -0.80444788]\n",
      "cv_score (mean): 0.46976567850903483\n",
      "train_mapre: 0.037331826053551787\n",
      "test_mapre: 0.12989768911858104\n",
      "| \u001b[39m214      \u001b[39m | \u001b[39m-0.1299  \u001b[39m | \u001b[39m450.0    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06590838 -0.2212146  -0.16174853 -0.11726341 -0.822853  ]\n",
      "cv_score (mean): 0.47779758264639727\n",
      "train_mapre: 0.053873568471215945\n",
      "test_mapre: 0.13003729729584088\n",
      "| \u001b[39m215      \u001b[39m | \u001b[39m-0.13    \u001b[39m | \u001b[39m500.0    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06263711 -0.21401786 -0.15619763 -0.11897085 -0.81860237]\n",
      "cv_score (mean): 0.4740851621183165\n",
      "train_mapre: 0.05558505603009369\n",
      "test_mapre: 0.13039793659490442\n",
      "| \u001b[39m216      \u001b[39m | \u001b[39m-0.1304  \u001b[39m | \u001b[39m359.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05845257 -0.22020878 -0.1586222  -0.11735018 -0.82201963]\n",
      "cv_score (mean): 0.47533067160134657\n",
      "train_mapre: 0.05419768274006641\n",
      "test_mapre: 0.13043158751914452\n",
      "| \u001b[39m217      \u001b[39m | \u001b[39m-0.1304  \u001b[39m | \u001b[39m455.4    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.05713303 -0.22004555 -0.15826356 -0.11741411 -0.82186726]\n",
      "cv_score (mean): 0.4749447010297593\n",
      "train_mapre: 0.054254853435997945\n",
      "test_mapre: 0.13050355163482047\n",
      "| \u001b[39m218      \u001b[39m | \u001b[39m-0.1305  \u001b[39m | \u001b[39m447.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.07129915 -0.24732612 -0.15138802 -0.18980839 -0.55172569]\n",
      "cv_score (mean): 0.44230947356808076\n",
      "train_mapre: 0.295049913183796\n",
      "test_mapre: 0.18241184708370842\n",
      "| \u001b[39m219      \u001b[39m | \u001b[39m-0.1824  \u001b[39m | \u001b[39m176.4    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m1.625    \u001b[39m |\n",
      "cv_scores (each fold): [-1.06171204 -0.21143034 -0.15576747 -0.11953631 -0.81698157]\n",
      "cv_score (mean): 0.47308554580368245\n",
      "train_mapre: 0.05622708957274434\n",
      "test_mapre: 0.130090588594909\n",
      "| \u001b[39m220      \u001b[39m | \u001b[39m-0.1301  \u001b[39m | \u001b[39m325.1    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.73160866 -0.19308789 -0.15623337 -0.11925469 -0.66553784]\n",
      "cv_score (mean): 0.3731444910703732\n",
      "train_mapre: 0.0493931011178627\n",
      "test_mapre: 0.11315824731332941\n",
      "| \u001b[39m221      \u001b[39m | \u001b[39m-0.1132  \u001b[39m | \u001b[39m329.1    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m6.897    \u001b[39m |\n",
      "cv_scores (each fold): [-1.79282775 -0.41938512 -0.32430745 -0.28252228 -1.34236147]\n",
      "cv_score (mean): 0.8322808154833629\n",
      "train_mapre: 0.815168333030744\n",
      "test_mapre: 0.42363875299499665\n",
      "| \u001b[39m222      \u001b[39m | \u001b[39m-0.4236  \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.96579211 -0.19663843 -0.14945141 -0.11964808 -0.72921025]\n",
      "cv_score (mean): 0.43214805680186236\n",
      "train_mapre: 0.13191264604788466\n",
      "test_mapre: 0.12404149394327721\n",
      "| \u001b[39m223      \u001b[39m | \u001b[39m-0.124   \u001b[39m | \u001b[39m154.8    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m7.625    \u001b[39m |\n",
      "cv_scores (each fold): [-1.0314593  -0.21088589 -0.16108009 -0.11796378 -0.80189932]\n",
      "cv_score (mean): 0.46465767581804646\n",
      "train_mapre: 0.04481664958924138\n",
      "test_mapre: 0.12971362531640745\n",
      "| \u001b[39m224      \u001b[39m | \u001b[39m-0.1297  \u001b[39m | \u001b[39m275.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.22254098 -0.22269017 -0.14575941 -0.11832954 -0.89851593]\n",
      "cv_score (mean): 0.5215672071712307\n",
      "train_mapre: 0.281135584677227\n",
      "test_mapre: 0.14489254088086165\n",
      "| \u001b[39m225      \u001b[39m | \u001b[39m-0.1449  \u001b[39m | \u001b[39m87.92    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.31743011 -0.23811281 -0.1527646  -0.12761986 -0.93969328]\n",
      "cv_score (mean): 0.5551241311119522\n",
      "train_mapre: 0.3562736989957988\n",
      "test_mapre: 0.1606529033504597\n",
      "| \u001b[39m226      \u001b[39m | \u001b[39m-0.1607  \u001b[39m | \u001b[39m62.55    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-2.33665423 -0.38317329 -0.22930544 -0.2317088  -0.67574339]\n",
      "cv_score (mean): 0.7713170291635925\n",
      "train_mapre: 0.6157368412643969\n",
      "test_mapre: 0.3125640206266586\n",
      "| \u001b[39m227      \u001b[39m | \u001b[39m-0.3126  \u001b[39m | \u001b[39m335.7    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.1864   \u001b[39m |\n",
      "cv_scores (each fold): [-0.541296   -0.18629888 -0.15214733 -0.12957836 -0.51702084]\n",
      "cv_score (mean): 0.30526828165092706\n",
      "train_mapre: 0.05665585069933464\n",
      "test_mapre: 0.11022001494894886\n",
      "| \u001b[35m228      \u001b[39m | \u001b[35m-0.1102  \u001b[39m | \u001b[35m343.0    \u001b[39m | \u001b[35m0.1      \u001b[39m | \u001b[35m5.255    \u001b[39m |\n",
      "cv_scores (each fold): [-0.6676966  -0.18890059 -0.1469783  -0.1268743  -0.58525402]\n",
      "cv_score (mean): 0.34314076440237684\n",
      "train_mapre: 0.07105969670483622\n",
      "test_mapre: 0.1179583093864791\n",
      "| \u001b[39m229      \u001b[39m | \u001b[39m-0.118   \u001b[39m | \u001b[39m290.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m5.676    \u001b[39m |\n",
      "cv_scores (each fold): [-1.07220955 -0.21178202 -0.15380705 -0.11622535 -0.82491819]\n",
      "cv_score (mean): 0.4757884334196171\n",
      "train_mapre: 0.14993389531286708\n",
      "test_mapre: 0.1365949146431882\n",
      "| \u001b[39m230      \u001b[39m | \u001b[39m-0.1366  \u001b[39m | \u001b[39m159.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06121078 -0.21208142 -0.15727122 -0.11556501 -0.82046614]\n",
      "cv_score (mean): 0.47331891481997623\n",
      "train_mapre: 0.09342708575151794\n",
      "test_mapre: 0.13375350394764554\n",
      "| \u001b[39m231      \u001b[39m | \u001b[39m-0.1338  \u001b[39m | \u001b[39m211.6    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.99268856 -0.41149238 -0.32616251 -0.25814813 -1.23111513]\n",
      "cv_score (mean): 0.8439213437282918\n",
      "train_mapre: 0.8259022908714352\n",
      "test_mapre: 0.41459960660435613\n",
      "| \u001b[39m232      \u001b[39m | \u001b[39m-0.4146  \u001b[39m | \u001b[39m224.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.7808258  -0.18841713 -0.14716565 -0.12497714 -0.62828963]\n",
      "cv_score (mean): 0.373935069025791\n",
      "train_mapre: 0.08460429729003416\n",
      "test_mapre: 0.11803473956034614\n",
      "| \u001b[39m233      \u001b[39m | \u001b[39m-0.118   \u001b[39m | \u001b[39m226.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m6.085    \u001b[39m |\n",
      "cv_scores (each fold): [-1.08501149 -0.21295777 -0.15285531 -0.11685061 -0.83311252]\n",
      "cv_score (mean): 0.4801575402985729\n",
      "train_mapre: 0.167327319969822\n",
      "test_mapre: 0.13819665920253565\n",
      "| \u001b[39m234      \u001b[39m | \u001b[39m-0.1382  \u001b[39m | \u001b[39m146.5    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.48768677 -0.18654187 -0.1458953  -0.1314958  -0.45124614]\n",
      "cv_score (mean): 0.28057317821365324\n",
      "train_mapre: 0.05916210302833094\n",
      "test_mapre: 0.11059058565896815\n",
      "| \u001b[39m235      \u001b[39m | \u001b[39m-0.1106  \u001b[39m | \u001b[39m365.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m4.672    \u001b[39m |\n",
      "cv_scores (each fold): [-0.62747452 -0.1874713  -0.1455239  -0.12796438 -0.55796567]\n",
      "cv_score (mean): 0.329279952609245\n",
      "train_mapre: 0.07170468784284083\n",
      "test_mapre: 0.11707879859536843\n",
      "| \u001b[39m236      \u001b[39m | \u001b[39m-0.1171  \u001b[39m | \u001b[39m305.8    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m5.383    \u001b[39m |\n",
      "cv_scores (each fold): [-1.95974748 -0.41312664 -0.32422956 -0.2592619  -1.24198546]\n",
      "cv_score (mean): 0.8396702079205175\n",
      "train_mapre: 0.8229345914015905\n",
      "test_mapre: 0.4158890732184337\n",
      "| \u001b[39m237      \u001b[39m | \u001b[39m-0.4159  \u001b[39m | \u001b[39m193.9    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m0.01     \u001b[39m |\n",
      "cv_scores (each fold): [-0.81296635 -0.19511206 -0.15676258 -0.11879646 -0.68484305]\n",
      "cv_score (mean): 0.3936961002557974\n",
      "train_mapre: 0.0776974496813831\n",
      "test_mapre: 0.11662261003213413\n",
      "| \u001b[39m238      \u001b[39m | \u001b[39m-0.1166  \u001b[39m | \u001b[39m223.7    \u001b[39m | \u001b[39m0.7276   \u001b[39m | \u001b[39m7.116    \u001b[39m |\n",
      "cv_scores (each fold): [-1.04551656 -0.2122228  -0.15720052 -0.11644452 -0.80994665]\n",
      "cv_score (mean): 0.4682662068832578\n",
      "train_mapre: 0.10929907021112041\n",
      "test_mapre: 0.13032438716394176\n",
      "| \u001b[39m239      \u001b[39m | \u001b[39m-0.1303  \u001b[39m | \u001b[39m184.6    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06277466 -0.21260891 -0.15517    -0.11606213 -0.81127077]\n",
      "cv_score (mean): 0.47157729466614545\n",
      "train_mapre: 0.12929201155861425\n",
      "test_mapre: 0.13182260366818493\n",
      "| \u001b[39m240      \u001b[39m | \u001b[39m-0.1318  \u001b[39m | \u001b[39m166.1    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.72194344 -0.18829135 -0.14437656 -0.12594361 -0.55350335]\n",
      "cv_score (mean): 0.34681166213417497\n",
      "train_mapre: 0.060821065702161586\n",
      "test_mapre: 0.10962902141236536\n",
      "| \u001b[35m241      \u001b[39m | \u001b[35m-0.1096  \u001b[39m | \u001b[35m238.8    \u001b[39m | \u001b[35m0.1      \u001b[39m | \u001b[35m5.323    \u001b[39m |\n",
      "cv_scores (each fold): [-1.03234601 -0.21215536 -0.1592122  -0.1160856  -0.8050327 ]\n",
      "cv_score (mean): 0.46496637280875885\n",
      "train_mapre: 0.0687096261234644\n",
      "test_mapre: 0.129847922089528\n",
      "| \u001b[39m242      \u001b[39m | \u001b[39m-0.1298  \u001b[39m | \u001b[39m235.8    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.26540289 -0.22269073 -0.14814366 -0.11751466 -0.89780403]\n",
      "cv_score (mean): 0.5303111954129575\n",
      "train_mapre: 0.29920393235178855\n",
      "test_mapre: 0.1508193496470436\n",
      "| \u001b[39m243      \u001b[39m | \u001b[39m-0.1508  \u001b[39m | \u001b[39m78.26    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.57787061 -0.18683078 -0.15452623 -0.12514809 -0.58349248]\n",
      "cv_score (mean): 0.32557363686611385\n",
      "train_mapre: 0.050639300878864334\n",
      "test_mapre: 0.11131311518809071\n",
      "| \u001b[39m244      \u001b[39m | \u001b[39m-0.1113  \u001b[39m | \u001b[39m419.3    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m5.868    \u001b[39m |\n",
      "cv_scores (each fold): [-0.4330462  -0.18617912 -0.143832   -0.13245738 -0.41476368]\n",
      "cv_score (mean): 0.2620556767861872\n",
      "train_mapre: 0.05938133434753767\n",
      "test_mapre: 0.11122747682895584\n",
      "| \u001b[39m245      \u001b[39m | \u001b[39m-0.1112  \u001b[39m | \u001b[39m411.2    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m4.434    \u001b[39m |\n",
      "cv_scores (each fold): [-1.3480041  -0.24556617 -0.15392371 -0.13403394 -0.95324644]\n",
      "cv_score (mean): 0.5669548727673186\n",
      "train_mapre: 0.380543739641403\n",
      "test_mapre: 0.16858216395481626\n",
      "| \u001b[39m246      \u001b[39m | \u001b[39m-0.1686  \u001b[39m | \u001b[39m55.48    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.06157048 -0.21796641 -0.15737606 -0.11790416 -0.82123153]\n",
      "cv_score (mean): 0.475209729964149\n",
      "train_mapre: 0.054530500409139766\n",
      "test_mapre: 0.13080469378532628\n",
      "| \u001b[39m247      \u001b[39m | \u001b[39m-0.1308  \u001b[39m | \u001b[39m415.4    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-0.77451745 -0.18832079 -0.1403428  -0.12558829 -0.55337329]\n",
      "cv_score (mean): 0.3564285251421258\n",
      "train_mapre: 0.07247418633503656\n",
      "test_mapre: 0.11203360960227672\n",
      "| \u001b[39m248      \u001b[39m | \u001b[39m-0.112   \u001b[39m | \u001b[39m216.3    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m5.173    \u001b[39m |\n",
      "cv_scores (each fold): [-1.16937333 -0.21574742 -0.14769748 -0.11894515 -0.87096453]\n",
      "cv_score (mean): 0.5045455831656462\n",
      "train_mapre: 0.22970891909982646\n",
      "test_mapre: 0.13970030181324095\n",
      "| \u001b[39m249      \u001b[39m | \u001b[39m-0.1397  \u001b[39m | \u001b[39m105.9    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "cv_scores (each fold): [-1.42599052 -0.26124135 -0.16826068 -0.14948376 -0.98849196]\n",
      "cv_score (mean): 0.5986936562556013\n",
      "train_mapre: 0.42756732134828074\n",
      "test_mapre: 0.19191459788377624\n",
      "| \u001b[39m250      \u001b[39m | \u001b[39m-0.1919  \u001b[39m | \u001b[39m42.22    \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "=============================================================\n",
      "Running time: 0:00:37.546942\n",
      "       target           C   epsilon      gamma\n",
      "0   -0.415329  209.093980  3.629590   0.011143\n",
      "1   -0.223750  151.863954  0.819104   0.932463\n",
      "2   -0.137023   93.943845  1.793248   3.973707\n",
      "3   -0.114976  269.869550  2.154053   6.855343\n",
      "4   -0.338165  103.021673  4.402775   0.283602\n",
      "..        ...         ...       ...        ...\n",
      "246 -0.130805  415.356631  5.000000  10.000000\n",
      "247 -0.112034  216.298865  0.100000   5.172942\n",
      "248 -0.139700  105.948408  5.000000  10.000000\n",
      "249 -0.191915   42.220112  0.100000  10.000000\n",
      "250 -0.109629  238.778621  0.100000   5.323172\n",
      "\n",
      "[251 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(1)\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "t = time.localtime()\n",
    "model_name = 'd33_inference_SVR'\n",
    "file_name = '{}.xlsx'.format(model_name)\n",
    "data = pd.read_excel('data-1.xlsx')\n",
    "\n",
    "x_all, y_all, train_features, test_features, train_labels, test_labels = normalizing_data(data, seed=1)\n",
    "train_features, test_features = train_features.cpu().data.numpy(), test_features.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.cpu().data.numpy(), test_labels.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.reshape(-1), test_labels.reshape(-1) \n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def train_model(C, epsilon, gamma):\n",
    "    params = {\n",
    "        \"C\": C,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"gamma\": gamma,\n",
    "        \"kernel\": \"rbf\" \n",
    "    }\n",
    "    model = SVR(**params)\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(model, train_features, train_labels, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "    cv_scores = scores\n",
    "    cv_score = -scores.mean()\n",
    "    print(\"cv_scores (each fold):\", cv_scores)  \n",
    "    print(\"cv_score (mean):\", cv_score)  \n",
    "    \n",
    "\n",
    "    \n",
    "    model.fit(train_features, train_labels)\n",
    "    y_pred_train = model.predict(train_features)\n",
    "    y_pred_test = model.predict(test_features)\n",
    "    train_mape = mean_absolute_percentage_error(train_labels, y_pred_train)\n",
    "    test_mape = mean_absolute_percentage_error(test_labels, y_pred_test)\n",
    "    print(\"train_mapre:\", train_mape)\n",
    "    print(\"test_mapre:\", test_mape)\n",
    "    error = -mean_absolute_percentage_error(test_labels, y_pred_test)\n",
    "    return error\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "bounds = {\n",
    "    'C': (1, 500), \n",
    "    'epsilon': (0.1, 5), \n",
    "    'gamma': (0.01, 10) \n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_model,\n",
    "    pbounds=bounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer.maximize(init_points=100, n_iter=150)\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for res in optimizer.res:\n",
    "    result_list.append(pd.DataFrame({'target': [res['target']],\n",
    "                                     'C': [res['params']['C']],\n",
    "                                     'epsilon': [res['params']['epsilon']],\n",
    "                                     'gamma': [res['params']['gamma']]}))\n",
    "\n",
    "\n",
    "table = pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "\n",
    "best_result = pd.DataFrame({'target': [optimizer.max['target']],\n",
    "                            'C': [optimizer.max['params']['C']],\n",
    "                            'epsilon': [optimizer.max['params']['epsilon']],\n",
    "                            'gamma': [optimizer.max['params']['gamma']]})\n",
    "\n",
    "\n",
    "table = pd.concat([table, best_result], ignore_index=True)\n",
    "\n",
    "\n",
    "table.to_excel(file_name)\n",
    "endtime = datetime.datetime.now()\n",
    "print('Running time: {}'.format(endtime - starttime))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6ab68-e1e4-49ed-885a-8f3d0ee7a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ba        Ca   Sr     Ti     Zr        Sn    Hf         W  \\\n",
      "0    1.000000  0.000000  0.0  1.000  0.000  0.000000  0.00  1.000000   \n",
      "1    1.000000  0.000000  0.0  0.950  0.050  0.000000  0.00  0.978718   \n",
      "2    1.000000  0.000000  0.0  0.950  0.000  0.071429  0.00  0.965424   \n",
      "3    1.000000  0.000000  0.0  0.925  0.075  0.000000  0.00  0.968220   \n",
      "4    1.000000  0.000000  0.0  0.900  0.000  0.000000  0.10  0.877303   \n",
      "..        ...       ...  ...    ...    ...       ...   ...       ...   \n",
      "149  0.333333  0.666667  0.0  1.000  0.000  0.000000  0.00  0.664214   \n",
      "150  0.333333  0.666667  0.0  0.500  0.500  0.000000  0.00  0.495194   \n",
      "151  0.333333  0.666667  0.0  0.500  0.000  0.000000  0.50  0.227934   \n",
      "152  0.200000  0.800000  0.0  0.840  0.000  0.000000  0.16  0.439015   \n",
      "153  0.000000  1.000000  0.0  1.000  0.000  0.000000  0.00  0.496321   \n",
      "\n",
      "           EI        EA         μ  \n",
      "0    0.885689  0.786531  0.000000  \n",
      "1    0.892040  0.765946  0.016596  \n",
      "2    0.868796  0.725267  0.027117  \n",
      "3    0.895215  0.755653  0.024894  \n",
      "4    0.885886  0.783581  0.100000  \n",
      "..        ...       ...       ...  \n",
      "149  0.295230  0.928844  0.000000  \n",
      "150  0.358736  0.722994  0.165962  \n",
      "151  0.296214  0.914096  0.500000  \n",
      "152  0.177453  0.952587  0.160000  \n",
      "153  0.000000  1.000000  0.000000  \n",
      "\n",
      "[154 rows x 11 columns]\n",
      "     d33(pC/N)\n",
      "0          190\n",
      "1          273\n",
      "2          250\n",
      "3          317\n",
      "4          361\n",
      "..         ...\n",
      "149        123\n",
      "150        421\n",
      "151        288\n",
      "152        135\n",
      "153        106\n",
      "\n",
      "[154 rows x 1 columns]\n",
      "tensor([[190.],\n",
      "        [273.],\n",
      "        [250.],\n",
      "        [317.],\n",
      "        [361.],\n",
      "        [343.],\n",
      "        [334.],\n",
      "        [400.],\n",
      "        [272.],\n",
      "        [409.],\n",
      "        [294.],\n",
      "        [275.],\n",
      "        [361.],\n",
      "        [201.],\n",
      "        [308.],\n",
      "        [225.],\n",
      "        [384.],\n",
      "        [193.],\n",
      "        [183.],\n",
      "        [346.],\n",
      "        [165.],\n",
      "        [197.],\n",
      "        [125.],\n",
      "        [312.],\n",
      "        [210.],\n",
      "        [118.],\n",
      "        [390.],\n",
      "        [437.],\n",
      "        [435.],\n",
      "        [358.],\n",
      "        [465.],\n",
      "        [446.],\n",
      "        [451.],\n",
      "        [428.],\n",
      "        [441.],\n",
      "        [508.],\n",
      "        [237.],\n",
      "        [627.],\n",
      "        [440.],\n",
      "        [400.],\n",
      "        [440.],\n",
      "        [532.],\n",
      "        [152.],\n",
      "        [635.],\n",
      "        [520.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [282.],\n",
      "        [338.],\n",
      "        [305.],\n",
      "        [283.],\n",
      "        [249.],\n",
      "        [264.],\n",
      "        [182.],\n",
      "        [140.],\n",
      "        [187.],\n",
      "        [543.],\n",
      "        [548.],\n",
      "        [631.],\n",
      "        [448.],\n",
      "        [217.],\n",
      "        [150.],\n",
      "        [270.],\n",
      "        [285.],\n",
      "        [324.],\n",
      "        [355.],\n",
      "        [360.],\n",
      "        [525.],\n",
      "        [600.],\n",
      "        [520.],\n",
      "        [180.],\n",
      "        [320.],\n",
      "        [170.],\n",
      "        [140.],\n",
      "        [ 90.],\n",
      "        [ 70.],\n",
      "        [218.],\n",
      "        [270.],\n",
      "        [571.],\n",
      "        [552.],\n",
      "        [532.],\n",
      "        [426.],\n",
      "        [603.],\n",
      "        [339.],\n",
      "        [141.],\n",
      "        [308.],\n",
      "        [370.],\n",
      "        [323.],\n",
      "        [282.],\n",
      "        [209.],\n",
      "        [532.],\n",
      "        [283.],\n",
      "        [531.],\n",
      "        [586.],\n",
      "        [420.],\n",
      "        [383.],\n",
      "        [421.],\n",
      "        [131.],\n",
      "        [337.],\n",
      "        [381.],\n",
      "        [404.],\n",
      "        [293.],\n",
      "        [360.],\n",
      "        [129.],\n",
      "        [  9.],\n",
      "        [381.],\n",
      "        [353.],\n",
      "        [389.],\n",
      "        [338.],\n",
      "        [344.],\n",
      "        [207.],\n",
      "        [281.],\n",
      "        [192.],\n",
      "        [156.],\n",
      "        [174.],\n",
      "        [275.],\n",
      "        [356.],\n",
      "        [261.],\n",
      "        [417.],\n",
      "        [307.],\n",
      "        [417.],\n",
      "        [359.],\n",
      "        [362.],\n",
      "        [170.],\n",
      "        [199.],\n",
      "        [282.],\n",
      "        [237.],\n",
      "        [327.],\n",
      "        [347.],\n",
      "        [323.],\n",
      "        [429.],\n",
      "        [215.],\n",
      "        [270.],\n",
      "        [ 49.],\n",
      "        [ 17.],\n",
      "        [335.],\n",
      "        [298.],\n",
      "        [350.],\n",
      "        [332.],\n",
      "        [448.],\n",
      "        [176.],\n",
      "        [328.],\n",
      "        [272.],\n",
      "        [349.],\n",
      "        [238.],\n",
      "        [253.],\n",
      "        [178.],\n",
      "        [200.],\n",
      "        [238.],\n",
      "        [123.],\n",
      "        [421.],\n",
      "        [288.],\n",
      "        [135.],\n",
      "        [106.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_229968/2812312343.py:159: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "data = pd.read_excel('data-1.xlsx')\n",
    "x_all, y_all, train_features, test_features, train_labels, test_labels = normalizing_data(data, seed=1)\n",
    "train_features, test_features = train_features.cpu().data.numpy(), test_features.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.cpu().data.numpy(), test_labels.cpu().data.numpy()\n",
    "train_labels, test_labels = train_labels.reshape(-1), test_labels.reshape(-1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Iteration', 'target', 'R2_Score_test', 'R2_Score_train', 'Train Loss', 'Test Loss', 'Figure_Path_Test', 'Figure_Path_Train', 'Figure_Path_All', 'Loss_Path'])\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "results_dir = 'Results/STU_SVR_BO(100+150)_1'\n",
    "figures_dir = os.path.join(results_dir, 'Figures')\n",
    "ensure_directory_exists(results_dir)\n",
    "ensure_directory_exists(figures_dir)\n",
    "\n",
    "\n",
    "for mm in range(0, 251):\n",
    "    set_random_seed(1)\n",
    "    target = pd.read_excel('d33_inference_SVR.xlsx')\n",
    "    tg = target.at[mm, 'target']\n",
    "    C = target.at[mm, 'C']\n",
    "    epsilon = target.at[mm, 'epsilon']\n",
    "    gamma = target.at[mm, 'gamma']\n",
    "    \n",
    "    params = {\n",
    "        'C': C,\n",
    "        'epsilon': epsilon,\n",
    "        'gamma': gamma,\n",
    "        'kernel': 'rbf'\n",
    "    }\n",
    "\n",
    "    \n",
    "    model = SVR(**params)\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    model_save_path = f'Results/STU_SVR_BO(100+150)_1/{mm}-seed_1.joblib'\n",
    "    joblib.dump(model, model_save_path)  \n",
    "    \n",
    "    \n",
    "    predict_train = model.predict(train_features)\n",
    "    train_mape = mean_absolute_percentage_error(train_labels, predict_train)\n",
    "    predict_test = model.predict(test_features)\n",
    "    test_mape = mean_absolute_percentage_error(test_labels, predict_test)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot([train_mape], 'bo-', label='Train MAPE')\n",
    "    plt.plot([test_mape], 'ro-', label='Test MAPE')\n",
    "    plt.title('MAPE during Training')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.text(0, test_mape, f'Target={tg:.4f}', fontdict={'size': 12, 'color': 'red'})\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figures_dir}/{mm}_SVR_training_history.png', format='png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    df_losses = pd.DataFrame({\n",
    "        'Epoch': [1],\n",
    "        'Train Loss': [train_mape],\n",
    "        'Test Loss': [test_mape]\n",
    "    })\n",
    "    excel_path = os.path.join(results_dir, f'{mm}_SVR_loss_data.xlsx')\n",
    "    df_losses.to_excel(excel_path, index=False)\n",
    "    \n",
    "    \n",
    "    fig_name_test = f'{figures_dir}/{mm}_SVR_experiment_vs_pred_test.png'\n",
    "    fig_name_train = f'{figures_dir}/{mm}_SVR_experiment_vs_pred_train.png'\n",
    "    fig_name_all = f'{figures_dir}/{mm}_SVR_experiment_vs_pred_all.png'\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_test, y=test_labels, color='red')\n",
    "    current_r2_test = r2_score(test_labels, predict_test)\n",
    "    plt.text(min(predict_test), max(test_labels), f'R²={current_r2_test:.4f}', color='red')\n",
    "    plt.title('Test Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_test, format='png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_train, y=train_labels, color='blue')\n",
    "    current_r2_train = r2_score(train_labels, predict_train)\n",
    "    plt.text(min(predict_train), max(train_labels), f'R²={current_r2_train:.4f}', color='blue')\n",
    "    plt.title('Train Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_train, format='png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    sns.regplot(x=predict_train, y=train_labels, color='blue', label='Train')\n",
    "    sns.regplot(x=predict_test, y=test_labels, color='red', label='Test')\n",
    "    plt.legend()\n",
    "    plt.text(min(np.concatenate([predict_train, predict_test])), max(np.concatenate([train_labels, test_labels])), f'R²={r2_score(np.concatenate([train_labels, test_labels]), np.concatenate([predict_train, predict_test])):.4f}', color='green')\n",
    "    plt.title('All Prediction vs Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(fig_name_all, format='png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    df_prediction_comparison_train = pd.DataFrame({\n",
    "        'Predicted Train': predict_train.squeeze(),\n",
    "        'Actual Train': train_labels.squeeze()\n",
    "    })\n",
    "    df_prediction_comparison_test = pd.DataFrame({\n",
    "        'Predicted Test': predict_test.squeeze(),\n",
    "        'Actual Test': test_labels.squeeze()\n",
    "    })\n",
    "    df_prediction_comparison_all = pd.DataFrame({\n",
    "        'Predicted': np.concatenate([predict_train, predict_test]),\n",
    "        'Actual': np.concatenate([train_labels, test_labels]),\n",
    "        'Dataset': ['Train'] * len(train_labels) + ['Test'] * len(test_labels)\n",
    "    })\n",
    "\n",
    "    df_prediction_comparison_train.to_excel(os.path.join(results_dir, f'{mm}_SVR_predictions_train.xlsx'), index=False)\n",
    "    df_prediction_comparison_test.to_excel(os.path.join(results_dir, f'{mm}_SVR_predictions_test.xlsx'), index=False)\n",
    "    df_prediction_comparison_all.to_excel(os.path.join(results_dir, f'{mm}_SVR_predictions_all.xlsx'), index=False)\n",
    "\n",
    "    \n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "        'Iteration': mm,\n",
    "        'target': tg,\n",
    "        'R2_Score_test': current_r2_test,\n",
    "        'R2_Score_train': current_r2_train,\n",
    "        'Train Loss': train_mape,  \n",
    "        'Test Loss': test_mape,    \n",
    "        'Figure_Path_Test': fig_name_test,\n",
    "        'Figure_Path_Train': fig_name_train,\n",
    "        'Figure_Path_All': fig_name_all,\n",
    "        'Loss_Path': excel_path\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "\n",
    "results_summary_filename = os.path.join(results_dir, 'results_summary_SVR.csv')\n",
    "results_df.to_csv(results_summary_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edb9f6-5755-4015-a645-646638876b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
